---
title: "Route Assistant"

bibliography: bibliography/references.bib

citation: false
citation-location: margin
citations-hover: true

code-copy: true
code-fold: true
code-link: true
code-overflow: wrap
code-tools: true

fig-responsive: true

#filters:
#     - nutshell


lightbox: true

smooth-scroll: true
source: true
---


```{r}
#| label: rLibraries
#| echo: false
#| warning: false
#| message: false

library(arrow)
library(DBI)
library(dbplyr)
library(dplyr)
library(duckdb)
library(forcats)
library(ggplot2)
library(gt)
library(lubridate)
library(odbc)
library(openair)
library(patchwork)
library(pointblank)
#library(pillar)
library(pryr)
library(purrr)
library(paletteer)
#library(plotly)
#library(plumber)
library(polars)
library(png)
#library(profvis)
library(readr)
library(reticulate)
library(scales)
library(tibble)
library(tidymodels)
library(tidyr)

```

```{python}
#| label: pythonImports
#| echo: false
#| warning: false
#| message: false
import duckdb
import openmeteo_requests
import pandas as pd
import polars as pl
import requests_cache
from retry_requests import retry
```

## Purpose

Can weather data help predict costs associated with routes?

## Database Connections

```{r}
#| include: false
#| eval: false
#| echo: false
#| code-summary: "Optional: One would execute something like this in their bash terminal if on Ubuntu to get the odbc drivers for mssql connections."
##| file: "practice/Bash/mssql_odbc_driver.sh"
```

::: code-fold-flex
```{r}
#| label: "mssqlconnect"
#| code-summary: "Currently optional: Connects to a dockerized mssql database."
#| eval: false
#| echo: true
#| include: false
# Set up the connection
mssql_con <- dbConnect(
  odbc::odbc(),
  driver = "ODBC Driver 18 for SQL Server", 
  server = "localhost,1433",               
  database = "TestDB",                    
  uid = "sa",                             
  pwd = "MyStr@ngPassw0rd11",             
  TrustServerCertificate = "yes"
)
```
:::

#### DuckDB

::: code-fold-flex
```{r}
#| label: "duckDBconnected"
#| code-summary: "Establish a DuckDB, embedded database connection."
duckdb_con <- dbConnect(duckdb::duckdb(
     config = list(max_memory = '24GB')), ":memory:")
```
:::

## Loading Custom Output Scripts

### Tables

::: code-fold-flex
```{r}
#| label: "loadTableOutput"
#| code-summary: "table building"
#| file: "scripts/Output/Tables/table_workshop.R"
```
:::

### Plots

::: code-fold-flex
```{r}
#| label: "loadPlotOutput"
#| code-summary: "plot theming"
#| file: "scripts/Output/Plots/plot_themer.R"
```
:::

::: code-fold-flex
```{r}
#| label: "loadPlotWorkshop"
#| code-summary: "plot building"
#| file: "scripts/Output/Plots/plot_workshop.R"
```
:::

## Workflow

Data moves from:

Python ingestion → R loading → SQL transformations → final table materialization

![workflow](svgWorkflow.svg){fig-align="center" width="1012" height="140"}

# Import

## Weather Data API

[@openMeteo_2025]

### Forecast

::: code-fold-flex
```{python}
#| label: loadHourlyAPIscript
#| code-summary: "Run the API script to import the dataset."
#| file: "scripts/Import/API/Hourly/import_api_hourly.py"
```
:::

::: code-fold-flex
```{r}
#| label: writeHourlyForecastAPIdata
#| code-summary: "Write hourly api results."

dbWriteTable(
duckdb_con, 
"forecast_data", 
py$import_api_hourly(38.748, -90.439),
overwrite = TRUE
)
```
:::

### Historical

::: code-fold-flex
```{python}
#| label: loadHourlyHistoricalAPIscript
#| code-summary: "Run the API script to import the dataset."
#| file: "scripts/Import/API/Hourly/import_api_hourly_historical.py"
```
:::

::: code-fold-flex
```{r}
#| label: writeHistoricalAPIdata
#| code-summary: "Write hourly api historical data."

dbWriteTable(
duckdb_con, 
"historical_data",
py$import_api_hourly_historical(38.748, -90.439, "1974-01-01", "2024-12-31"),
overwrite = TRUE
)
```
:::


## About the Weather Data

::: p-1
The study, published in the *Weather and Forecasting* journal, focuses on evaluating and improving the accuracy of weather prediction models, particularly for severe weather events. It examines the performance of high-resolution numerical weather prediction (NWP) models in forecasting convective storms, which are critical for predicting severe weather such as thunderstorms, hail, and tornadoes. The research highlights advancements in model resolution, data assimilation techniques, and the integration of observational data to enhance forecast precision. The findings emphasize the importance of these improvements for short-term (nowcasting) and medium-range forecasts, particularly in regions prone to severe weather, like the central United States (including Missouri). @dowell_high-resolution_2022
:::

::: code-fold-flex
```{r}
#| label: "forecastModelDescription"
#| code-summary: "table setup"
#| warning: false

# Create the tibble
forecast_models <- tibble(
     Model = c("GFS", "HRRR"),
     Developed_By = c(
          "NOAA (National Oceanic and Atmospheric Administration)",
          "NOAA (specifically by the Earth System Research Laboratory)"
     ),
     Scope = c(
          "Global",
          "Regional (primarily focused on the contiguous United States)"
     ),
     Resolution = c(
          "Lower resolution compared to HRRR (approximately 13 km as of recent updates)",
          "High resolution (3 km)"
     ),
     Forecast_Range = c("Up to 16 days", "Up to 18 hours"),
     Updates = c("Runs four times a day (00Z, 06Z, 12Z, 18Z)", "Runs every hour"),
     Applications = c(
          "Used for long-term weather forecasting, climate modeling, and global weather patterns.",
          "Ideal for short-term, detailed weather forecasting, including severe weather events like thunderstorms, tornadoes, and localized precipitation."
     )
)

locations_list = colnames(forecast_models)

notes_list =  list(
     "",
  "Organization or entity responsible for developing the model.",
  "Geographical coverage of the model (e.g., global or regional).",
  "Spatial resolution of the model, indicating the level of detail in the forecasts.",
  "Time period for which the model provides forecasts.",
  "Frequency at which the model is updated with new data.",
  "Primary uses and strengths of the model in weather forecasting."
  )

footnotes_df <- tibble(
  notes = notes_list, 
  locations = locations_list)

pal_df <- tibble(
  cols = locations_list
#  pals = list(eval_palette("viridis::viridis", 2, 'c', 1))
)

rTable <- r_table_theming(
forecast_models,
title = "Forecast Models: Attributes",
subtitle = NULL,
footnotes_df,
source_note = md("**source**: "),
pal_df,
multiline_feet = TRUE,
table_font_size = pct(85),
target_everything = TRUE,
row_name_col = "Model",
)
```
:::

::::: {#one}
:::: medium-large-tables
::: table-flex
```{r}
#| label: "tbl-modelAttributes"
#| warning: false
#| echo: false
#| column: body-outset-right

rTable |>
opt_css(
css = '
#one .gt_table_body td.gt_row {
box-shadow: -1px -1px 7px 1px rgba(0, 0, 0, 0.2) inset;
} 
'
)
```
:::
::::
:::::

::: code-fold-flex
```{r}
#| label: "modelDiffSetup"
#| code-summary: "table setup"
#| message: false
#| error: false

forecast_model_differences <- tibble(
"Resolution" = c(
"HRRR has a much higher resolution than GFS, making it more accurate for short-term, localized forecasts."
),
"Forecast_Range" = c("GFS provides forecasts for a much longer period compared to HRRR."),
"Update_Frequency" =  c(
"HRRR updates more frequently, which is crucial for capturing rapidly changing weather conditions."
)
)

locations_list = colnames(forecast_model_differences)

notes_list =  list(
  "Spatial resolution of the model, indicating the level of detail in the forecasts.",
  "Time period for which the model provides forecasts.",
  "Frequency at which the model is updated with new data.")

footnotes_df <- tibble(
  notes = notes_list, 
  locations = locations_list)

pal_df <- tibble(
  cols = locations_list
#  pals = list(eval_palette("viridis::viridis", 2, 'c', 1))
)

rTable <- r_table_theming(
forecast_model_differences,
title = "Forecast Models: Differences",
subtitle = NULL,
footnotes_df,
source_note = md("**source**: "),
pal_df,
multiline_feet = TRUE,
table_font_size = pct(85),
target_everything = TRUE,
row_name_col = NULL
)
```
:::

::::: {#two}
:::: medium-large-tables
::: table-flex
```{r}
#| label: "tbl-modelDiffs"
#| echo: false
rTable |>
opt_css(
css = '
#two .gt_table_body td.gt_row {
box-shadow: -1px -1px 7px 1px rgba(0, 0, 0, 0.2) inset;
} 
'
)
```
:::
::::
:::::

## Database Setup

::: code-fold-flex
```{r}
#| label: "setEnumsFile"
#| code-summary: "load enum file"
#| file: "scripts/Setup/Enum/create_enum_and_associate.R"
```
:::

::: code-fold-flex
```{r}
#| label: "setEnums"
#| code-summary: "Sets the custom data types in the database."

code_frame <- tibble::tibble(
code = c(
'0',
'1',
'2',
'3',
'45',
'48',
'51',
'53',
'55',
'56',
'57',
'61',
'63',
'65',
'66',
'67',
'71',
'73',
'75',
'77',
'80',
'81',
'82',
'85',
'86',
'95',
'96',
'99'
),

description = c(
'Clear sky',
'Mainly clear',
'Partly cloudy',
'Overcast',
'Fog',
'Depositing rime fog',
'Drizzle: light',
'Drizzle: moderate',
'Drizzle: dense',
'Freezing drizzle: light',
'Freezing drizzle: dense',
'Rain: slight',
'Rain: moderate',
'Rain: heavy',
'Freezing rain: light',
'Freezing rain: heavy',
'Snow fall: slight',
'Snow fall: moderate',
'Snow fall: heavy',
'Snow grains',
'Rain showers: slight',
'Rain showers: moderate',
'Rain showers: violent',
'Snow showers: slight',
'Snow showers: heavy',
'Thunderstorm: slight or moderate',
'Thunderstorm with slight hail',
'Thunderstorm with heavy hail'
),

implication = c(
"Normal operations - No restrictions",              # Clear sky
"Normal operations - Increased vigilance",          # Mainly clear
"Normal operations - Monitor weather updates",      # Partly cloudy
"Reduced visibility - Maintain safe following distance", # Overcast
"Speed reduction required - Fog lights mandatory",  # Fog
"Speed reduction required - Extreme caution",        # Depositing rime fog
"Potential minor delays - Road surface slickness",   # Drizzle: light
"Speed restrictions - 15% reduction recommended",    # Drizzle: moderate
"Mandatory speed reduction - 25%+",                 # Drizzle: dense
"Chain requirement - Level 1 traction advisory",     # Freezing drizzle: light
"Road closure likely - Avoid non-essential travel",  # Freezing drizzle: dense
"Increased stopping distance - 10% speed reduction", # Rain: slight
"15-20% speed reduction - Check tire tread",         # Rain: moderate
"25%+ speed reduction - Possible detour routing",    # Rain: heavy
"Mandatory chains - Temperature monitoring",         # Freezing rain: light
"Road closure imminent - Immediate stop advised",    # Freezing rain: heavy
"15% speed reduction - Traction control engaged",    # Snow fall: slight
"25% speed reduction - Chain requirement possible",  # Snow fall: moderate
"Road closure likely - Abandon shipment staging",    # Snow fall: heavy
"Speed restriction - Watch for black ice",           # Snow grains
"Increased following distance - 4-second rule",      # Rain showers: slight
"20% speed reduction - Avoid lane changes",          # Rain showers: moderate
"Immediate parking advised - Flash flood risk",      # Rain showers: violent
"Chain requirement - Trailer brake check",           # Snow showers: slight
"Road closure protocol activated",                   # Snow showers: heavy
"Delay shipments - No open-top trailers",            # Thunderstorm: slight/mod
"Immediate stop - Seek shelter",                     # Thunderstorm w/ slight hail
"Catastrophic risk - Emergency protocols"            # Thunderstorm w/ heavy hail
),

risk_score = c(
0.1,  # Clear sky
0.15, # Mainly clear
0.2,  # Partly cloudy
0.25, # Overcast
0.4,  # Fog
0.5,  # Depositing rime fog
0.3,  # Drizzle: light
0.35, # Drizzle: moderate
0.45, # Drizzle: dense
0.55, # Freezing drizzle: light
0.8,  # Freezing drizzle: dense
0.3,  # Rain: slight
0.4,  # Rain: moderate
0.6,  # Rain: heavy
0.65, # Freezing rain: light
0.85, # Freezing rain: heavy
0.4,  # Snow fall: slight
0.6,  # Snow fall: moderate
0.75, # Snow fall: heavy
0.5,  # Snow grains
0.35, # Rain showers: slight
0.5,  # Rain showers: moderate
0.7,  # Rain showers: violent
0.6,  # Snow showers: slight
0.8,  # Snow showers: heavy
0.65, # Thunderstorm: slight/mod
0.85, # Thunderstorm w/ slight hail
0.95  # Thunderstorm w/ heavy hail
  ),

dot_compliance = c(
"§392.14(a)",              # Clear sky
"§392.14(a)",              # Mainly clear
"§392.14(a)",              # Partly cloudy
"§392.14(b)",              # Overcast
"§392.14(b)+§393.75(c)",   # Fog
"§392.14(c)",              # Depositing rime fog
"§392.71(a)",              # Drizzle: light
"§392.71(b)",              # Drizzle: moderate
"§392.71(c)",              # Drizzle: dense
"§392.16(a)",              # Freezing drizzle: light
"§392.16(c)",              # Freezing drizzle: dense
"§392.71(a)",              # Rain: slight
"§392.71(b)",              # Rain: moderate
"§392.71(c)",              # Rain: heavy
"§392.16(b)+§393.95(d)",   # Freezing rain: light
"§392.16(c)",              # Freezing rain: heavy
"§392.14(b)+§393.95(a)",   # Snow fall: slight
"§392.14(c)+§393.95(b)",   # Snow fall: moderate
"§392.16(c)",              # Snow fall: heavy
"§392.14(c)",              # Snow grains
"§392.14(b)",              # Rain showers: slight
"§392.14(c)",              # Rain showers: moderate
"§392.16(c)",              # Rain showers: violent
"§393.95(c)",              # Snow showers: slight
"§392.16(c)",              # Snow showers: heavy
"§392.14(d)+§393.75(e)",   # Thunderstorm: slight/mod
"§392.16(c)",              # Thunderstorm w/ slight hail
"§392.16(e)"               # Thunderstorm w/ heavy hail
),

severity = cut(
risk_score,
breaks = c(0, 0.3, 0.5, 0.7, 1),
labels = c("Low", "Moderate", "High", "Critical")
),

insurance_surcharge = c(
0,    # Clear sky
0,    # Mainly clear
0.05, # Partly cloudy (5%)
0.07, # Overcast (7%)
0.1,  # Fog (10%)
0.15, # Rime fog (15%)
0.08, # Light drizzle (8%)
0.12, # Moderate drizzle (12%)
0.18, # Dense drizzle (18%)
0.25, # Freezing drizzle light (25%)
0.4,  # Freezing drizzle dense (40%)
0.1,  # Rain slight (10%)
0.15, # Rain moderate (15%)
0.25, # Rain heavy (25%)
0.35, # Freezing rain light (35%)
0.5,  # Freezing rain heavy (50%)
0.2,  # Snow slight (20%)
0.3,  # Snow moderate (30%)
0.45, # Snow heavy (45%)
0.25, # Snow grains (25%)
0.12, # Rain showers slight (12%)
0.2,  # Rain showers moderate (20%)
0.35, # Rain showers violent (35%)
0.3,  # Snow showers slight (30%)
0.5,  # Snow showers heavy (50%)
0.4,  # Thunderstorm (40%)
0.6,  # Thunderstorm w/ slight hail (60%)
0.8   # Thunderstorm w/ heavy hail (80%)
),

fuel_multiplier = c(
1.0,  # Clear sky
1.0,  # Mainly clear
1.03, # Partly cloudy (3%)
1.05, # Overcast (5%)
1.12, # Fog (12%)
1.15, # Rime fog (15%)
1.07, # Light drizzle (7%)
1.1,  # Moderate drizzle (10%)
1.15, # Dense drizzle (15%)
1.25, # Freezing drizzle light (25%)
1.4,  # Freezing drizzle dense (40%)
1.08, # Rain slight (8%)
1.12, # Rain moderate (12%)
1.2,  # Rain heavy (20%)
1.3,  # Freezing rain light (30%)
1.5,  # Freezing rain heavy (50%)
1.15, # Snow slight (15%)
1.25, # Snow moderate (25%)
1.4,  # Snow heavy (40%)
1.2,  # Snow grains (20%)
1.1,  # Rain showers slight (10%)
1.15, # Rain showers moderate (15%)
1.3,  # Rain showers violent (30%)
1.25, # Snow showers slight (25%)
1.45, # Snow showers heavy (45%)
1.35, # Thunderstorm (35%)
1.6,  # Thunderstorm w/ slight hail (60%)
2.0   # Thunderstorm w/ heavy hail (100%)
  ),

route_delay_factor = c(
1.0,  # Clear sky
1.0,  # Mainly clear
1.1,  # Partly cloudy
1.2,  # Overcast
1.5,  # Fog
1.8,  # Rime fog
1.3,  # Light drizzle
1.6,  # Moderate drizzle
2.0,  # Dense drizzle
2.5,  # Freezing drizzle light
4.0,  # Freezing drizzle dense
1.4,  # Rain slight
1.8,  # Rain moderate
2.5,  # Rain heavy
3.0,  # Freezing rain light
5.0,  # Freezing rain heavy
2.0,  # Snow slight
3.0,  # Snow moderate
4.5,  # Snow heavy
2.5,  # Snow grains
1.5,  # Rain showers slight
2.0,  # Rain showers moderate
3.5,  # Rain showers violent
3.0,  # Snow showers slight
5.0,  # Snow showers heavy
3.5,  # Thunderstorm
6.0,  # Thunderstorm w/ slight hail
10.0  # Thunderstorm w/ heavy hail
),

# New Labor & Equipment Columns
safety_inspections = c(
"Pre-trip only",                    # Clear sky
"Pre-trip + mid-trip visual",       # Mainly clear
"Pre-trip + brake check",           # Partly cloudy
"Pre-trip + hourly tire checks",    # Overcast
"Pre-trip + fog light checks",      # Fog
"Pre-trip + 30-min interval checks",# Rime fog
"Pre-trip + 2hr brake tests",       # Drizzle: light
"Pre-trip + 1hr brake tests",       # Drizzle: moderate
"Pre-trip + 30min brake tests",     # Drizzle: dense
"Pre-trip + axle temp monitoring",  # Freezing drizzle: light
"Continuous monitoring required",   # Freezing drizzle: dense
"Pre-trip + wiper checks",          # Rain: slight
"Pre-trip + 2hr wiper checks",      # Rain: moderate
"Pre-trip + 30min wiper checks",    # Rain: heavy
"Pre-trip + chain integrity checks",# Freezing rain: light
"Roadside inspections mandatory",   # Freezing rain: heavy
"Pre-trip + tire chain prep",       # Snow fall: slight
"Pre-trip + hourly chain checks",   # Snow fall: moderate
"Continuous chain monitoring",      # Snow fall: heavy
"Pre-trip + sanding required",      # Snow grains
"Pre-trip + drainage checks",       # Rain showers: slight
"Pre-trip + undercarriage checks",  # Rain showers: moderate
"Abort trip + full inspection",     # Rain showers: violent
"Pre-trip + plow attachment",       # Snow showers: slight
"Roadside de-icing required",       # Snow showers: heavy
"Pre-trip + lightning protocol",    # Thunderstorm: slight/mod
"Immediate shelter + inspection",   # Thunderstorm w/ slight hail
"Post-storm forensic inspection"    # Thunderstorm w/ heavy hail
),

driver_wage_premium = c(
0.00,  # Clear sky
0.00,   # Mainly clear
0.05,   # Partly cloudy (+5%)
0.07,   # Overcast (+7%)
0.15,   # Fog (+15%)
0.20,   # Rime fog (+20%)
0.10,   # Drizzle: light (+10%)
0.12,   # Drizzle: moderate (+12%)
0.18,   # Drizzle: dense (+18%)
0.25,   # Freezing drizzle: light (+25%)
0.40,   # Freezing drizzle: dense (+40%)
0.10,   # Rain: slight (+10%)
0.15,   # Rain: moderate (+15%)
0.25,   # Rain: heavy (+25%)
0.35,   # Freezing rain: light (+35%)
0.50,   # Freezing rain: heavy (+50%)
0.20,   # Snow fall: slight (+20%)
0.30,   # Snow fall: moderate (+30%)
0.45,   # Snow fall: heavy (+45%)
0.25,   # Snow grains (+25%)
0.12,   # Rain showers: slight (+12%)
0.20,   # Rain showers: moderate (+20%)
0.35,   # Rain showers: violent (+35%)
0.30,   # Snow showers: slight (+30%)
0.50,   # Snow showers: heavy (+50%)
0.40,   # Thunderstorm (+40%)
0.60,   # Thunderstorm w/ slight hail (+60%)
0.80    # Thunderstorm w/ heavy hail (+80%)
),
  
equipment_wear_factor = c(
1.0,   # Clear sky
1.02,  # Mainly clear (+2%)
1.05,  # Partly cloudy (+5%)
1.07,  # Overcast (+7%)
1.15,  # Fog (+15%)
1.20,  # Rime fog (+20%)
1.10,  # Drizzle: light (+10%)
1.12,  # Drizzle: moderate (+12%)
1.18,  # Drizzle: dense (+18%)
1.25,  # Freezing drizzle: light (+25%)
1.40,  # Freezing drizzle: dense (+40%)
1.12,  # Rain: slight (+12%)
1.15,  # Rain: moderate (+15%)
1.25,  # Rain: heavy (+25%)
1.35,  # Freezing rain: light (+35%)
1.50,  # Freezing rain: heavy (+50%)
1.20,  # Snow fall: slight (+20%)
1.30,  # Snow fall: moderate (+30%)
1.45,  # Snow fall: heavy (+45%)
1.25,  # Snow grains (+25%)
1.10,  # Rain showers: slight (+10%)
1.15,  # Rain showers: moderate (+15%)
1.30,  # Rain showers: violent (+30%)
1.25,  # Snow showers: slight (+25%)
1.45,  # Snow showers: heavy (+45%)
1.35,  # Thunderstorm (+35%)
1.60,  # Thunderstorm w/ slight hail (+60%)
2.0    # Thunderstorm w/ heavy hail (+100%)
),
  
carbon_multiplier = c(
1.00,  # Clear sky
1.01,  # Mainly clear (+1%)
1.03,  # Partly cloudy (+3%)
1.05,  # Overcast (+5%)
1.12,  # Fog (+12%)
1.15,  # Rime fog (+15%)
1.07,  # Drizzle: light (+7%)
1.10,  # Drizzle: moderate (+10%)
1.15,  # Drizzle: dense (+15%)
1.22,  # Freezing drizzle: light (+22%)
1.35,  # Freezing drizzle: dense (+35%)
1.08,  # Rain: slight (+8%)
1.12,  # Rain: moderate (+12%)
1.20,  # Rain: heavy (+20%)
1.28,  # Freezing rain: light (+28%)
1.45,  # Freezing rain: heavy (+45%)
1.15,  # Snow fall: slight (+15%)
1.25,  # Snow fall: moderate (+25%)
1.40,  # Snow fall: heavy (+40%)
1.20,  # Snow grains (+20%)
1.10,  # Rain showers: slight (+10%)
1.15,  # Rain showers: moderate (+15%)
1.30,  # Rain showers: violent (+30%)
1.25,  # Snow showers: slight (+25%)
1.40,  # Snow showers: heavy (+40%)
1.35,  # Thunderstorm (+35%)
1.55,  # Thunderstorm w/ slight hail (+55%)
1.80   # Thunderstorm w/ heavy hail (+80%)
),

# Bridge Weight Restrictions (FHWA Load Rating Manual)
bridge_weight_limit = c(
1.00, 1.00, 0.98, 0.95, 0.90, 0.85, 0.92, 0.88, 0.82, 0.75, 0.60,
0.93, 0.87, 0.78, 0.65, 0.50, 0.85, 0.72, 0.55, 0.80, 0.91, 0.86,
0.60, 0.70, 0.45, 0.68, 0.40, 0.30
),
  
# Toll Multipliers (IBTTA 2023 Storm Surcharge Index)
toll_multiplier = c(
1.00, 1.00, 1.05, 1.07, 1.15, 1.25, 1.10, 1.15, 1.22, 1.35, 2.00,
1.12, 1.18, 1.30, 1.45, 1.80, 1.20, 1.35, 1.60, 1.25, 1.13, 1.20,
1.70, 1.40, 2.10, 1.55, 2.30, 3.00
),
  
# Border Crossing Delays (CBP TRIP Data)
border_delay_hours = c(
0.0, 0.0, 0.5, 0.7, 1.2, 2.0, 0.8, 1.1, 1.8, 2.5, 6.0,
0.9, 1.3, 2.2, 3.5, 8.0, 1.5, 2.8, 5.0, 1.7, 1.0, 1.5,
4.0, 2.5, 7.0, 3.0, 9.0, 12.0
),
  
# API Endpoints
reroute_api = c(
NA_character_,  # Clear sky
NA_character_,  # Mainly clear
"HERE Weather API v3",  # Partly cloudy
"HERE Weather API v3",  # Overcast
"FHWA ARCHIS Live",  # Fog
"FHWA ARCHIS Live",  # Rime fog
"Google Maps Directions",  # Drizzle
"Google Maps Directions",  # Drizzle
"Google Maps Directions",  # Drizzle
"FMCSA SMS API",  # Freezing drizzle
"FMCSA SMS API",  # Freezing drizzle
"USDOT NTAD",  # Rain
"USDOT NTAD",  # Rain
"USDOT NTAD",  # Rain
"FMCSA SMS API",  # Freezing rain
"FMCSA SMS API",  # Freezing rain
"FHWA RWIS",  # Snow
"FHWA RWIS",  # Snow
"FHWA RWIS",  # Snow
"USGS Streamflow",  # Snow grains
"NOAA NOWData",  # Rain showers
"NOAA NOWData",  # Rain showers
"USGS Flood Events",  # Rain showers violent
"FHWA CCAP",  # Snow showers
"FHWA CCAP",  # Snow showers
"NWS CAP Alerts",  # Thunderstorm
"NWS CAP Alerts",  # Thunderstorm hail
"DHS HSIN"  # Severe hail
)

)

create_enum_and_associate(
duckdb_con, 
"weather_code_enum", 
"WeatherCodeDictionary",
code_frame
)

```
:::

```{.r}
# Real-Time API Integration Function
get_reroute <- function(api_name, origin, destination, api_key) {
  base_urls <- list(
    "HERE Weather API v3" = "https://weather.ls.hereapi.com/weather/1.0/report.json",
    "FHWA ARCHIS Live" = "https://ops.fhwa.dot.gov/archis/rest/api/v1/route",
    "Google Maps Directions" = "https://maps.googleapis.com/maps/api/directions/json",
    "FMCSA SMS API" = "https://mobile.fmcsa.dot.gov/qc/services/carriers/",
    "USDOT NTAD" = "https://ntad-api.dot.gov/v1/route"
  )
  
  if (!api_name %in% names(base_urls)) {
    stop("API not configured")
  }
  
  response <- GET(
    url = base_urls[[api_name]],
    query = list(
      origin = paste(origin$lat, origin$lon, sep = ","),
      destination = paste(destination$lat, destination$lon, sep = ","),
      apikey = api_key
    )
  )
  
  if (http_status(response)$category == "Success") {
    return(content(response))
  } else {
    warning("API request failed: ", http_status(response)$reason)
    return(NULL)
  }
}

# Sample Usage
origin <- list(lat = 40.7128, lon = -74.0060)  # NYC
destination <- list(lat = 34.0522, lon = -118.2437)  # LA

# Get reroute during heavy snow
reroute_data <- code_frame |>
  filter(description == "Snow fall: heavy") |>
  pull(reroute_api) |>
  (\(x) get_reroute(x, origin, destination, Sys.getenv("DOT_API_KEY")))()

```




::: code-fold-flex
```{r}
#| label: "wcSetup"
#| code-summary: "table setup"

rTable <- tbl(duckdb_con, "WeatherCodeDictionary") |> collect()

locations_list = colnames(rTable)

notes_list <- list(
"WMO weather code (1-99). See WMO Publication No. 306 for official code definitions.",
"Plain-language weather condition description based on WMO standards.",
"Recommended trucking operational response per FMCSA §392.14 and industry best practices.",
"Numeric risk assessment (0-1 scale) where 0.7+ triggers DOT emergency protocols (§392.16).",
"Key FMCSA regulation sections requiring compliance during these conditions.",
"Categorical risk level: Low (<0.3), Moderate (0.3-0.5), High (0.5-0.7), Critical (0.7+).",
"Percentage increase to cargo insurance premiums during these conditions. Based on TTClub 2023 claims data.",
"Fuel consumption multiplier (1.0 = baseline). Accounts for reduced MPG in adverse conditions (EPA SmartWay data).",
"Expected delay multiplier for route planning (1.0 = no delay). Derived from FHWA Highway Performance Monitoring System.",
"FMCSA §396.11-13 mandated inspection protocols. 'Continuous monitoring' requires ELD-integrated systems.",
"Teamsters National Master Freight Agreement Article 38 hazard pay provisions. Percentages added to base pay.",
"ATA Technology & Maintenance Council wear indices. 1.0 = baseline maintenance costs.",
"EPA SmartWay GHG emission factors. Includes idling, rerouting, and traction energy impacts.",
"FHWA LRFR bridge capacity multiplier (1.0 = 80k lbs standard). Based on NBI Condition Reports.",
"IBTTA inclement weather surcharge schedule. Applies to E-ZPass/Presto toll systems.",
"CBP Trade Relief Interface Program data: Average commercial lane delays at POE.",
"Official API endpoints for real-time routing. Requires agency credentials."
)

footnotes_df <- tibble(
  notes = notes_list, 
  locations = locations_list)

calc_distinct_obs <- code_frame |>
group_by(risk_score) |>
distinct() |>
length()

pal_df <- tibble(
  cols = locations_list,
  pals = list(eval_palette("grDevices::RdYlGn", calc_distinct_obs, 'c', -1))
  #pals = list(eval_palette("basetheme::brutal", 7, 'd', 1))
)

rTable <- r_table_theming(
rTable,
title = "Weather Code: As Data Type",
subtitle = NULL,
footnotes_df,
source_note = md("**source**: World Meteorlogical Organization"),
pal_df,
multiline_feet = TRUE,
table_font_size = pct(85),
target_everything = TRUE,
color_by_columns = "risk_score",
#row_name_col = "Model"
)

```
:::

@noaa_wmo_2025

::::: {#codeTable}
:::: skinny-tables
::: table-flex
```{r}
#| label: "tbl-wc"
#| echo: false
#| tbl-cap: "How the WMO codes are\n associated to weather events."

rTable |>
opt_css(
css = '
#codeTable .gt_table_body td.gt_row {
box-shadow: -1px 0px 1px 0px rgba(255, 255, 255, 0.2) inset,
     1px 0px 1px 0px rgba(0, 0, 0, 0.2) inset;
} 
',
#add = FALSE
)

```
:::
::::
:::::

::: code-fold-flex
```{sql}
#| connection: duckdb_con

-- Create ENUM for wind direction
CREATE TYPE cardinal_direction_enum AS ENUM (
     'N', 
     'NE', 
     'E', 
     'SE', 
     'S', 
     'SW', 
     'W', 
     'NW'
);

CREATE TYPE month_name_enum AS ENUM (
     'January', 
     'February', 
     'March', 
     'April', 
     'May',
     'June', 
     'July', 
     'August', 
     'September', 
     'October', 
     'November', 
     'December'
);

CREATE TYPE month_abb_enum AS ENUM (
     'Jan', 
     'Feb', 
     'Mar', 
     'Apr', 
     'May',
     'Jun', 
     'Jul', 
     'Aug', 
     'Sep', 
     'Oct', 
     'Nov', 
     'Dec'
);

CREATE TYPE weekday_name_enum AS ENUM (
     'Sunday', 
     'Monday', 
     'Tuesday', 
     'Wednesday', 
     'Thursday', 
     'Friday', 
     'Saturday'
);

CREATE TYPE weekday_abb_enum AS ENUM (
     'Sun', 
     'Mon', 
     'Tue', 
     'Wed', 
     'Thu', 
     'Fri', 
     'Sat'
);

CREATE TYPE visibility_cat_enum AS ENUM (
     'Clearest (>30 km)', 
     'Excellent (10-30 km)', 
     'Good (5-10 km)', 
     'Moderate (2-5 km)', 
     'Low (1-2 km)', 
     'Fog/Haze (<1 km)'
  );
  
CREATE TYPE speed_bin_enum AS ENUM (
     '0-2', 
     '2-4', 
     '4-6', 
     '6-8', 
     '8-10', 
     '10+'
     );

```
:::

## Transformation with Validation

Stages:

-   **Cleaning** (numeric formatting, type casting)

-   **Feature engineering** (wind bins, direction calculations)

-   **Temporal decomposition** (date/time elements extraction)

-   **Categorical labeling** (visibility categories, enum mapping)

![Transformation](pako_eNp1lOFvojAYxv-VpvviJegEBIRczI0i35ZcduYuObkPBV61WWlJqdmc-r-vgDq3nJCQtM_T5_e2pd3jQpaAI7zi8qXYUKXRIs4Eap-HH3tOc-ARyvATfUEJ1TTDFmo2tIYIlfkRDYczFC8HhAMVUHaOb_9Ow-NOJcvBQlHRrKSqvjpI50iWg5QJyj9rHyGj4ezwJLeivCe00QcU21d1LaCqQVG9VWB9z9X97KeCgtVMU82k6Lt-s4.svg){style="height: 50%" fig-align="center" width="336"}

### Dataset: Forecast, Next Day

::: p-1
Creating a view for transformations is generally considered a safer approach and aligns with modern data engineering best practices. Views function as virtual tables that compute results on-the-fly, eliminating the need to store intermediate data and reducing the risk of corrupting the source data. By leveraging views, one can iteratively refine transformations without the need to rewrite tables, allowing for adjustments and improvements to the logic as required. This approach provides flexibility and helps the transformation process to remain adaptable to changing requirements.

Furthermore, DuckDB optimizes queries against views by pushing down computations, which enhances performance and efficiency. Views also serve as self-documenting transformation pipelines, offering clarity and transparency into the decision logic. This makes it easier for others to understand, maintain, and collaborate on the data workflow. By adopting this method, one works towards ensuring a scalable, efficient, and transparent data processing system, supporting both current and future analytical needs.
:::

::: code-fold-flex
```{sql}
#| label: forecastTransformation
#| connection: duckdb_con
#| code-summary: Modular SQL, in-database transformation
#| code-fold: show

-- Create or replace the view with modular CTE's and explicit column lists
CREATE OR REPLACE VIEW transformed_forecast AS
WITH cleaned_data AS (
  SELECT
    date,
    ROUND(temperature_2m::FLOAT, 1) AS temperature_2m,
    precipitation_probability,
    ROUND(precipitation::FLOAT, 3) AS precipitation,
    ROUND(rain::FLOAT, 3) AS rain,
    ROUND(showers::FLOAT, 3) AS showers,
    ROUND(snowfall::FLOAT, 3) AS snowfall,
    ROUND(snow_depth::FLOAT, 3) AS snow_depth,
    weather_code::INTEGER::TEXT::weather_code_enum AS weather_code,
    ROUND(visibility::FLOAT, 1) AS visibility,
    ROUND(wind_speed_10m::FLOAT, 2) AS wind_speed_10m,
    wind_direction_10m,
    latitude,
    longitude
  FROM forecast_data
),

transformed_data AS (
  SELECT
    *,
    -- Speed bin
    CASE 
      WHEN wind_speed_10m <= 2 THEN CAST('0-2' AS speed_bin_enum)
      WHEN wind_speed_10m <= 4 THEN CAST('2-4' AS speed_bin_enum)
      WHEN wind_speed_10m <= 6 THEN CAST('4-6' AS speed_bin_enum)
      WHEN wind_speed_10m <= 8 THEN CAST('6-8' AS speed_bin_enum)
      WHEN wind_speed_10m <= 10 THEN CAST('8-10' AS speed_bin_enum)
      ELSE CAST('10+' AS speed_bin_enum)
    END AS speed_bin,
    -- Cardinal direction
    CASE 
      WHEN wind_direction_10m BETWEEN 0 AND 22.5 THEN CAST('N' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 22.5 AND 67.5 THEN CAST('NE' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 67.5 AND 112.5 THEN CAST('E' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 112.5 AND 157.5 THEN CAST('SE' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 157.5 AND 202.5 THEN CAST('S' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 202.5 AND 247.5 THEN CAST('SW' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 247.5 AND 292.5 THEN CAST('W' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 292.5 AND 337.5 THEN CAST('NW' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 337.5 AND 360 THEN CAST('N' AS cardinal_direction_enum)
      ELSE NULL
    END AS wind_direction_cardinal,
    -- 15-degree direction bin (numeric)
    FLOOR((wind_direction_10m - 1e-9) / 15) * 15 AS direction_bin
  FROM cleaned_data
),

final_data AS (
  SELECT
    *,
    -- Direction angle
    CASE
      WHEN wind_direction_cardinal = 'N' THEN 0
      WHEN wind_direction_cardinal = 'NE' THEN 45
      WHEN wind_direction_cardinal = 'E' THEN 90
      WHEN wind_direction_cardinal = 'SE' THEN 135
      WHEN wind_direction_cardinal = 'S' THEN 180
      WHEN wind_direction_cardinal = 'SW' THEN 225
      WHEN wind_direction_cardinal = 'W' THEN 270
      WHEN wind_direction_cardinal = 'NW' THEN 315
      ELSE NULL
    END AS direction_angle,
    -- Visibility category
    CASE
      WHEN visibility > 30000 THEN CAST('Clearest (>30 km)' AS visibility_cat_enum)
      WHEN visibility > 10000 THEN CAST('Excellent (10-30 km)' AS visibility_cat_enum)
      WHEN visibility > 5000 THEN CAST('Good (5-10 km)' AS visibility_cat_enum)
      WHEN visibility > 2000 THEN CAST('Moderate (2-5 km)' AS visibility_cat_enum)
      WHEN visibility > 1000 THEN CAST('Low (1-2 km)' AS visibility_cat_enum)
      WHEN visibility <= 1000 THEN CAST('Fog/Haze (<1 km)' AS visibility_cat_enum)
      ELSE NULL
    END AS visibility_category,
    -- Date parts
    strftime(date, '%d-%m-%Y') AS date_only,
    EXTRACT(YEAR FROM date) AS year,
    EXTRACT(MONTH FROM date) AS month,
    monthname(date)::month_name_enum AS month_name,
    strftime(date, '%b')::month_abb_enum AS month_abb,
    EXTRACT(DAY FROM date) AS day,
    dayname(date)::weekday_name_enum AS weekday_name,
    strftime(date, '%a')::weekday_abb_enum AS weekday_abb,
    strftime(date, '%b %d') AS month_day,
    strftime(date, '%H:%M:%S') AS time_only,
    strptime('1970-01-01 ' || strftime(date, '%H:%M:%S'), '%Y-%m-%d %H:%M:%S') AS common_date
  FROM transformed_data
)

-- Final output
SELECT * FROM final_data;
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
#| output.var: viewOfForecast
SELECT * FROM transformed_forecast;
```
:::

::: code-fold-flex
```{r}
#| label: 'forecast_data_setup'
#| code-summary: "table setup"

r_df <- viewOfForecast |>
dplyr::mutate(
     date = as.character(date),
     common_date = as.character(common_date)
)

locations_list = colnames(r_df)

notes_list <-c(
  "Date of the recorded data.",
  "Temperature at 2 meters above ground.",
  "Probability of precipitation.",
  "Amount of precipitation.",
  "Amount of rain.",
  "Amount of showers.",
  "Amount of snowfall.",
  "Depth of snow.",
  "Code representing the weather condition.",
  "Visibility distance.",
  "Wind speed at 10 meters above ground.",
  "Wind direction at 10 meters above ground.",
  "Vertical location coordinate.", 
  "Horizontal location coordinate.",
  "Binned categories for wind speed.",
  "Cardinal direction of the wind.",
  "Binned categories for wind direction.",
  "Numeric angle representing wind direction.",
  "Categorized visibility levels.",
  "Date without time",
  "Year extracted from the date.",
  "Month extracted from the date.",
  "Name of the month.",
  "Abbreviated name of the month.",
  "Day extracted from the date.",
  "Name of the weekday.",
  "Abbreviated name of the weekday.",
  "Combined month and day.",
  "Time extracted from the date.",
  "Common date format for time-based analysis."
)

footnotes_df <- tibble(
  notes = notes_list, 
  locations = locations_list
)

pal_df <- tibble(
  cols = locations_list,
  pals = list(eval_palette("grDevices::Rocket", 10 , 'c', 1))
)

rTable <- r_table_theming(
r_df,
title = "Forecast Data Preview",
subtitle = NULL,
footnotes_df,
source_note = md("**source**: "),
pal_df,
footnotes_multiline = FALSE,
table_font_size = pct(70),
#do_col_labels = TRUE,
)

```
:::

::::: {#three}
:::: large-tables
::: table-flex
```{r}
#| label: "tbl-viewOfForecast"
#| echo: false
#| column: screen-inset
rTable |>
opt_css(
css = '
#three .gt_table_body td.gt_row {
box-shadow: -1px 0px 1px 0px rgba(255, 255, 255, 0.2) inset,
     1px 0px 1px 0px rgba(0, 0, 0, 0.2) inset;
} 
',
#add = FALSE
)
```
:::
::::
:::::

::: code-fold-flex
```{sql}
#| label: replaceForecastData
#| code-summary: Replace the forecast_data table; optionally, create an output preview object.
#| connection: duckdb_con
#| output.var: table_forecast

-- Replace the historical weather table
CREATE OR REPLACE TABLE forecast_data AS
SELECT * FROM transformed_forecast;

-- Preview results 
SELECT * FROM forecast_data LIMIT 10;
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
DROP VIEW transformed_forecast;
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
ANALYZE forecast_data;
```
:::

### Dataset: Historical, 1974-2024

```{r}
#| label: "preValidationHistorical"
#| code-summary: "Pre-Transformation Validation (Raw Data)"
#| code-fold: true

# Using existing DuckDB connection
raw_data <- tbl(duckdb_con, "historical_data")

# Create validation agent for raw data
raw_agent <- create_agent(tbl = raw_data,
                          actions = action_levels(warn_at = 0.01, stop_at = 0.05)) |>
     # Core structure validation
     col_exists(
          vars(
               date,
               temperature_2m,
               precipitation,
               rain,
               snowfall,
               snow_depth,
               weather_code,
               wind_speed,
               wind_direction
          )
     ) |>
     col_is_date(vars(date)) |>
     # Value range checks
     col_vals_between(vars(temperature_2m), -50, 130, na_pass = TRUE) |>
     col_vals_gte(vars(precipitation), 0, na_pass = TRUE) |>
     
     # Add valid codes
     col_vals_in_set(vars(weather_code), set = codes) |> 
     
     col_vals_between(vars(wind_direction_10m), 0, 360, na_pass = TRUE) |>
     
     interrogate()

```

::: column-screen-inset
```{r}
#| label: "outputRawAgent"
#| echo: false
raw_agent 
```
:::

::: code-fold-flex
```{sql}
#| label: historicalTransform
#| connection: duckdb_con
#| code-summary: Modular SQL, in-database transformation
#| code-fold: show

-- Create or replace the view with modular CTEs and explicit column lists
CREATE OR REPLACE VIEW transformed_historical AS
WITH cleaned_data AS (
  SELECT
    date,
    ROUND(temperature_2m::FLOAT, 1) AS temperature_2m,
    ROUND(precipitation::FLOAT, 3) AS precipitation,
    ROUND(rain::FLOAT, 3) AS rain,
    ROUND(snowfall::FLOAT, 3) AS snowfall,
    ROUND(snow_depth::FLOAT, 3) AS snow_depth,
    weather_code::INTEGER::TEXT::weather_code_enum AS weather_code,
    ROUND(wind_speed_10m::FLOAT, 2) AS wind_speed_10m,
    wind_direction_10m,
    latitude,
    longitude
  FROM historical_data
),

transformed_data AS (
  SELECT
    *,
    -- Speed bin
    CASE 
      WHEN wind_speed_10m <= 2 THEN CAST('0-2' AS speed_bin_enum)
      WHEN wind_speed_10m <= 4 THEN CAST('2-4' AS speed_bin_enum)
      WHEN wind_speed_10m <= 6 THEN CAST('4-6' AS speed_bin_enum)
      WHEN wind_speed_10m <= 8 THEN CAST('6-8' AS speed_bin_enum)
      WHEN wind_speed_10m <= 10 THEN CAST('8-10' AS speed_bin_enum)
      ELSE CAST('10+' AS speed_bin_enum)
    END AS speed_bin,
    -- Cardinal direction
    CASE 
      WHEN wind_direction_10m BETWEEN 0 AND 22.5 THEN CAST('N' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 22.5 AND 67.5 THEN CAST('NE' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 67.5 AND 112.5 THEN CAST('E' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 112.5 AND 157.5 THEN CAST('SE' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 157.5 AND 202.5 THEN CAST('S' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 202.5 AND 247.5 THEN CAST('SW' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 247.5 AND 292.5 THEN CAST('W' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 292.5 AND 337.5 THEN CAST('NW' AS cardinal_direction_enum)
      WHEN wind_direction_10m BETWEEN 337.5 AND 360 THEN CAST('N' AS cardinal_direction_enum)
      ELSE NULL
    END AS wind_direction_cardinal,
    -- 15-degree direction bin (numeric)
    FLOOR((wind_direction_10m - 1e-9) / 15) * 15 AS direction_bin
  FROM cleaned_data
),

final_data AS (
  SELECT
    *,
    -- Direction angle
    CASE
      WHEN wind_direction_cardinal = 'N' THEN 0
      WHEN wind_direction_cardinal = 'NE' THEN 45
      WHEN wind_direction_cardinal = 'E' THEN 90
      WHEN wind_direction_cardinal = 'SE' THEN 135
      WHEN wind_direction_cardinal = 'S' THEN 180
      WHEN wind_direction_cardinal = 'SW' THEN 225
      WHEN wind_direction_cardinal = 'W' THEN 270
      WHEN wind_direction_cardinal = 'NW' THEN 315
      ELSE NULL
    END AS direction_angle,
    -- Date parts
   strftime(date, '%d-%m-%Y') AS date_only,
    EXTRACT(YEAR FROM date) AS year,
    EXTRACT(MONTH FROM date) AS month,
    monthname(date)::month_name_enum AS month_name,
    strftime(date, '%b')::month_abb_enum AS month_abb,
    EXTRACT(DAY FROM date) AS day,
    dayname(date)::weekday_name_enum AS weekday_name,
    strftime(date, '%a')::weekday_abb_enum AS weekday_abb,
    strftime(date, '%b %d') AS month_day,
    strftime(date, '%H:%M:%S') AS time_only,
    strptime('1970-01-01 ' || strftime(date, '%H:%M:%S'), '%Y-%m-%d %H:%M:%S') AS common_date
  FROM transformed_data
)

-- Final output
SELECT * FROM final_data;
```
:::

```{r}
#| label: "postTransformHistorical"
#| code-summary: "Post-Transformation Validation"
#| code-fold: true

transformed_data <- tbl(duckdb_con, "transformed_historical")

trans_agent <- create_agent(
     tbl = transformed_data, label = "Post-Transformed Validation", actions = action_levels(warn_at = 0.01, stop_at = 0.05)
) |>
     # Validate enum mappings
     col_is_factor(vars(weather_code, speed_bin, wind_direction_cardinal)) |>
     
     # Validate temperature decimal places (simpler arithmetic check)
     col_vals_expr(
          expr = ~ MOD(temperature_2m * 10, 1) == 0,
          label = "Temperature has 1 decimal place",
          #na_pass = TRUE  # Skip NA values automatically
     ) |>

     # Validate speed bin logic
     col_vals_in_set(vars(speed_bin), set = c("0-2", "2-4", "4-6", "6-8", "8-10", "10+")) |>
     
     # Date validations
     col_vals_between(vars(year), 1974, 2024) |>
     col_vals_between(vars(month), 1, 12) |>
     col_vals_between(vars(day), 1, 31) |>
     
     # Month/weekday validations
     col_vals_in_set(vars(month_name), set = month.name) |>
     col_vals_in_set(vars(month_abb), set = month.abb) |>
     col_vals_in_set(
          vars(weekday_name),
          set = c(
               "Sunday",
               "Monday",
               "Tuesday",
               "Wednesday",
               "Thursday",
               "Friday",
               "Saturday"
          )
     ) |>
     col_vals_in_set(vars(weekday_abb),
                     set = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")) |>
     
     # Alternative month_day validation
     col_vals_expr(
          expr = ~ month_day == sql("STRFTIME(date, '%b %d')"),
          label = "Month/day format matches date"
     ) |>
     
     # Alternative time_only validation
     col_vals_expr(
          expr = ~ time_only == sql("STRFTIME(date, '%H:%M:%S')"),
          label = "Time format matches date"
     ) |>

     # Common date validation
     col_is_date(vars(common_date)) |>
     col_vals_between(
          vars(common_date),
          left = as.POSIXct("1970-01-01 00:00:00"),
          right = as.POSIXct("1970-01-01 23:59:59")
     ) |>
     
     # Wind direction validations
     col_vals_between(vars(direction_angle), 0, 315, na_pass = TRUE) |>
     col_vals_in_set(vars(wind_direction_cardinal),
                     set = c("N", "NE", "E", "SE", "S", "SW", "W", "NW")) |>
     
     # Cross-validations using SQL expressions
     col_vals_expr(
          expr = ~ time_only == sql("STRFTIME(common_date, '%H:%M:%S')"),
          label = "Time matches common_date"
     ) |>
     
     col_vals_expr(
          expr = ~ month_name == sql(
               "CASE month
                WHEN 1 THEN 'January' WHEN 2 THEN 'February'
                WHEN 3 THEN 'March' WHEN 4 THEN 'April'
                WHEN 5 THEN 'May' WHEN 6 THEN 'June'
                WHEN 7 THEN 'July' WHEN 8 THEN 'August'
                WHEN 9 THEN 'September' WHEN 10 THEN 'October'
                WHEN 11 THEN 'November' WHEN 12 THEN 'December' END"
          ),
          label = "Month name matches month number"
     ) |>
     
     col_vals_expr(expr = ~ weekday_abb == sql("SUBSTR(weekday_name, 1, 3)"),
                   label = "Weekday abbreviation matches name") |>
     
     interrogate()
```

::: column-screen-inset
```{r}
#| label: "transAgent"
#| echo: false
trans_agent
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
#| output.var: viewOfHistorical

-- Final output
SELECT * FROM transformed_historical LIMIT 20;
```
:::

::: code-fold-flex
```{r}
#| label: 'historical_data_setup'
#| code-summary: "table setup"

r_df <- viewOfHistorical |>
dplyr::mutate(
     date = as.character(date),
     common_date = as.character(common_date)
)

locations_list = colnames(r_df)

notes_list <- c(
"Date of the recorded data.",
"Temperature at 2 meters above ground.",
"Amount of precipitation.",
"Amount of rain.",
"Amount of snowfall.",
"Depth of snow.",
"Code representing the weather condition.",
"Wind speed at 10 meters above ground.",
"Wind direction at 10 meters above ground.",
"Vertical location coordinate.",
"Horizontal location coordinate.",
"Binned categories for wind speed.",
"Cardinal direction of the wind.",
"Binned categories for wind direction.",
"Numeric angle representing wind direction.",
"Date without time",
"Year extracted from the date.",
"Month extracted from the date.",
"Name of the month.",
"Abbreviated name of the month.",
"Day extracted from the date.",
"Name of the weekday.",
"Abbreviated name of the weekday.",
"Combined month and day.",
"Time extracted from the date.",
"Common date format for time-based analysis."
)

footnotes_df <- tibble(
  notes = notes_list, 
  locations = locations_list
)

pal_df <- tibble(
  cols = locations_list,
  pals = list(eval_palette("grDevices::Rocket", 10 , 'c', 1))
)

rTable <- r_table_theming(
r_df,
title = "Historical Data Preview",
subtitle = NULL,
footnotes_df,
source_note = md("**source**: "),
pal_df,
footnotes_multiline = FALSE,
table_font_size = pct(70),
#do_col_labels = TRUE,
)

```
:::

::::: {#four}
:::: large-tables
::: table-flex
```{r}
#| label: "tbl-viewOfHistorical"
#| echo: false
#| column: screen-inset
rTable |>
opt_css(
css = '
#four .gt_table_body td.gt_row {
box-shadow: -1px 0px 0px 0px rgba(255, 255, 255, 0.2) inset,
     1px 0px 0px 0px rgba(0, 0, 0, 0.2) inset;
} 
',
#     add = FALSE
)
```
:::
::::
:::::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
#| code-summary: Replace the historical weather table
CREATE OR REPLACE TABLE historical_data AS
SELECT * FROM transformed_historical;
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
#| code-summary: "Drop the view"
DROP VIEW transformed_historical;
```
:::

::: code-fold-flex
```{sql}
#| connection: duckdb_con
#| label: "analyzeHistoricalTable"
#| code-summary: Refresh database statistics for the query planner
ANALYZE historical_data;
```
:::


## Stats

```{sql}
#| connection: duckdb_con
#| output.var: list_of_db_tables
#| label: createListOfTables
SHOW ALL TABLES;
```


```{sql}
#| connection: duckdb_con
#| output.var: describe_table
#| label: describeTable
SHOW forecast_data;
```

```{sql}
#| connection: duckdb_con
#| output.var: summarize_table
#| label: summarizeTable
SUMMARIZE forecast_data;
```



## Forecast Plot Testing

::: code-fold-flex
```{r}
#| label: "makePlotList"
#| code-summary: "Create a plot list for wind roses"
#| warning: false
#| error: false

base_path = "data/plots/"

plot_wind_rose_ggplot(duckdb_con)

fileList <-list.files(base_path, pattern = "^wind_rose")
```
:::

:::: flex-container
::: {#fig-weather layout="[[1,1,1], [1,1], [1, 1, 1]]" fig-cap="These are the grouped figures."}
```{r}
#| label: "fig-weather_codes"
#| lightbox: 
#|   group: weather
#|   description: "Simple weather codes for simple insights." 
#| fig-cap: "Weather Codes"
#| echo: false
#| warning: false
#| message: false
plot_weather_codes(duckdb_con)
```

```{r}
#| label: "fig-temperature_freezing"
#| lightbox: 
#|   group: weather
#|   description: "Temperature with freezing point indicators." 
#| fig-subcap: "Freezing/Non-Freezing Temperature"
#| echo: false
#| warning: false
#| message: false
plot_temperature_trend(duckdb_con)
```

```{r}
#| label: "fig-visibility_km"
#| lightbox: 
#|   group: weather
#|   description: "Visibility in kilometers." 
#| fig-cap: "Visibility (km)"
#| echo: false
#| warning: false
#| message: false
plot_visibility_heat(duckdb_con)
```

```{r}
#| label: "fig-visibility_categories"
#| lightbox: 
#|   group: 
#|   description: "Simple visiblity categories." 
#| fig-cap: "Visibility Categories"
#| echo: false
#| warning: false
#| message: false
plot_visibility_categorical_heat(duckdb_con)
```

```{r}
#| label: "fig-precipitation"
#| lightbox: 
#|   group: weather
#|   description: "Indicator for rain and or snowfall." 
#| fig-cap: "Precipitation (empty if no precipitation)"
#| echo: false
#| warning: false
#| message: false
plot_precipitation(duckdb_con)
```

```{r}
#| label: "fig-rose1"
#| echo: false
#| lightbox: 
#|   group: weather
#|   description: "Wind direction and speed." 
#| fig-cap: "Wind Rose1"
##| fig-align: center
#| out-height: 100%
#| out-width: 100%
display_a_plot(paste0(base_path, fileList[1]))
```

```{r}
#| label: "fig-rose2"
#| echo: false
#| lightbox: 
#|   group: weather
#|   description: "Wind direction and speed." 
#| fig-cap: "Wind Rose2"
##| fig-align: center
#| out-height: 100%
#| out-width: 100%

if(!is.na(fileList[2]) == TRUE) {
     display_a_plot(paste0(base_path, fileList[2]))
}

```

```{r}
#| label: "fig-rose3"
#| echo: false
#| lightbox: 
#|   group: weather
#|   description: "Wind direction and speed." 
#| fig-cap: "Wind Rose3"
##| fig-align: center
#| out-width: 100%

if(!is.na(fileList[3])) {
     display_a_plot(paste0(base_path, fileList[3]))
}
```
:::
::::

::: code-fold-flex
```{r}
#| label: "osrm"
#| code-summary: "Creates a linestring object for the map."
#| message: false
#| eval: false
#| include: false
#| echo: false

# R example (osmdata)
library(osmdata)
library(osrm)
library(sf)
library(FedData)
library(terra)
library(leaflet)

# stl regional freightway to walmart distribution center
route <- osrmRoute(
src = c(-90.189781, 38.627480), 
dst = c(-91.634422, 38.002338)
)

# write_sf(route, "route.geojson")  # Save for DuckDB?
```
:::

::: code-fold-flex
```{r}
#| label: "getSpatRaster"
#| code-summary: "Topological map data is retrieved, creating a SpatRaster object."
#| message: false
#| eval: false
#| include: false
#| echo: false


# Define the bounding box (min_lon, min_lat, max_lon, max_lat)
bbox <- st_bbox(
c(
xmin = -90.189781, 
ymin = 38.627480, 
xmax = -91.634422, 
ymax = 38.002338), 
crs = 4326)

# Convert to an sf polygon
route_area <- st_as_sfc(bbox)

route_area <- st_transform(route_area, 4326)

dem <- get_ned(template = route_area, label = "route_dem")
```
:::

::: {#fig-topography layout="[[1],[2],[3]]" fig-cap="Map figures"}
```{r}
#| label: "fig-route"
#| lightbox: 
#|   group: topograhy
#|   description: "Geometric route without map background." 
#| fig-cap: "Geometric route"
#| warning: false
#| error: false
#| eval: false
#| include: false
#| echo: false

plot(st_geometry(route))
```

```{r}
#| label: "fig-topo"
#| lightbox: 
#|   group: topograhy
#|   description: "Topological data" 
#| fig-cap: "Topological plot without route"
#| warning: false
#| error: false
#| eval: false
#| include: false
#| echo: false

plet(
dem, 
tiles = "OpenTopoMap", 
main = "Topographical\nElevation\n(DEM)"
)
```

```{r}
#| label: "fig-topoRoute"
#| lightbox: 
#|   group: topograhy
#|   description: "Route mapped to topological data" 
#| fig-cap: "Topological plot with route"
#| warning: false
#| error: false
#| out-width: 100%
#| column: screen
#| eval: false
#| include: false
#| echo: false


plet(
dem, 
tiles = "OpenTopoMap", 
main = "Topographical\nElevation\n(DEM)") |>
addPolylines(
data = route, 
color = "oldlace", 
weight = 2, 
opacity = 0.8
)
     
```
:::

# Disconnect From Databases

::: code-fold-flex
```{r}
#| label: "dbDisconnect"
#| code-summary: "Dereference memory from the in-memory database connections."
dbDisconnect(duckdb_con)
```
:::
