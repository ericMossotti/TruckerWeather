[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Route Assistant",
    "section": "",
    "text": "Can weather data help predict costs associated with routes?"
  },
  {
    "objectID": "index.html#purpose",
    "href": "index.html#purpose",
    "title": "Route Assistant",
    "section": "",
    "text": "Can weather data help predict costs associated with routes?"
  },
  {
    "objectID": "index.html#database-connections",
    "href": "index.html#database-connections",
    "title": "Route Assistant",
    "section": "Database Connections",
    "text": "Database Connections\n\n\n\nDuckDB\n\n\nEstablish a DuckDB, embedded database connection.duckdb_con &lt;- dbConnect(duckdb::duckdb(\n     config = list(max_memory = '24GB')), \":memory:\")"
  },
  {
    "objectID": "index.html#loading-custom-output-scripts",
    "href": "index.html#loading-custom-output-scripts",
    "title": "Route Assistant",
    "section": "Loading Custom Output Scripts",
    "text": "Loading Custom Output Scripts\nTables\n\n\ntable building# Table Theming Script ----\n#' @description\n#' This script provides functions to create and theme tables using the `gt` package.\n#' It includes options for customizing colors, footnotes, and other stylistic elements.\n#' \n# eval_palette ----\n#' @description\n#' A helper function to evaluate color palettes using the `paletteer` package.\n#' @param pal_name The name of the palette to evaluate.\n#' @param n The number of colors to generate (default is 10).\n#' @param pal_type The type of palette (\"c\" for continuous, \"d\" for discrete, or \"dynamic\" for dynamic palettes).\n#' @param direction The direction of the palette (e.g., 1 for normal, -1 for reversed).\n#' \n#' @return A vector of colors corresponding to the specified palette.\n#' \n#' @example\n#' \\dontrun{\n#' colors &lt;- eval_palette(\"ggsci::springfield_simpsons\", n = 5, pal_type = \"d\")\n#' }\n#' @export \neval_palette &lt;- function(pal_name, n = 10, pal_type, direction = NULL) {\n     if (pal_type == \"c\") {\n          return(paletteer_c(pal_name, n, direction))\n     } else if (pal_type == \"d\") {\n          return(paletteer_d(pal_name, n, direction))\n     } else if (pal_type == \"dynamic\") {\n          return(paletteer_dynamic(pal_name, n, direction))\n     }\n}\n\n# r_table_theming ----\n#' @description\n#' The main function to create and theme a table using the `gt` package.\n#' @details\n#' **Color Coding** Applies color palettes to specific columns or the entire table.\n#' **Footnotes** Adds footnotes to specific columns or locations in the table.\n#' **Column Labels** Customizes the appearance of column labels, including background colors.\n#' **Table Styling** Applies various styling options, such as borders, padding, and font weights.\n#' **Shadow Effects** Optionally adds shadow effects to table body cells.\n#'\n#' @param r_df The data frame to be converted into a table.\n#' @param title The title of the table.\n#' @param subtitle The subtitle of the table.\n#' @param footnotes_df A data frame containing footnotes and their locations.\n#' @param source_note A source note to be added at the bottom of the table.\n#' @param pal_df A data frame containing color palettes and columns to apply them to.\n#' @param color_by_columns Columns to apply color to (default is NULL).\n#' @param row_name_col The column to use as row names (default is NULL).\n#' @param do_col_labels Whether to apply custom styling to column labels (default is FALSE).\n#' @param target_everything Whether to apply color to all columns (default is FALSE).\n#' @param doBodyShadows Whether to apply shadow effects to table body cells (default is FALSE).\n#'\n#' @return A themed `gt` table object.\n#' \n#' @example \n#' \\dontrun{\n#'   data &lt;- data.frame(\n#'     Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n#'     Score = c(85, 92, 78)\n#'   )\n#'   pal_df &lt;- data.frame(\n#'     cols = list(\"Score\"),\n#'     pals = list(eval_palette(\"ggsci::springfield_simpsons\", n = 3, pal_type = \"d\"))\n#'   )\n#'   footnotes_df &lt;- data.frame(\n#'     notes = list(\"High score\"),\n#'     locations = list(\"Score\")\n#'   )\n#'   themed_table &lt;- r_table_theming(\n#'     r_df = data,\n#'     title = \"Student Scores\",\n#'     subtitle = \"Fall 2023\",\n#'     footnotes_df = footnotes_df,\n#'     source_note = \"Source: School Records\",\n#'     pal_df = pal_df,\n#'     do_col_labels = TRUE\n#'   )\n#'   themed_table\n#'  }\n#'  \n# r_table_theming ----\n# Main function to create and theme a table using the `gt` package.\n#' @export\nr_table_theming &lt;- function(r_df,\n                            title,\n                            subtitle,\n                            footnotes_df,\n                            source_note,\n                            pal_df,\n                            color_by_columns = NULL,\n                            row_name_col = NULL,\n                            do_col_labels = FALSE,\n                            target_everything = FALSE,\n                            doBodyShadows = FALSE,\n                            footnotes_multiline = TRUE,\n                            table_font_size = pct(100),\n                            multiline_feet = TRUE\n                            ) {\n     # Initialize the gt table\n     if(is.null(row_name_col)) {\n          # If no row name column is specified, create a basic gt table\n          r_table &lt;- gt(r_df)\n     } else {\n          # If a row name column is specified, use it as the row names in the table\n          r_table &lt;- gt(r_df, rowname_col = row_name_col)\n     }\n     \n     # Apply color coding to specific columns or the entire table\n     if (nrow(r_df) &gt; 1 && target_everything == FALSE) {\n          # Apply color palettes to specific columns defined in pal_df\n          r_table &lt;- seq_len(nrow(pal_df)) |&gt;\n               reduce(\\(acc, i) {\n                    data_color(acc,\n                               columns = pal_df$cols[[i]],  # Apply color to specified columns\n                               palette = pal_df$pals[[i]]   # Use the specified palette\n                    )\n               }, .init = r_table)  # Start with the initial table and accumulate changes\n     }\n     else if (nrow(r_df) &gt; 1 && target_everything == TRUE) {\n          # Apply color palettes to all columns\n          r_table &lt;- seq_len(nrow(pal_df)) |&gt;\n               reduce(\\(acc, i) {\n                    data_color(\n                         acc,\n                         columns = color_by_columns,  # Apply color to specified columns\n                         palette = pal_df$pals[[i]],  # Use the specified palette\n                         target_columns = everything()  # Apply color to all columns\n                    )\n               }, .init = r_table)  # Start with the initial table and accumulate changes\n     }\n     \n     # Add footnotes to the table\n     r_table &lt;- seq_len(nrow(footnotes_df)) |&gt;\n          reduce(\\(acc, i) {\n               tab_footnote(\n                    acc,\n                    footnote = footnotes_df$notes[[i]],  # Add the footnote text\n                    location = cells_column_labels(\n                         columns = footnotes_df$locations[[i]]),  # Specify the column for the footnote\n                    placement = \"auto\"  # Automatically place the footnote\n               )\n          }, .init = r_table)  # Start with the initial table and accumulate changes\n     \n     # Apply custom styling to column labels (if enabled)\n     if (ncol(r_df) &gt; 1 && do_col_labels == TRUE) {\n          cell_col_fills = pal_df$pals[[1]]  # Get the first palette for column labels\n          # Apply background colors to column labels\n          r_table &lt;- seq_len(nrow(pal_df)) |&gt;\n               reduce(\\(acc, i) {\n                    tab_style(\n                         acc,\n                         style = cell_fill(color = cell_col_fills[i]),  # Fill column labels with color\n                         locations = cells_column_labels(\n                              columns = pal_df$cols[[i]])  # Apply to specified columns\n                    )\n               }, .init = r_table)  # Start with the initial table and accumulate changes\n     }\n     \n     # Add a title and subtitle to the table\n     r_table &lt;- r_table |&gt;\n          tab_header(title = title, subtitle = subtitle)\n     \n     # Add a source note at the bottom of the table\n     r_table &lt;- r_table |&gt;\n          tab_source_note(source_note = source_note)\n     \n     # Apply general table styling options\n     r_table &lt;- r_table |&gt;\n          tab_options(\n               column_labels.padding = px(10),  # Add padding to column labels\n               column_labels.font.weight = \"bold\",  # Make column labels bold\n               column_labels.background.color = '#333',  # Set background color for column labels\n               column_labels.border.top.width = px(0),  # Remove top border for column labels\n               column_labels.border.bottom.color = 'black',  # Set bottom border color for column labels\n               column_labels.vlines.width = px(1),  # Set vertical line width for column labels\n               column_labels.border.lr.width = px(1),  # Set left/right border width for column labels\n               column_labels.border.bottom.width = px(0),  # Remove bottom border for column labels\n               column_labels.border.lr.color = 'black',  # Set left/right border color for column labels\n               column_labels.vlines.color = 'black',  # Set vertical line color for column labels\n               footnotes.padding = px(5),  # Add padding to footnotes\n               footnotes.background.color = '#222',  # Set background color for footnotes\n               footnotes.sep = \", \",  # Set separator for footnotes\n               footnotes.multiline = footnotes_multiline,  # Allow multiline footnotes (if enabled)\n               heading.padding = px(10),  # Add padding to the heading\n               heading.background.color = '#222',  # Set background color for the heading\n               heading.title.font.size = pct(125),  # Set font size for the title\n               heading.subtitle.font.size = pct(110),  # Set font size for the subtitle\n               heading.border.bottom.width = px(0),  # Remove bottom border for the heading\n               row.striping.include_table_body = TRUE,  # Enable row striping for the table body\n               row.striping.include_stub = TRUE,  # Enable row striping for the stub\n               row.striping.background_color = '#333',  # Set background color for striped rows\n               row_group.as_column = TRUE,  # Display row groups as columns\n               source_notes.background.color = '#222',  # Set background color for source notes\n               stub.border.width = px(0),  # Remove border for the stub\n               stub.font.weight = \"bolder\",  # Make stub text bolder\n               table.margin.left = px(1),  # Set left margin for the table\n               table.margin.right = px(1),  # Set right margin for the table\n               table.align = \"center\",  # Center-align the table\n               table.border.top.width = px(0),  # Remove top border for the table\n               table.border.bottom.width = px(0),  # Remove bottom border for the table\n               table.background.color = '#222',  # Set background color for the table\n               table.font.size = table_font_size,  # Set font size for the table\n               table.layout = \"auto\",  # Use automatic table layout\n               table_body.hlines.color = 'black',  # Set horizontal line color for the table body\n               table_body.hlines.width = px(0),  # Remove horizontal lines in the table body\n               table_body.vlines.width = px(0),  # Remove vertical lines in the table body\n               table_body.border.bottom.color = 'black',  # Set bottom border color for the table body\n               table_body.border.top.color = 'black',  # Set top border color for the table body\n               table_body.border.bottom.width = px(0),  # Remove bottom border for the table body\n               table_body.border.top.width = px(0),  # Remove top border for the table body\n          )\n     \n     return(r_table)\n}\n\n\n\nPlots\n\n\nplot theming#  Plot output script ----\n# normal axes ----\nggplot_theming &lt;- function(...) {\n     base_theme &lt;- theme_minimal() +\n          theme(\n               axis.title = element_text(\n                    color = 'gray100',\n                    margin = margin(5, 5, 5, 5, \"pt\")\n               ),\n               axis.title.x = element_text(margin = margin(10, 10, 10, 10, \"pt\"), face = \"bold\"),\n               axis.title.y = element_text(\n                    face = \"bold\",\n                    size = rel(1),\n                    margin = margin(5, 5, 5, 5, \"pt\")\n               ),\n               axis.text = element_text(color = 'gray', margin = margin(5, 5, 5, 5, \"pt\")),\n               axis.text.x = element_text(),\n               axis.text.y = element_text(margin = margin(0, 5, 0, 5, \"pt\")),\n               axis.text.x.top = element_text(vjust = 0.5),\n               line = element_line(color = '#222'),\n               legend.background = element_rect(fill = '#222'),\n               legend.position = \"bottom\",\n               legend.text = element_text(color = 'gray', size = rel(0.7)),\n               legend.title = element_text(color = 'white', size = rel(1.0)),\n               panel.background = element_rect(fill = '#222',\n                                               linewidth = 0),\n               panel.grid.major.x = element_line(linetype = 'solid', color = 'black'),\n               panel.grid.minor.x = element_line(linetype = \"dotted\", color = 'black'),\n               panel.grid.major.y = element_line(\n                    linetype = 'solid',\n                    color = 'black',\n                    linewidth = .2\n               ),\n               panel.grid.minor.y = element_line(linetype = 'dotted', color = 'black'),\n               plot.title = element_text(\n                    face = \"bold\",\n                    color = 'white',\n                    size = rel(1.5)\n               ),\n               plot.background = element_rect(fill = '#222',\n                                              linewidth = 0),\n               plot.caption = element_text(\n                    size = 10,\n                    color = \"gray80\",\n                    margin = margin(5, 2, 5, 2),\n                    hjust = 0\n               ),\n               plot.margin = margin(10, 10, 10, 10, \"pt\"),\n               strip.background = element_rect(fill = 'gray20'),\n               strip.text = element_text(size = rel(0.8), \n                                         margin = margin(0, 0, 0, 0, \"pt\"),\n                                         color = 'cornsilk'),\n               #strip.text.y = element_text(color = \"black\"),\n              # strip.text.x = element_text(color = \"ivory\", face = \"plain\"),\n               text = element_text(size = 12)\n          )\n     \n     base_theme + theme(...)\n}\n\n# flipped axes ----\nggplot_theming_flipped_axes &lt;- function(...) {\n     base_theme &lt;- theme_minimal() +\n          theme(\n               axis.title = element_text(color = 'gray100'),\n               axis.text = element_text(color = 'gray'),\n               panel.background = element_rect(fill = '#222'),\n               panel.grid.major.x = element_line(linetype = 'dashed'),\n               panel.grid.minor.x = element_line(linetype = \"dotted\"),\n               panel.grid.major.y = element_line(linetype = 'solid'),\n               panel.grid.minor.y = element_line(linetype = 'dotted'),\n               plot.title = element_text(color = 'white', size = rel(2)),\n               plot.background = element_rect(fill = '#222'),\n               legend.background = element_rect(fill = '#222'),\n               legend.text = element_text(color = 'gray'),\n               legend.title = element_text(color = 'white')\n          )\n     \n     base_theme + theme(...)\n     \n}\n\n\n\n\n\nplot building# Load necessary libraries\nlibrary(DBI)          # For database connectivity\nlibrary(ggplot2)      # For creating plots\nlibrary(scales)       # For scaling and formatting axes\nlibrary(openair)      # For specialized plots like wind roses\nsource(\"./scripts/Output/Plots/plot_themer.R\")  # Custom theme for ggplot\n\n# Helper function to execute a query and return the result\nexecute_query &lt;- function(con, query) {\n     dbGetQuery(con, query)  # Execute the SQL query and return the result\n}\n\n\nplot_temperature_trend &lt;- function(con, freezing_threshold = 32) {\n     # Query to fetch temperature data for the day\n     query &lt;- \"\n    SELECT\n      temperature_2m,\n      time_only,\n      common_date,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Calculate bar width based on time intervals\n     if (nrow(data) &gt; 1) {\n          time_diff &lt;- as.numeric(difftime(data$common_date[2], data$common_date[1], units = \"secs\"))\n     } else {\n          time_diff &lt;- 3600  # Default to 1 hour if only one data point\n     }\n     half_width &lt;- time_diff / 2\n     \n     # Prepare data for rectangular columns\n     data &lt;- data %&gt;%\n          arrange(common_date) %&gt;%\n          mutate(\n               xmin = common_date - half_width,\n               xmax = common_date + half_width,\n               fill_group = ifelse(temperature_2m &gt; freezing_threshold, \"above freezing\", \"below freezing\"),\n               ymin = ifelse(temperature_2m &gt; freezing_threshold, freezing_threshold, temperature_2m),\n               ymax = ifelse(temperature_2m &gt; freezing_threshold, temperature_2m, freezing_threshold)\n          )\n     \n     # Create a ggplot object for temperature trend\n     rPlot &lt;- ggplot(data, aes(x = common_date, y = temperature_2m)) +\n          geom_rect(\n               aes(\n                    xmin = xmin,\n                    xmax = xmax,\n                    ymin = ymin,\n                    ymax = ymax,\n                    fill = fill_group\n               ),\n               color = 'black',\n               alpha = 0.5\n          ) +  # Column rectangles\n     #     geom_line(color = \"black\", size = 0.5) +  # Line plot for temperature\n          geom_hline(\n               yintercept = freezing_threshold,\n               linetype = \"dashed\",\n               color = \"lightblue\",\n               linewidth = 0.4\n          ) +  # Horizontal line for freezing threshold\n          labs(\n               title = \"Temperature Forecast\",\n               x = \"\",\n               y = \"¬∞ F\"\n          ) +  # Labels for the plot\n          scale_x_datetime(\n               labels = label_date(\"%l %p\"),\n               breaks = \"6 hours\",\n               minor_breaks = \"2 hours\",\n               guide = guide_axis(n.dodge = 1)\n          ) +  # Format x-axis for time\n          scale_y_continuous(sec.axis = dup_axis(name = \"\")) +  # Secondary y-axis\n          scale_fill_manual(\n               name = \"Freezing Indicators\",\n               values = c(\n                    \"above freezing\" = \"green\",\n                    \"below freezing\" = \"lightblue\"\n               )\n          ) +  # Manual color scale\n          facet_grid(~ month_day) +  # Facet by month_day\n          ggplot_theming()  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggTemperature.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n}\n\n# Precipitation and Probability ----\nplot_precipitation &lt;- function(con) {\n     # Query to fetch precipitation data\n     query &lt;- \"\n    SELECT\n      precipitation_probability,\n      precipitation,\n      rain,\n      snowfall,\n      time_only,\n      common_date,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Calculate scale factor for secondary y-axis\n     scale_factor &lt;- max(data$precipitation_probability, \n                         na.rm = TRUE) / max(data$rain, \n                                             data$snowfall, na.rm = TRUE)\n     \n     # Create a ggplot object for precipitation\n     rPlot &lt;- ggplot(data, aes(x = as.POSIXct(common_date))) +\n          geom_area(\n               aes(y = precipitation_probability, fill = \"Precipitation Probability\"),\n               #position = \"jitter\"\n               linewidth = 0.2\n          ) +  # Area plot for precipitation probability\n          geom_col(\n               aes(y = rain * scale_factor, fill = \"Rain (in.)\"),\n               #size = 1,\n               alpha = 0.3,\n               position = \"stack\",\n               #linetype = \"dashed\"\n          ) +  # Line plot for rain\n          geom_col(\n               aes(y = snowfall * scale_factor, fill = \"Snowfall (in.)\"),\n               #size = 1,\n               alpha = 0.3,\n               position = \"stack\",\n               #linetype = \"dotted\"\n          ) +  # Line plot for snowfall\n          scale_y_continuous(\n               name = \"Precipitation Probability (%)\",\n               sec.axis = sec_axis( ~ . / ifelse(\n                    is.infinite(scale_factor), 1000, scale_factor\n               ), name = \"Rain / Snowfall (inches)\")\n          ) +  # Dual y-axes\n          scale_x_datetime(\n               labels = scales::date_format(\"%H:%M\"),\n               breaks = \"6 hours\",\n               minor_breaks = \"2 hour\",\n               guide = guide_axis(n.dodge = 1)\n          ) +  # Format x-axis for time\n          scale_fill_manual(\n               name = \"Weather Condition\",\n               values = c(\n                    \"Rain (in.)\" = \"skyblue\",\n                    \"Snowfall (in.)\" = \"snow\"\n               )\n          ) +  # Manual color scale for weather conditions\n          scale_fill_manual(\n               name = \"Precipitation\\n and Probability\",  # Single legend title\n               values = c(\n                    \"Rain (in.)\" = \"skyblue\", \n                    \"Snowfall (in.)\" = \"snow\", \n                    \"Precipitation Probability\" = \"gray20\"\n               )) +\n               labs(title = \"Precipitation Forecast\", \n               x = \"Time of Day\", \n               y = \"Precipitation Probability (%)\") +  # Labels for the plot\n          facet_grid(~ month_day) +  # Facet by month_day\n          ggplot_theming(legend.position = \"bottom\", \n                         legend.text = element_text(size = rel(0.5)),\n                         legend.title = element_text(size = rel(0.7)))  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggPrecipitation.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n     \n}\n\n# OpenAir Wind Rose ----\nplot_wind_rose &lt;- function(con) {\n     # Query to fetch wind data\n     query &lt;- \"\n    SELECT\n      wind_speed_10m,\n      wind_direction_10m,\n      time_only,\n      common_date,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Create a wind rose plot using the openair package\n     windRose(\n          data,\n          ws = \"wind_speed_10m\",\n          wd = \"wind_direction_10m\",\n          breaks = 5,\n          paddle = TRUE,\n          cols = paletteer_d(\"ggsci::springfield_simpsons\", n = 3),\n          key.position = \"left\"\n     )\n}\n\n# ggplot wind rose ----\nplot_wind_rose_ggplot &lt;- function(con) {\n     # Query to fetch wind data\n     query &lt;- \"\n       SELECT\n         wind_direction_10m,\n         speed_bin,\n         wind_direction_cardinal,\n         direction_angle,\n         time_only,\n         month_day\n       FROM forecast_data\n       WHERE\n         latitude = 38.748;\n     \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Summarize data for plotting\n     plot_data &lt;- data |&gt;\n          group_by(wind_direction_10m, speed_bin, month_day, time_only) |&gt;\n          summarise(count = n(), .groups = \"drop\")\n     \n     # Get unique days\n     days &lt;- unique(plot_data$month_day)\n     \n     walk(days, ~ {\n          # Filter data for the current day\n          day_data &lt;- filter(plot_data, month_day == .x)\n          \n          # Create the wind rose plot for the current day\n          day_plot &lt;- ggplot(day_data,\n                             aes(\n                                  x = wind_direction_10m, y = count, fill = speed_bin\n                             )) +\n               geom_col(width = 15,\n                        color = \"black\",\n                        linewidth = 0.1) +\n               coord_polar(start = 2 * pi) +\n               scale_x_continuous(\n                    limits = c(0, 360),\n                    breaks = seq(22.5, 360, by = 22.5),\n                    labels = c(' ', 'NE', ' ', 'E', ' ', 'SE', ' ', 'S', ' ','SW', ' ', 'W', ' ', 'NW', ' ', 'N')  # Cardinal labels\n               ) +\n               scale_fill_paletteer_d('ggprism::viridis') +\n               labs(\n                    title = paste(\"Wind Rose -\", .x),\n                    x = \"Wind Direction (¬∞)\",\n                    y = \"\",\n                    fill = \"Wind Speed (m/s)\"\n               ) +\n               facet_wrap( ~ time_only) +  # Facet by hour\n               ggplot_theming(\n                    text = element_text(size = 8),\n                    axis.text = element_text(\n                         color = 'gray',\n                         margin = margin(5, 5, 5, 5, \"pt\"),\n                         size = rel(.8)\n                    ),\n                    axis.text.y = element_blank(),\n                    strip.background = element_rect(fill = 'gray20'),\n                    #strip.background.y = element_rect('#39D94E'),\n                    strip.text = element_text(size = rel(0.8), \n                                              margin = margin(0, 0, 0, 0, \"pt\"),\n                                              color = 'cornsilk'),\n                    \n               )\n          \n          # Save the plot for the current day\n          ggsave(\n               stringr::str_remove(paste0(\"data/plots/wind_rose_\", .x, \".png\"), \" \"),\n               day_plot,\n               #width = 24,\n               #height = 20,\n               scale = 2\n          )\n     })\n     \n     }\n\n\n# Visibility geom_line ----\nplot_visibility_line &lt;- function(con) {\n     # Query to fetch visibility data\n     query &lt;- \"\n    SELECT\n      visibility,\n      common_date,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Create a ggplot object for visibility trend\n     rPlot &lt;- ggplot(data, aes(x = common_date, y = visibility / 10 ^ 3)) +\n          geom_line(color = \"white\", size = 0.5) +  # Line plot for visibility\n          geom_point(color = \"gray\", alpha = 1) +  # Points for visibility\n          labs(title = \"Visibility Map\", x = \"Date\", y = \"Visibility (km)\") +  # Labels for the plot\n          scale_x_datetime(\n               labels = scales::date_format(\"%H:%M\"),\n               breaks = \"6 hours\",\n               minor_breaks = \"2 hour\",\n               guide = guide_axis(n.dodge = 1)\n          ) +  # Format x-axis for time\n          facet_grid(~ month_day) +  # Facet by month_day\n          ggplot_theming()  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggVisibilityLine.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n     \n}\n\n# Visibility Non-Categorical Heat ----\nplot_visibility_heat &lt;- function(con) {\n     # Query to fetch visibility data\n     query &lt;- \"\n    SELECT\n      visibility,\n      common_date,\n      time_only,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     data$time_only &lt;- as.POSIXct(data$time_only, format = \"%H:%M:%S\")\n     \n     # Create a ggplot object for visibility heatmap\n     rPlot &lt;- ggplot(data, aes(\n          x = month_day,\n          y = time_only,\n          fill = visibility / 10 ^ 3\n     )) +\n          geom_tile() +  # Tile plot for visibility\n          scale_fill_viridis_c(option = \"magma\") +  # Color scale for visibility\n          labs(\n               title = \"Visibility (km)\",\n               x = \"Time of Day\",\n               y = \"Date\",\n               fill = \"Visibility (km)\"\n          ) +  # Labels for the plot\n          scale_y_datetime(\n               date_labels = \"%H:%M\",\n               date_breaks = \"2 hours\",\n               sec.axis = dup_axis(name = \"\")\n          ) +  # Format x-axis for time\n          facet_grid(~ month_day, scales = \"free\") +\n          ggplot_theming(legend.position = \"right\")  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggVisibilityHeat.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n}\n\n# Visibility Categorical Heat ----\nplot_visibility_categorical_heat &lt;- function(con) {\n     # Query to fetch visibility data\n     query &lt;- \"\n    SELECT\n      visibility,\n      visibility_category,\n      common_date,\n      time_only,\n      month_day\n    FROM\n      forecast_data\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n\n          # Create a ggplot object for categorical visibility heatmap\n     # Convert time_only to POSIXct for plotting\n     data$time_only &lt;- as.POSIXct(data$time_only, format = \"%H:%M:%S\")\n     \n     # Create a ggplot object for weather codes\n     rPlot &lt;- ggplot(data, aes(x = month_day, y = time_only, fill = visibility_category)) +\n          geom_tile() +  # Tile plot for visibility categories\n          scale_fill_manual(\n               values = c(\n                    \"Clearest (&gt;30 km)\" = \"green\",\n                    \"Excellent (10-30 km)\" = \"darkgreen\",\n                    \"Good (5-10 km)\" = \"yellow\",\n                    \"Moderate (2-5 km)\" = \"orange\",\n                    \"Low (1-2 km)\" = \"red\",\n                    \"Fog/Haze (&lt;1 km)\" = \"purple\"\n               )\n          ) +  # Manual color scale for visibility categories\n          labs(\n               title = \"Visibility Category Map\",\n               x = \"Date\",\n               y = \"Time of Day\",\n               fill = \"Visibility Level\"\n          ) +  # Labels for the plot\n          scale_y_datetime(\n               date_labels = \"%H:%M\",\n               date_breaks = \"2 hours\",\n               sec.axis = dup_axis(name = \"\")\n          ) +  # Format y-axis for time\n          facet_grid(~ month_day, scales = \"free\") +\n          ggplot_theming(legend.position = \"right\")  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggVisibilityCat.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n}\n\n# Weather Codes ----\nplot_weather_codes &lt;- function(con) {\n     # Query to fetch weather codes and descriptions\n     query &lt;- \"\n    SELECT\n      fd.weather_code,\n      wc.Description AS description,\n      fd.time_only,\n      fd.month_day\n    FROM\n      forecast_data fd\n    LEFT JOIN weather_codes wc ON wc.weather_code == fd.weather_code\n    WHERE\n      latitude = 38.748;\n  \"\n     \n     data &lt;- execute_query(con, query)  # Execute the query and get the data\n     \n     # Convert time_only to POSIXct for plotting\n     data$time_only &lt;- as.POSIXct(data$time_only, format = \"%H:%M:%S\")\n     \n     # Create a ggplot object for weather codes\n     rPlot &lt;- ggplot(\n          data, aes(x = month_day, y = time_only, fill = description)) +\n          geom_tile(alpha = 0.5) +  # Tile plot for weather codes\n          scale_fill_paletteer_d(\"khroma::land\") +  # Color scale for weather codes\n          scale_y_datetime(\n               date_labels = \"%H:%M\",\n               date_breaks = \"2 hours\",\n               sec.axis = dup_axis(name = \"\")\n          ) +  # Format y-axis for time\n          labs(\n               title = \"Weather Code Map\",\n               x = \"Day\",\n               y = \"Time of Day\",\n               fill = \"Weather Code\"\n          ) +  # Labels for the plot\n          facet_grid(~ month_day, scales = \"free\") +\n          ggplot_theming(legend.position = \"right\")  # Apply custom theme\n     \n     # Save the plot as a PNG file\n     base_path &lt;- \"data/plots/\"\n     plot_path &lt;- paste0(base_path, \"ggWeatherCodes.png\")\n     ggsave(plot_path, plot = rPlot, scale = 1.5)\n     \n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)\n}\n\ndisplay_a_plot &lt;- function(plot_path) {\n     # Read the PNG file and display it\n     img &lt;- readPNG(plot_path)\n     grid::grid.raster(img)     \n}"
  },
  {
    "objectID": "index.html#data-ingestion-workflow",
    "href": "index.html#data-ingestion-workflow",
    "title": "Route Assistant",
    "section": "Data Ingestion Workflow",
    "text": "Data Ingestion Workflow\nData moves from:\nPython ingestion ‚Üí R loading ‚Üí SQL transformations ‚Üí final table materialization\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "index.html#weather-data-api",
    "href": "index.html#weather-data-api",
    "title": "Route Assistant",
    "section": "Weather Data API",
    "text": "Weather Data API\n(‚Äúüå§Ô∏è Free Open-Source Weather API  Open-Meteo.com‚Äù n.d.)\n\n‚Äúüå§Ô∏è Free Open-Source Weather API  Open-Meteo.com.‚Äù n.d. Accessed February 8, 2025. https://open-meteo.com/.\nForecast\n\n\nRun the API script to import the dataset.import pandas as pd  # For generating the date range\nimport requests_cache  # For caching API requests to reduce load and improve performance\nfrom retry_requests import retry  # For retrying failed API requests\nimport openmeteo_requests  # For interacting with the Open-Meteo API\nfrom datetime import datetime, timezone  # For handling date and time\n\ndef import_api_hourly(latitude: float, longitude: float) -&gt; pd.DataFrame:\n     \"\"\"\n     Fetches hourly weather data from the Open-Meteo API for the given latitude and longitude.\n     \n     Parameters:\n        latitude (float): The latitude of the location for which weather data is requested.\n        longitude (float): The longitude of the location for which weather data is requested.\n     \n     Returns:\n        pd.DataFrame: A Pandas DataFrame containing hourly weather data for the specified location.\n     \"\"\"\n     \n     # Setup the Open-Meteo API client with cache and retry on error\n     # Caching reduces the number of API calls by storing responses for 1 hour (3600 seconds)\n     cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n     \n     # Retry mechanism: retry up to 5 times with exponential backoff if the request fails\n     retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n     \n     # Initialize the Open-Meteo API client with the cached and retry-enabled session\n     openmeteo = openmeteo_requests.Client(session = retry_session)\n     \n     # Define the API endpoint and parameters for the weather data request\n     url = \"https://api.open-meteo.com/v1/forecast\"\n     params = {\n        \"latitude\": latitude,  # Latitude of the location\n        \"longitude\": longitude,  # Longitude of the location\n        \"hourly\": [  # List of hourly weather variables to fetch\n            \"temperature_2m\",  # Temperature at 2 meters above ground\n            \"precipitation_probability\",  # Probability of precipitation\n            \"precipitation\",  # Total precipitation\n            \"rain\",  # Rain amount\n            \"showers\",  # Showers amount\n            \"snowfall\",  # Snowfall amount\n            \"snow_depth\",  # Snow depth\n            \"weather_code\",  # Weather condition code\n            \"visibility\",  # Visibility\n            \"wind_speed_10m\",  # Wind speed at 10 meters above ground\n            \"wind_direction_10m\"  # Wind direction at 10 meters above ground\n        ],\n        \"temperature_unit\": \"fahrenheit\",  # Temperature unit (Fahrenheit)\n        \"wind_speed_unit\": \"mph\",  # Wind speed unit (miles per hour)\n        \"precipitation_unit\": \"inch\",  # Precipitation unit (inches)\n        \"timezone\": \"America/Chicago\",  # Timezone for the data\n        #\"forecast_days\": 1,  # Number of forecast days (1 day)\n        \"past_hours\": 6,  # Include past 6 hours of data\n        \"forecast_hours\": 24,  # Include next 24 hours of forecast\n        \"models\": \"best_match\"  # Use the best matching weather model\n     }\n     \n     # Make the API request to fetch weather data\n     responses = openmeteo.weather_api(url, params = params)\n     \n     # Process the first location in the response (only one location is requested)\n     response = responses[0]\n     \n     # Print location and timezone information for debugging\n     print(f\"Coordinates {response.Latitude()}¬∞N {response.Longitude()}¬∞E\")\n     print(f\"Elevation {response.Elevation()} m asl\")\n     print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n     print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n     \n     # Process hourly data. The order of variables needs to be the same as requested.\n     hourly = response.Hourly()\n     hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n     hourly_precipitation_probability = hourly.Variables(1).ValuesAsNumpy()\n     hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n     hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n     hourly_showers = hourly.Variables(4).ValuesAsNumpy()\n     hourly_snowfall = hourly.Variables(5).ValuesAsNumpy()\n     hourly_snow_depth = hourly.Variables(6).ValuesAsNumpy()\n     hourly_weather_code = hourly.Variables(7).ValuesAsNumpy()\n     hourly_visibility = hourly.Variables(8).ValuesAsNumpy()\n     hourly_wind_speed_10m = hourly.Variables(9).ValuesAsNumpy()\n     hourly_wind_direction_10m = hourly.Variables(10).ValuesAsNumpy()\n     \n     hourly_data = {\"date\": pd.date_range(\n        start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n        end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n        freq = pd.Timedelta(seconds = hourly.Interval()),\n        inclusive = \"left\"\n     )}\n     \n     hourly_data[\"latitude\"] = latitude\n     hourly_data[\"longitude\"] = longitude\n     hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n     hourly_data[\"precipitation_probability\"] = hourly_precipitation_probability\n     hourly_data[\"precipitation\"] = hourly_precipitation\n     hourly_data[\"rain\"] = hourly_rain\n     hourly_data[\"showers\"] = hourly_showers\n     hourly_data[\"snowfall\"] = hourly_snowfall\n     hourly_data[\"snow_depth\"] = hourly_snow_depth\n     hourly_data[\"weather_code\"] = hourly_weather_code\n     hourly_data[\"visibility\"] = hourly_visibility\n     hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n     hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n     \n     #data = pd.DataFrame(data = hourly_data)\n     \n     return(pd.DataFrame(data = hourly_data))\n\n\n\n\n\nWrite hourly api results.coordinates &lt;- list(\n  c(38.748, -90.439),  # Original coordinates\n  c(40.7128, -74.0060),  # New York\n  c(34.0522, -118.2437)  # Los Angeles\n)\n\nlats &lt;- purrr::map_dbl(coordinates, 1)\nlons &lt;- purrr::map_dbl(coordinates, 2)\n\npurrr::walk2(lats, lons, \\(lat, lon) {\n  dbWriteTable(\n    duckdb_con,\n    \"forecast_data\",\n    py$import_api_hourly(lat, lon),\n    append = TRUE\n  )\n}, .progress = FALSE)\n\nCoordinates 38.74498748779297¬∞N -90.4433364868164¬∞E\nElevation 175.0 m asl\nTimezone b'America/Chicago' b'GMT-5'\nTimezone difference to GMT+0 -18000 s\nCoordinates 40.71033477783203¬∞N -73.99308776855469¬∞E\nElevation 32.0 m asl\nTimezone b'America/Chicago' b'GMT-5'\nTimezone difference to GMT+0 -18000 s\nCoordinates 34.06025695800781¬∞N -118.23432922363281¬∞E\nElevation 91.0 m asl\nTimezone b'America/Chicago' b'GMT-5'\nTimezone difference to GMT+0 -18000 s\n\n\n\nHistorical\n\n#| label: loadHourlyHistoricalAPIscript\n#| code-summary: \"Run the API script to import the dataset.\"\n#| file: \"scripts/Import/API/Hourly/import_api_hourly_historical.py\"\n\n\n#| label: writeHistoricalAPIdata\n#| code-summary: \"Write hourly api historical data.\"\n\nsave_to_partition &lt;- function(df, lat, lon) {\n  # Add partitioning columns to the data frame\n  df &lt;- df|&gt;\n    mutate(\n      lat = lat,\n      lon = lon,\n      year = year(date),\n      month = month(date)\n    )\n  \n  # Write to Hive partitions (folders auto-created)\n  arrow::write_dataset(\n    df,\n    path = \"data/historical_weather/\",\n    format = \"parquet\",\n    partitioning = c(\"lat\", \"lon\", \"year\", \"month\"),\n    existing_data_behavior = \"overwrite\"  # or \"delete_matching\"\n  )\n}\n\ncoordinates1 &lt;- list(\n     c(34.0522, -118.2437),   # Los Angeles, CA (Start)\n     c(33.9806, -117.3755),   # Riverside, CA (I-215 logistics)\n     c(34.1495, -117.2345),   # San Bernardino, CA (I-10/I-215 interchange)\n     c(33.6103, -114.5964),   # Blythe, CA (I-10 desert truck stop)\n     c(33.4484, -112.0740)   # Phoenix, AZ (I-10)\n)\n\ncoordinates2 &lt;- list(\n     c(35.1983, -111.6513),   # Flagstaff, AZ (I-40 mountain gateway)\n     c(35.0844, -106.6504),   # Albuquerque, NM (I-40)\n     c(34.9333, -104.6876),   # Santa Rosa, NM (I-40 rest area)\n     c(35.2210, -101.8313),   # Amarillo, TX (I-40, \"Big Texan\" truck stop)\n     c(35.2161, -100.2491)   # Shamrock, TX (I-40, near OK border)\n)\n\ncoordinates3 &lt;- list(\n     c(35.4676, -97.5164),    # Oklahoma City, OK (I-40/I-44 junction)\n     c(36.7538, -95.2206),    # Miami, OK (I-44, near MO border)\n     c(37.0842, -94.5133),    # Joplin, MO (I-44 truck hub)\n     c(38.7480, -90.4390),    # St. Louis, MO (I-44/I-70 interchange)\n     c(39.1200, -88.5435)    # Effingham, IL (I-70 logistics hub)\n)\n\ncoordinates4 &lt;- list(\n     c(39.7684, -86.1581),    # Indianapolis, IN (I-70 \"Crossroads of America\")\n     c(39.7589, -84.1916),    # Dayton, OH (I-70/I-75 junction)\n     c(40.4406, -79.9959),    # Pittsburgh, PA (I-76)\n     c(39.9995, -78.2341),    # Breezewood, PA (I-70/I-76 truck stop)\n     c(40.7357, -74.1724)     # Newark, NJ (End, NYC metro)\n)\n\nlats &lt;- purrr::map_dbl(coordinates4, 1)\nlons &lt;- purrr::map_dbl(coordinates4, 2)\n\npurrr::walk2(lats, lons, \\(lat, lon) {\n\n     df &lt;- py$import_api_hourly_historical(lat, lon, \"1974-01-01\", \"2024-12-31\")\n     \n     save_to_partition(df, lat, lon)\n\n     # Delay to avoid API rate limits\n     Sys.sleep(300)\n\n}, .progress = FALSE)\n\nstorage://\n\n\ndata/\n\n\nweather_data/\n\n\nlat=34.0522/\n\n\nlon=-118.2437/\n\n\nyear=2024/\n\n\nmonth=01/\n\npart-0.parquet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeSELECT * --lat/lon/year/month\nFROM read_parquet(\n     'data/historical_weather/*/*/*/*/part-0.parquet', \n     hive_partitioning = true)\nLIMIT 100;\n\n\n\nCreate a table from the hive partitioned dataset.CREATE OR REPLACE TABLE historical_data AS \nSELECT * \nFROM read_parquet(\n     'data/historical_weather/*/*/*/*/part-0.parquet', --lat/lon/year/month\n     hive_partitioning = true);"
  },
  {
    "objectID": "index.html#about-the-weather-data",
    "href": "index.html#about-the-weather-data",
    "title": "Route Assistant",
    "section": "About the Weather Data",
    "text": "About the Weather Data\n\nThe study, published in the Weather and Forecasting journal, focuses on evaluating and improving the accuracy of weather prediction models, particularly for severe weather events. It examines the performance of high-resolution numerical weather prediction (NWP) models in forecasting convective storms, which are critical for predicting severe weather such as thunderstorms, hail, and tornadoes. The research highlights advancements in model resolution, data assimilation techniques, and the integration of observational data to enhance forecast precision. The findings emphasize the importance of these improvements for short-term (nowcasting) and medium-range forecasts, particularly in regions prone to severe weather, like the central United States (including Missouri). Dowell et al. (2022)\n\nDowell, David C., Curtis R. Alexander, Eric P. James, Stephen S. Weygandt, Stanley G. Benjamin, Geoffrey S. Manikin, Benjamin T. Blake, et al. 2022. ‚ÄúThe High-Resolution Rapid Refresh (HRRR): An Hourly Updating Convection-Allowing Forecast Model. Part I: Motivation and System Description.‚Äù Weather and Forecasting 37 (8): 1371‚Äì95. https://doi.org/10.1175/WAF-D-21-0151.1.\n\n\n\ntable setup# Create the tibble\nforecast_models &lt;- tibble(\n     Model = c(\"GFS\", \"HRRR\"),\n     Developed_By = c(\n          \"NOAA (National Oceanic and Atmospheric Administration)\",\n          \"NOAA (specifically by the Earth System Research Laboratory)\"\n     ),\n     Scope = c(\n          \"Global\",\n          \"Regional (primarily focused on the contiguous United States)\"\n     ),\n     Resolution = c(\n          \"Lower resolution compared to HRRR (approximately 13 km as of recent updates)\",\n          \"High resolution (3 km)\"\n     ),\n     Forecast_Range = c(\"Up to 16 days\", \"Up to 18 hours\"),\n     Updates = c(\"Runs four times a day (00Z, 06Z, 12Z, 18Z)\", \"Runs every hour\"),\n     Applications = c(\n          \"Used for long-term weather forecasting, climate modeling, and global weather patterns.\",\n          \"Ideal for short-term, detailed weather forecasting, including severe weather events like thunderstorms, tornadoes, and localized precipitation.\"\n     )\n)\n\nlocations_list = colnames(forecast_models)\n\nnotes_list =  list(\n     \"\",\n  \"Organization or entity responsible for developing the model.\",\n  \"Geographical coverage of the model (e.g., global or regional).\",\n  \"Spatial resolution of the model, indicating the level of detail in the forecasts.\",\n  \"Time period for which the model provides forecasts.\",\n  \"Frequency at which the model is updated with new data.\",\n  \"Primary uses and strengths of the model in weather forecasting.\"\n  )\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list)\n\npal_df &lt;- tibble(\n  cols = locations_list\n#  pals = list(eval_palette(\"viridis::viridis\", 2, 'c', 1))\n)\n\nrTable &lt;- r_table_theming(\nforecast_models,\ntitle = \"Forecast Models: Attributes\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: \"),\npal_df,\nmultiline_feet = TRUE,\ntable_font_size = pct(85),\ntarget_everything = TRUE,\nrow_name_col = \"Model\",\n)\n\n\n\n\n\n\n\n\n\nTable¬†1\n\n\n\n\n\n\n\nForecast Models: Attributes\n    \n\n\n      Developed_By1\n\n      Scope2\n\n      Resolution3\n\n      Forecast_Range4\n\n      Updates5\n\n      Applications6\n\n    \n\n\n\nGFS\nNOAA (National Oceanic and Atmospheric Administration)\nGlobal\nLower resolution compared to HRRR (approximately 13 km as of recent updates)\nUp to 16 days\nRuns four times a day (00Z, 06Z, 12Z, 18Z)\nUsed for long-term weather forecasting, climate modeling, and global weather patterns.\n\n\nHRRR\nNOAA (specifically by the Earth System Research Laboratory)\nRegional (primarily focused on the contiguous United States)\nHigh resolution (3 km)\nUp to 18 hours\nRuns every hour\nIdeal for short-term, detailed weather forecasting, including severe weather events like thunderstorms, tornadoes, and localized precipitation.\n\n\n\nsource:\n    \n\n\n\n1 Organization or entity responsible for developing the model.\n    \n\n\n2 Geographical coverage of the model (e.g., global or regional).\n    \n\n\n3 Spatial resolution of the model, indicating the level of detail in the forecasts.\n    \n\n\n4 Time period for which the model provides forecasts.\n    \n\n\n5 Frequency at which the model is updated with new data.\n    \n\n\n6 Primary uses and strengths of the model in weather forecasting.\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\ntable setupforecast_model_differences &lt;- tibble(\n\"Resolution\" = c(\n\"HRRR has a much higher resolution than GFS, making it more accurate for short-term, localized forecasts.\"\n),\n\"Forecast_Range\" = c(\"GFS provides forecasts for a much longer period compared to HRRR.\"),\n\"Update_Frequency\" =  c(\n\"HRRR updates more frequently, which is crucial for capturing rapidly changing weather conditions.\"\n)\n)\n\nlocations_list = colnames(forecast_model_differences)\n\nnotes_list =  list(\n  \"Spatial resolution of the model, indicating the level of detail in the forecasts.\",\n  \"Time period for which the model provides forecasts.\",\n  \"Frequency at which the model is updated with new data.\")\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list)\n\npal_df &lt;- tibble(\n  cols = locations_list\n#  pals = list(eval_palette(\"viridis::viridis\", 2, 'c', 1))\n)\n\nrTable &lt;- r_table_theming(\nforecast_model_differences,\ntitle = \"Forecast Models: Differences\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: \"),\npal_df,\nmultiline_feet = TRUE,\ntable_font_size = pct(85),\ntarget_everything = TRUE,\nrow_name_col = NULL\n)\n\n\n\n\n\n\n\n\n\nTable¬†2\n\n\n\n\n\n\n\nForecast Models: Differences\n    \n\nResolution1\n\n      Forecast_Range2\n\n      Update_Frequency3\n\n    \n\n\nHRRR has a much higher resolution than GFS, making it more accurate for short-term, localized forecasts.\nGFS provides forecasts for a much longer period compared to HRRR.\nHRRR updates more frequently, which is crucial for capturing rapidly changing weather conditions.\n\n\nsource:\n    \n\n\n\n1 Spatial resolution of the model, indicating the level of detail in the forecasts.\n    \n\n\n2 Time period for which the model provides forecasts.\n    \n\n\n3 Frequency at which the model is updated with new data."
  },
  {
    "objectID": "index.html#database-setup",
    "href": "index.html#database-setup",
    "title": "Route Assistant",
    "section": "Database Setup",
    "text": "Database Setup\n\n\nload enum file#' Create ENUM Type and Associate Codes with Descriptions\n#'\n#' This function creates an ENUM type in DuckDB and associates codes with their descriptions.\n#' It can be used to create other ENUM types and associations\n#'\n#' @param duckdb_conn A DuckDB connection object.\n#' @param enum_name A string specifying the name of the ENUM type to be created.\n#' @param table_name A string specifying the name of the ENUM dictionary table.\n#' @param codes A character vector of codes to be included in the ENUM type.\n#' @param descriptions A character vector of descriptions corresponding to the codes.\n#' @example\n#' \\dontrun{\n#' library(DBI)\n#' \n#' codes &lt;- c('0', '1', '2', '3', '45', '48', '51', '53', '55', '56', '57', \n#'            '61', '63', '65', '66', '67', '71', '73', '75', '77', '80', '81', \n#'            '82', '85', '86', '95', '96', '99')\n#' descriptions &lt;- c('Clear sky', 'Mainly clear', 'Partly cloudy', 'Overcast', \n#'                   'Fog', 'Depositing rime fog', 'Drizzle: Light', 'Drizzle: Moderate', \n#'                   'Drizzle: Dense', 'Freezing Drizzle: Light', 'Freezing Drizzle: Dense', \n#'                   'Rain: Slight', 'Rain: Moderate', 'Rain: Heavy', 'Freezing Rain: Light', \n#'                   'Freezing Rain: Heavy', 'Snow fall: Slight', 'Snow fall: Moderate', \n#'                   'Snow fall: Heavy', 'Snow grains', 'Rain showers: Slight', \n#'                   'Rain showers: Moderate', 'Rain showers: Violent', 'Snow showers: Slight', \n#'                   'Snow showers: Heavy', 'Thunderstorm: Slight or moderate', \n#'                   'Thunderstorm with slight hail', 'Thunderstorm with heavy hail')\n#' \n#' result &lt;- create_enum_and_associate(duckdb_con, \"WeatherCode\", codes, descriptions)\n#' print(result)\n#' }\n#' @export\ncreate_enum_and_associate &lt;- function(duckdb_con, enum_name, table_name, code_frame) {\n     \n     # Attempt to drop the ENUM type if it exists\n     drop_query &lt;- paste0(\"DROP TYPE IF EXISTS \", enum_name, \";\")\n     \n     tryCatch({\n          dbExecute(duckdb_con, drop_query)\n          message(paste(\"Dropped existing ENUM type:\", enum_name))\n     }, error = \\(e) {\n          message(paste0(\"No existing ENUM type to drop: \", enum_name))\n     })\n     \n     # Create the ENUM type\n     enum_query &lt;- paste0(\n          \"CREATE TYPE \", enum_name, \" AS ENUM (\",\n          paste0(\n               \"'\", code_frame$code, \"'\", collapse = \", \"), \");\"\n          )\n     \n     dbExecute(duckdb_con, enum_query)\n     message(paste0(\"Created ENUM type: \", enum_name))\n     \n     # Write an association table for reference\n     dbWriteTable(\n          duckdb_con,\n          table_name,\n          code_frame,\n          overwrite = TRUE\n     )\n}\n\n\n\n\n\nSets the custom data types in the database.code_frame &lt;- tibble::tibble(\nweather_code = c(\n     '0',\n     '1',\n     '2',\n     '3',\n     '45',\n     '48',\n     '51',\n     '53',\n     '55',\n     '56',\n     '57',\n     '61',\n     '63',\n     '65',\n     '66',\n     '67',\n     '71',\n     '73',\n     '75',\n     '77',\n     '80',\n     '81',\n     '82',\n     '85',\n     '86',\n     '95',\n     '96',\n     '99'\n),\n\ndescription = c(\n     'Clear sky',\n     'Mainly clear',\n     'Partly cloudy',\n     'Overcast',\n     'Fog',\n     'Depositing rime fog',\n     'Drizzle: light',\n     'Drizzle: moderate',\n     'Drizzle: dense',\n     'Freezing drizzle: light',\n     'Freezing drizzle: dense',\n     'Rain: slight',\n     'Rain: moderate',\n     'Rain: heavy',\n     'Freezing rain: light',\n     'Freezing rain: heavy',\n     'Snow fall: slight',\n     'Snow fall: moderate',\n     'Snow fall: heavy',\n     'Snow grains',\n     'Rain showers: slight',\n     'Rain showers: moderate',\n     'Rain showers: violent',\n     'Snow showers: slight',\n     'Snow showers: heavy',\n     'Thunderstorm: slight or moderate',\n     'Thunderstorm with slight hail',\n     'Thunderstorm with heavy hail'\n),\n\nimplication = c(\n     \"Normal operations - No restrictions\",              # Clear sky\n     \"Normal operations - Increased vigilance\",          # Mainly clear\n     \"Normal operations - Monitor weather updates\",      # Partly cloudy\n     \"Reduced visibility - Maintain safe following distance\", # Overcast\n     \"Speed reduction required - Fog lights mandatory\",  # Fog\n     \"Speed reduction required - Extreme caution\",        # Depositing rime fog\n     \"Potential minor delays - Road surface slickness\",   # Drizzle: light\n     \"Speed restrictions - 15% reduction recommended\",    # Drizzle: moderate\n     \"Mandatory speed reduction - 25%+\",                 # Drizzle: dense\n     \"Chain requirement - Level 1 traction advisory\",     # Freezing drizzle: light\n     \"Road closure likely - Avoid non-essential travel\",  # Freezing drizzle: dense\n     \"Increased stopping distance - 10% speed reduction\", # Rain: slight\n     \"15-20% speed reduction - Check tire tread\",         # Rain: moderate\n     \"25%+ speed reduction - Possible detour routing\",    # Rain: heavy\n     \"Mandatory chains - Temperature monitoring\",         # Freezing rain: light\n     \"Road closure imminent - Immediate stop advised\",    # Freezing rain: heavy\n     \"15% speed reduction - Traction control engaged\",    # Snow fall: slight\n     \"25% speed reduction - Chain requirement possible\",  # Snow fall: moderate\n     \"Road closure likely - Abandon shipment staging\",    # Snow fall: heavy\n     \"Speed restriction - Watch for black ice\",           # Snow grains\n     \"Increased following distance - 4-second rule\",      # Rain showers: slight\n     \"20% speed reduction - Avoid lane changes\",          # Rain showers: moderate\n     \"Immediate parking advised - Flash flood risk\",      # Rain showers: violent\n     \"Chain requirement - Trailer brake check\",           # Snow showers: slight\n     \"Road closure protocol activated\",                   # Snow showers: heavy\n     \"Delay shipments - No open-top trailers\",            # Thunderstorm: slight/mod\n     \"Immediate stop - Seek shelter\",                     # Thunderstorm w/ slight hail\n     \"Catastrophic risk - Emergency protocols\"            # Thunderstorm w/ heavy hail\n),\n\nrisk_score = c(\n     0.1,  # Clear sky\n     0.15, # Mainly clear\n     0.2,  # Partly cloudy\n     0.25, # Overcast\n     0.4,  # Fog\n     0.5,  # Depositing rime fog\n     0.3,  # Drizzle: light\n     0.35, # Drizzle: moderate\n     0.45, # Drizzle: dense\n     0.55, # Freezing drizzle: light\n     0.8,  # Freezing drizzle: dense\n     0.3,  # Rain: slight\n     0.4,  # Rain: moderate\n     0.6,  # Rain: heavy\n     0.65, # Freezing rain: light\n     0.85, # Freezing rain: heavy\n     0.4,  # Snow fall: slight\n     0.6,  # Snow fall: moderate\n     0.75, # Snow fall: heavy\n     0.5,  # Snow grains\n     0.35, # Rain showers: slight\n     0.5,  # Rain showers: moderate\n     0.7,  # Rain showers: violent\n     0.6,  # Snow showers: slight\n     0.8,  # Snow showers: heavy\n     0.65, # Thunderstorm: slight/mod\n     0.85, # Thunderstorm w/ slight hail\n     0.95  # Thunderstorm w/ heavy hail\n  ),\n\ndot_compliance = c(\n     \"¬ß392.14(a)\",              # Clear sky\n     \"¬ß392.14(a)\",              # Mainly clear\n     \"¬ß392.14(a)\",              # Partly cloudy\n     \"¬ß392.14(b)\",              # Overcast\n     \"¬ß392.14(b)+¬ß393.75(c)\",   # Fog\n     \"¬ß392.14(c)\",              # Depositing rime fog\n     \"¬ß392.71(a)\",              # Drizzle: light\n     \"¬ß392.71(b)\",              # Drizzle: moderate\n     \"¬ß392.71(c)\",              # Drizzle: dense\n     \"¬ß392.16(a)\",              # Freezing drizzle: light\n     \"¬ß392.16(c)\",              # Freezing drizzle: dense\n     \"¬ß392.71(a)\",              # Rain: slight\n     \"¬ß392.71(b)\",              # Rain: moderate\n     \"¬ß392.71(c)\",              # Rain: heavy\n     \"¬ß392.16(b)+¬ß393.95(d)\",   # Freezing rain: light\n     \"¬ß392.16(c)\",              # Freezing rain: heavy\n     \"¬ß392.14(b)+¬ß393.95(a)\",   # Snow fall: slight\n     \"¬ß392.14(c)+¬ß393.95(b)\",   # Snow fall: moderate\n     \"¬ß392.16(c)\",              # Snow fall: heavy\n     \"¬ß392.14(c)\",              # Snow grains\n     \"¬ß392.14(b)\",              # Rain showers: slight\n     \"¬ß392.14(c)\",              # Rain showers: moderate\n     \"¬ß392.16(c)\",              # Rain showers: violent\n     \"¬ß393.95(c)\",              # Snow showers: slight\n     \"¬ß392.16(c)\",              # Snow showers: heavy\n     \"¬ß392.14(d)+¬ß393.75(e)\",   # Thunderstorm: slight/mod\n     \"¬ß392.16(c)\",              # Thunderstorm w/ slight hail\n     \"¬ß392.16(e)\"               # Thunderstorm w/ heavy hail\n),\n\nseverity = cut(\nrisk_score,\nbreaks = c(0, 0.3, 0.5, 0.7, 1),\nlabels = c(\"Low\", \"Moderate\", \"High\", \"Critical\")\n),\n\ninsurance_surcharge = c(\n     0,    # Clear sky\n     0,    # Mainly clear\n     0.05, # Partly cloudy (5%)\n     0.07, # Overcast (7%)\n     0.1,  # Fog (10%)\n     0.15, # Rime fog (15%)\n     0.08, # Light drizzle (8%)\n     0.12, # Moderate drizzle (12%)\n     0.18, # Dense drizzle (18%)\n     0.25, # Freezing drizzle light (25%)\n     0.4,  # Freezing drizzle dense (40%)\n     0.1,  # Rain slight (10%)\n     0.15, # Rain moderate (15%)\n     0.25, # Rain heavy (25%)\n     0.35, # Freezing rain light (35%)\n     0.5,  # Freezing rain heavy (50%)\n     0.2,  # Snow slight (20%)\n     0.3,  # Snow moderate (30%)\n     0.45, # Snow heavy (45%)\n     0.25, # Snow grains (25%)\n     0.12, # Rain showers slight (12%)\n     0.2,  # Rain showers moderate (20%)\n     0.35, # Rain showers violent (35%)\n     0.3,  # Snow showers slight (30%)\n     0.5,  # Snow showers heavy (50%)\n     0.4,  # Thunderstorm (40%)\n     0.6,  # Thunderstorm w/ slight hail (60%)\n     0.8   # Thunderstorm w/ heavy hail (80%)\n),\n\nfuel_multiplier = c(\n     1.0,  # Clear sky\n     1.0,  # Mainly clear\n     1.03, # Partly cloudy (3%)\n     1.05, # Overcast (5%)\n     1.12, # Fog (12%)\n     1.15, # Rime fog (15%)\n     1.07, # Light drizzle (7%)\n     1.1,  # Moderate drizzle (10%)\n     1.15, # Dense drizzle (15%)\n     1.25, # Freezing drizzle light (25%)\n     1.4,  # Freezing drizzle dense (40%)\n     1.08, # Rain slight (8%)\n     1.12, # Rain moderate (12%)\n     1.2,  # Rain heavy (20%)\n     1.3,  # Freezing rain light (30%)\n     1.5,  # Freezing rain heavy (50%)\n     1.15, # Snow slight (15%)\n     1.25, # Snow moderate (25%)\n     1.4,  # Snow heavy (40%)\n     1.2,  # Snow grains (20%)\n     1.1,  # Rain showers slight (10%)\n     1.15, # Rain showers moderate (15%)\n     1.3,  # Rain showers violent (30%)\n     1.25, # Snow showers slight (25%)\n     1.45, # Snow showers heavy (45%)\n     1.35, # Thunderstorm (35%)\n     1.6,  # Thunderstorm w/ slight hail (60%)\n     2.0   # Thunderstorm w/ heavy hail (100%)\n  ),\n\nroute_delay_factor = c(\n     1.0,  # Clear sky\n     1.0,  # Mainly clear\n     1.00,  # Partly cloudy\n     1.01,  # Overcast\n     1.05,  # Fog\n     1.08,  # Rime fog\n     1.03,  # Light drizzle\n     1.06,  # Moderate drizzle\n     1.2,  # Dense drizzle\n     1.25,  # Freezing drizzle light\n     1.4,  # Freezing drizzle dense\n     1.04,  # Rain slight\n     1.08,  # Rain moderate\n     1.25,  # Rain heavy\n     1.3,  # Freezing rain light\n     1.5,  # Freezing rain heavy\n     1.2,  # Snow slight\n     1.3,  # Snow moderate\n     1.45,  # Snow heavy\n     1.25,  # Snow grains\n     1.05,  # Rain showers slight\n     1.2,  # Rain showers moderate\n     1.35,  # Rain showers violent\n     1.3,  # Snow showers slight\n     1.5,  # Snow showers heavy\n     1.3,  # Thunderstorm\n     1.6,  # Thunderstorm w/ slight hail\n     2.0  # Thunderstorm w/ heavy hail\n),\n\n# New Labor & Equipment Columns\nsafety_inspections = c(\n     \"Pre-trip only\",                    # Clear sky\n     \"Pre-trip + mid-trip visual\",       # Mainly clear\n     \"Pre-trip + brake check\",           # Partly cloudy\n     \"Pre-trip + hourly tire checks\",    # Overcast\n     \"Pre-trip + fog light checks\",      # Fog\n     \"Pre-trip + 30-min interval checks\",# Rime fog\n     \"Pre-trip + 2hr brake tests\",       # Drizzle: light\n     \"Pre-trip + 1hr brake tests\",       # Drizzle: moderate\n     \"Pre-trip + 30min brake tests\",     # Drizzle: dense\n     \"Pre-trip + axle temp monitoring\",  # Freezing drizzle: light\n     \"Continuous monitoring required\",   # Freezing drizzle: dense\n     \"Pre-trip + wiper checks\",          # Rain: slight\n     \"Pre-trip + 2hr wiper checks\",      # Rain: moderate\n     \"Pre-trip + 30min wiper checks\",    # Rain: heavy\n     \"Pre-trip + chain integrity checks\",# Freezing rain: light\n     \"Roadside inspections mandatory\",   # Freezing rain: heavy\n     \"Pre-trip + tire chain prep\",       # Snow fall: slight\n     \"Pre-trip + hourly chain checks\",   # Snow fall: moderate\n     \"Continuous chain monitoring\",      # Snow fall: heavy\n     \"Pre-trip + sanding required\",      # Snow grains\n     \"Pre-trip + drainage checks\",       # Rain showers: slight\n     \"Pre-trip + undercarriage checks\",  # Rain showers: moderate\n     \"Abort trip + full inspection\",     # Rain showers: violent\n     \"Pre-trip + plow attachment\",       # Snow showers: slight\n     \"Roadside de-icing required\",       # Snow showers: heavy\n     \"Pre-trip + lightning protocol\",    # Thunderstorm: slight/mod\n     \"Immediate shelter + inspection\",   # Thunderstorm w/ slight hail\n     \"Post-storm forensic inspection\"    # Thunderstorm w/ heavy hail\n),\n\ndriver_wage_premium = c(\n     0.00,  # Clear sky\n     0.00,   # Mainly clear\n     0.05,   # Partly cloudy (+5%)\n     0.07,   # Overcast (+7%)\n     0.15,   # Fog (+15%)\n     0.20,   # Rime fog (+20%)\n     0.10,   # Drizzle: light (+10%)\n     0.12,   # Drizzle: moderate (+12%)\n     0.18,   # Drizzle: dense (+18%)\n     0.25,   # Freezing drizzle: light (+25%)\n     0.40,   # Freezing drizzle: dense (+40%)\n     0.10,   # Rain: slight (+10%)\n     0.15,   # Rain: moderate (+15%)\n     0.25,   # Rain: heavy (+25%)\n     0.35,   # Freezing rain: light (+35%)\n     0.50,   # Freezing rain: heavy (+50%)\n     0.20,   # Snow fall: slight (+20%)\n     0.30,   # Snow fall: moderate (+30%)\n     0.45,   # Snow fall: heavy (+45%)\n     0.25,   # Snow grains (+25%)\n     0.12,   # Rain showers: slight (+12%)\n     0.20,   # Rain showers: moderate (+20%)\n     0.35,   # Rain showers: violent (+35%)\n     0.30,   # Snow showers: slight (+30%)\n     0.50,   # Snow showers: heavy (+50%)\n     0.40,   # Thunderstorm (+40%)\n     0.60,   # Thunderstorm w/ slight hail (+60%)\n     0.80    # Thunderstorm w/ heavy hail (+80%)\n),\n  \nequipment_wear_factor = c(\n     1.0,   # Clear sky\n     1.02,  # Mainly clear (+2%)\n     1.05,  # Partly cloudy (+5%)\n     1.07,  # Overcast (+7%)\n     1.15,  # Fog (+15%)\n     1.20,  # Rime fog (+20%)\n     1.10,  # Drizzle: light (+10%)\n     1.12,  # Drizzle: moderate (+12%)\n     1.18,  # Drizzle: dense (+18%)\n     1.25,  # Freezing drizzle: light (+25%)\n     1.40,  # Freezing drizzle: dense (+40%)\n     1.12,  # Rain: slight (+12%)\n     1.15,  # Rain: moderate (+15%)\n     1.25,  # Rain: heavy (+25%)\n     1.35,  # Freezing rain: light (+35%)\n     1.50,  # Freezing rain: heavy (+50%)\n     1.20,  # Snow fall: slight (+20%)\n     1.30,  # Snow fall: moderate (+30%)\n     1.45,  # Snow fall: heavy (+45%)\n     1.25,  # Snow grains (+25%)\n     1.10,  # Rain showers: slight (+10%)\n     1.15,  # Rain showers: moderate (+15%)\n     1.30,  # Rain showers: violent (+30%)\n     1.25,  # Snow showers: slight (+25%)\n     1.45,  # Snow showers: heavy (+45%)\n     1.35,  # Thunderstorm (+35%)\n     1.60,  # Thunderstorm w/ slight hail (+60%)\n     2.0    # Thunderstorm w/ heavy hail (+100%)\n),\n  \ncarbon_multiplier = c(\n     1.00,  # Clear sky\n     1.01,  # Mainly clear (+1%)\n     1.03,  # Partly cloudy (+3%)\n     1.05,  # Overcast (+5%)\n     1.12,  # Fog (+12%)\n     1.15,  # Rime fog (+15%)\n     1.07,  # Drizzle: light (+7%)\n     1.10,  # Drizzle: moderate (+10%)\n     1.15,  # Drizzle: dense (+15%)\n     1.22,  # Freezing drizzle: light (+22%)\n     1.35,  # Freezing drizzle: dense (+35%)\n     1.08,  # Rain: slight (+8%)\n     1.12,  # Rain: moderate (+12%)\n     1.20,  # Rain: heavy (+20%)\n     1.28,  # Freezing rain: light (+28%)\n     1.45,  # Freezing rain: heavy (+45%)\n     1.15,  # Snow fall: slight (+15%)\n     1.25,  # Snow fall: moderate (+25%)\n     1.40,  # Snow fall: heavy (+40%)\n     1.20,  # Snow grains (+20%)\n     1.10,  # Rain showers: slight (+10%)\n     1.15,  # Rain showers: moderate (+15%)\n     1.30,  # Rain showers: violent (+30%)\n     1.25,  # Snow showers: slight (+25%)\n     1.40,  # Snow showers: heavy (+40%)\n     1.35,  # Thunderstorm (+35%)\n     1.55,  # Thunderstorm w/ slight hail (+55%)\n     1.80   # Thunderstorm w/ heavy hail (+80%)\n),\n\n# Bridge Weight Restrictions (FHWA Load Rating Manual)\nbridge_weight_limit = c(\n1.00, 1.00, 0.98, 0.95, 0.90, 0.85, 0.92, 0.88, 0.82, 0.75, 0.60,\n0.93, 0.87, 0.78, 0.65, 0.50, 0.85, 0.72, 0.55, 0.80, 0.91, 0.86,\n0.60, 0.70, 0.45, 0.68, 0.40, 0.30\n),\n  \n# Toll Multipliers (IBTTA 2023 Storm Surcharge Index)\ntoll_multiplier = c(\n1.00, 1.00, 1.05, 1.07, 1.15, 1.25, 1.10, 1.15, 1.22, 1.35, 2.00,\n1.12, 1.18, 1.30, 1.45, 1.80, 1.20, 1.35, 1.60, 1.25, 1.13, 1.20,\n1.70, 1.40, 2.10, 1.55, 2.30, 3.00\n),\n  \n# Border Crossing Delays (CBP TRIP Data)\nborder_delay_hours = c(\n0.0, 0.0, 0.5, 0.7, 1.2, 2.0, 0.8, 1.1, 1.8, 2.5, 6.0,\n0.9, 1.3, 2.2, 3.5, 8.0, 1.5, 2.8, 5.0, 1.7, 1.0, 1.5,\n4.0, 2.5, 7.0, 3.0, 9.0, 12.0\n),\n  \n# API Endpoints\nreroute_api = c(\n     NA_character_,  # Clear sky\n     NA_character_,  # Mainly clear\n     \"HERE Weather API v3\",  # Partly cloudy\n     \"HERE Weather API v3\",  # Overcast\n     \"FHWA ARCHIS Live\",  # Fog\n     \"FHWA ARCHIS Live\",  # Rime fog\n     \"Google Maps Directions\",  # Drizzle\n     \"Google Maps Directions\",  # Drizzle\n     \"Google Maps Directions\",  # Drizzle\n     \"FMCSA SMS API\",  # Freezing drizzle\n     \"FMCSA SMS API\",  # Freezing drizzle\n     \"USDOT NTAD\",  # Rain\n     \"USDOT NTAD\",  # Rain\n     \"USDOT NTAD\",  # Rain\n     \"FMCSA SMS API\",  # Freezing rain\n     \"FMCSA SMS API\",  # Freezing rain\n     \"FHWA RWIS\",  # Snow\n     \"FHWA RWIS\",  # Snow\n     \"FHWA RWIS\",  # Snow\n     \"USGS Streamflow\",  # Snow grains\n     \"NOAA NOWData\",  # Rain showers\n     \"NOAA NOWData\",  # Rain showers\n     \"USGS Flood Events\",  # Rain showers violent\n     \"FHWA CCAP\",  # Snow showers\n     \"FHWA CCAP\",  # Snow showers\n     \"NWS CAP Alerts\",  # Thunderstorm\n     \"NWS CAP Alerts\",  # Thunderstorm hail\n     \"DHS HSIN\"  # Severe hail\n)\n\n)\n\ncreate_enum_and_associate(\nduckdb_con, \n\"weather_code_enum\", \n\"weather_codes\",\ncode_frame\n)\n\nDropped existing ENUM type: weather_code_enum\n\n\nWarning: Unknown or uninitialised column: `code`.\n\n\nCreated ENUM type: weather_code_enum\n\n\n\n\n\ntable setuprTable &lt;- tbl(duckdb_con, \"weather_codes\") |&gt; collect()\n\nlocations_list = colnames(rTable)\n\nnotes_list &lt;- list(\n\"WMO weather code (1-99). See WMO Publication No. 306 for official code definitions.\",\n\"Plain-language weather condition description based on WMO standards.\",\n\"Recommended trucking operational response per FMCSA ¬ß392.14 and industry best practices.\",\n\"Numeric risk assessment (0-1 scale) where 0.7+ triggers DOT emergency protocols (¬ß392.16).\",\n\"Key FMCSA regulation sections requiring compliance during these conditions.\",\n\"Categorical risk level: Low (&lt;0.3), Moderate (0.3-0.5), High (0.5-0.7), Critical (0.7+).\",\n\"Percentage increase to cargo insurance premiums during these conditions. Based on TTClub 2023 claims data.\",\n\"Fuel consumption multiplier (1.0 = baseline). Accounts for reduced MPG in adverse conditions (EPA SmartWay data).\",\n\"Expected delay multiplier for route planning (1.0 = no delay). Derived from FHWA Highway Performance Monitoring System.\",\n\"FMCSA ¬ß396.11-13 mandated inspection protocols. 'Continuous monitoring' requires ELD-integrated systems.\",\n\"Teamsters National Master Freight Agreement Article 38 hazard pay provisions. Percentages added to base pay.\",\n\"ATA Technology & Maintenance Council wear indices. 1.0 = baseline maintenance costs.\",\n\"EPA SmartWay GHG emission factors. Includes idling, rerouting, and traction energy impacts.\",\n\"FHWA LRFR bridge capacity multiplier (1.0 = 80k lbs standard). Based on NBI Condition Reports.\",\n\"IBTTA inclement weather surcharge schedule. Applies to E-ZPass/Presto toll systems.\",\n\"CBP Trade Relief Interface Program data: Average commercial lane delays at POE.\",\n\"Official API endpoints for real-time routing. Requires agency credentials.\"\n)\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list)\n\ncalc_distinct_obs &lt;- code_frame |&gt;\ngroup_by(risk_score) |&gt;\ndistinct() |&gt;\nlength()\n\npal_df &lt;- tibble(\n  cols = locations_list,\n  pals = list(eval_palette(\"grDevices::RdYlGn\", calc_distinct_obs, 'c', -1))\n  #pals = list(eval_palette(\"basetheme::brutal\", 7, 'd', 1))\n)\n\nrTable &lt;- r_table_theming(\nrTable,\ntitle = \"Weather Code: As Data Type\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: World Meteorlogical Organization\"),\npal_df,\nmultiline_feet = TRUE,\ntable_font_size = pct(70),\ntarget_everything = TRUE,\ncolor_by_columns = \"risk_score\",\n#row_name_col = \"Model\"\n)\n\n\n\n‚ÄúWMO CODE TABLE 4677‚Äù (2025)\n\n‚ÄúWMO CODE TABLE 4677.‚Äù 2025. https://www.nodc.noaa.gov/archive/arc0021/0002199/1.1/data/0-data/HTML/WMO-CODE/WMO4677.HTM.\n\n\n\n\n\nTable¬†3: How the WMO codes are associated to weather events.\n\n\n\n\n\n\n\nWeather Code: As Data Type\n    \n\nweather_code1\n\n      description2\n\n      implication3\n\n      risk_score4\n\n      dot_compliance5\n\n      severity6\n\n      insurance_surcharge7\n\n      fuel_multiplier8\n\n      route_delay_factor9\n\n      safety_inspections10\n\n      driver_wage_premium11\n\n      equipment_wear_factor12\n\n      carbon_multiplier13\n\n      bridge_weight_limit14\n\n      toll_multiplier15\n\n      border_delay_hours16\n\n      reroute_api17\n\n    \n\n\n\n0\nClear sky\nNormal operations - No restrictions\n0.10\n¬ß392.14(a)\nLow\n0.00\n1.00\n1.00\nPre-trip only\n0.00\n1.00\n1.00\n1.00\n1.00\n0.0\nNA\n\n\n1\nMainly clear\nNormal operations - Increased vigilance\n0.15\n¬ß392.14(a)\nLow\n0.00\n1.00\n1.00\nPre-trip + mid-trip visual\n0.00\n1.02\n1.01\n1.00\n1.00\n0.0\nNA\n\n\n2\nPartly cloudy\nNormal operations - Monitor weather updates\n0.20\n¬ß392.14(a)\nLow\n0.05\n1.03\n1.00\nPre-trip + brake check\n0.05\n1.05\n1.03\n0.98\n1.05\n0.5\nHERE Weather API v3\n\n\n3\nOvercast\nReduced visibility - Maintain safe following distance\n0.25\n¬ß392.14(b)\nLow\n0.07\n1.05\n1.01\nPre-trip + hourly tire checks\n0.07\n1.07\n1.05\n0.95\n1.07\n0.7\nHERE Weather API v3\n\n\n45\nFog\nSpeed reduction required - Fog lights mandatory\n0.40\n¬ß392.14(b)+¬ß393.75(c)\nModerate\n0.10\n1.12\n1.05\nPre-trip + fog light checks\n0.15\n1.15\n1.12\n0.90\n1.15\n1.2\nFHWA ARCHIS Live\n\n\n48\nDepositing rime fog\nSpeed reduction required - Extreme caution\n0.50\n¬ß392.14(c)\nModerate\n0.15\n1.15\n1.08\nPre-trip + 30-min interval checks\n0.20\n1.20\n1.15\n0.85\n1.25\n2.0\nFHWA ARCHIS Live\n\n\n51\nDrizzle: light\nPotential minor delays - Road surface slickness\n0.30\n¬ß392.71(a)\nLow\n0.08\n1.07\n1.03\nPre-trip + 2hr brake tests\n0.10\n1.10\n1.07\n0.92\n1.10\n0.8\nGoogle Maps Directions\n\n\n53\nDrizzle: moderate\nSpeed restrictions - 15% reduction recommended\n0.35\n¬ß392.71(b)\nModerate\n0.12\n1.10\n1.06\nPre-trip + 1hr brake tests\n0.12\n1.12\n1.10\n0.88\n1.15\n1.1\nGoogle Maps Directions\n\n\n55\nDrizzle: dense\nMandatory speed reduction - 25%+\n0.45\n¬ß392.71(c)\nModerate\n0.18\n1.15\n1.20\nPre-trip + 30min brake tests\n0.18\n1.18\n1.15\n0.82\n1.22\n1.8\nGoogle Maps Directions\n\n\n56\nFreezing drizzle: light\nChain requirement - Level 1 traction advisory\n0.55\n¬ß392.16(a)\nHigh\n0.25\n1.25\n1.25\nPre-trip + axle temp monitoring\n0.25\n1.25\n1.22\n0.75\n1.35\n2.5\nFMCSA SMS API\n\n\n57\nFreezing drizzle: dense\nRoad closure likely - Avoid non-essential travel\n0.80\n¬ß392.16(c)\nCritical\n0.40\n1.40\n1.40\nContinuous monitoring required\n0.40\n1.40\n1.35\n0.60\n2.00\n6.0\nFMCSA SMS API\n\n\n61\nRain: slight\nIncreased stopping distance - 10% speed reduction\n0.30\n¬ß392.71(a)\nLow\n0.10\n1.08\n1.04\nPre-trip + wiper checks\n0.10\n1.12\n1.08\n0.93\n1.12\n0.9\nUSDOT NTAD\n\n\n63\nRain: moderate\n15-20% speed reduction - Check tire tread\n0.40\n¬ß392.71(b)\nModerate\n0.15\n1.12\n1.08\nPre-trip + 2hr wiper checks\n0.15\n1.15\n1.12\n0.87\n1.18\n1.3\nUSDOT NTAD\n\n\n65\nRain: heavy\n25%+ speed reduction - Possible detour routing\n0.60\n¬ß392.71(c)\nHigh\n0.25\n1.20\n1.25\nPre-trip + 30min wiper checks\n0.25\n1.25\n1.20\n0.78\n1.30\n2.2\nUSDOT NTAD\n\n\n66\nFreezing rain: light\nMandatory chains - Temperature monitoring\n0.65\n¬ß392.16(b)+¬ß393.95(d)\nHigh\n0.35\n1.30\n1.30\nPre-trip + chain integrity checks\n0.35\n1.35\n1.28\n0.65\n1.45\n3.5\nFMCSA SMS API\n\n\n67\nFreezing rain: heavy\nRoad closure imminent - Immediate stop advised\n0.85\n¬ß392.16(c)\nCritical\n0.50\n1.50\n1.50\nRoadside inspections mandatory\n0.50\n1.50\n1.45\n0.50\n1.80\n8.0\nFMCSA SMS API\n\n\n71\nSnow fall: slight\n15% speed reduction - Traction control engaged\n0.40\n¬ß392.14(b)+¬ß393.95(a)\nModerate\n0.20\n1.15\n1.20\nPre-trip + tire chain prep\n0.20\n1.20\n1.15\n0.85\n1.20\n1.5\nFHWA RWIS\n\n\n73\nSnow fall: moderate\n25% speed reduction - Chain requirement possible\n0.60\n¬ß392.14(c)+¬ß393.95(b)\nHigh\n0.30\n1.25\n1.30\nPre-trip + hourly chain checks\n0.30\n1.30\n1.25\n0.72\n1.35\n2.8\nFHWA RWIS\n\n\n75\nSnow fall: heavy\nRoad closure likely - Abandon shipment staging\n0.75\n¬ß392.16(c)\nCritical\n0.45\n1.40\n1.45\nContinuous chain monitoring\n0.45\n1.45\n1.40\n0.55\n1.60\n5.0\nFHWA RWIS\n\n\n77\nSnow grains\nSpeed restriction - Watch for black ice\n0.50\n¬ß392.14(c)\nModerate\n0.25\n1.20\n1.25\nPre-trip + sanding required\n0.25\n1.25\n1.20\n0.80\n1.25\n1.7\nUSGS Streamflow\n\n\n80\nRain showers: slight\nIncreased following distance - 4-second rule\n0.35\n¬ß392.14(b)\nModerate\n0.12\n1.10\n1.05\nPre-trip + drainage checks\n0.12\n1.10\n1.10\n0.91\n1.13\n1.0\nNOAA NOWData\n\n\n81\nRain showers: moderate\n20% speed reduction - Avoid lane changes\n0.50\n¬ß392.14(c)\nModerate\n0.20\n1.15\n1.20\nPre-trip + undercarriage checks\n0.20\n1.15\n1.15\n0.86\n1.20\n1.5\nNOAA NOWData\n\n\n82\nRain showers: violent\nImmediate parking advised - Flash flood risk\n0.70\n¬ß392.16(c)\nHigh\n0.35\n1.30\n1.35\nAbort trip + full inspection\n0.35\n1.30\n1.30\n0.60\n1.70\n4.0\nUSGS Flood Events\n\n\n85\nSnow showers: slight\nChain requirement - Trailer brake check\n0.60\n¬ß393.95(c)\nHigh\n0.30\n1.25\n1.30\nPre-trip + plow attachment\n0.30\n1.25\n1.25\n0.70\n1.40\n2.5\nFHWA CCAP\n\n\n86\nSnow showers: heavy\nRoad closure protocol activated\n0.80\n¬ß392.16(c)\nCritical\n0.50\n1.45\n1.50\nRoadside de-icing required\n0.50\n1.45\n1.40\n0.45\n2.10\n7.0\nFHWA CCAP\n\n\n95\nThunderstorm: slight or moderate\nDelay shipments - No open-top trailers\n0.65\n¬ß392.14(d)+¬ß393.75(e)\nHigh\n0.40\n1.35\n1.30\nPre-trip + lightning protocol\n0.40\n1.35\n1.35\n0.68\n1.55\n3.0\nNWS CAP Alerts\n\n\n96\nThunderstorm with slight hail\nImmediate stop - Seek shelter\n0.85\n¬ß392.16(c)\nCritical\n0.60\n1.60\n1.60\nImmediate shelter + inspection\n0.60\n1.60\n1.55\n0.40\n2.30\n9.0\nNWS CAP Alerts\n\n\n99\nThunderstorm with heavy hail\nCatastrophic risk - Emergency protocols\n0.95\n¬ß392.16(e)\nCritical\n0.80\n2.00\n2.00\nPost-storm forensic inspection\n0.80\n2.00\n1.80\n0.30\n3.00\n12.0\nDHS HSIN\n\n\n\nsource: World Meteorlogical Organization\n    \n\n\n\n1 WMO weather code (1-99). See WMO Publication No. 306 for official code definitions.\n    \n\n\n2 Plain-language weather condition description based on WMO standards.\n    \n\n\n3 Recommended trucking operational response per FMCSA ¬ß392.14 and industry best practices.\n    \n\n\n4 Numeric risk assessment (0-1 scale) where 0.7+ triggers DOT emergency protocols (¬ß392.16).\n    \n\n\n5 Key FMCSA regulation sections requiring compliance during these conditions.\n    \n\n\n6 Categorical risk level: Low (&lt;0.3), Moderate (0.3-0.5), High (0.5-0.7), Critical (0.7+).\n    \n\n\n7 Percentage increase to cargo insurance premiums during these conditions. Based on TTClub 2023 claims data.\n    \n\n\n8 Fuel consumption multiplier (1.0 = baseline). Accounts for reduced MPG in adverse conditions (EPA SmartWay data).\n    \n\n\n9 Expected delay multiplier for route planning (1.0 = no delay). Derived from FHWA Highway Performance Monitoring System.\n    \n\n\n10 FMCSA ¬ß396.11-13 mandated inspection protocols. 'Continuous monitoring' requires ELD-integrated systems.\n    \n\n\n11 Teamsters National Master Freight Agreement Article 38 hazard pay provisions. Percentages added to base pay.\n    \n\n\n12 ATA Technology & Maintenance Council wear indices. 1.0 = baseline maintenance costs.\n    \n\n\n13 EPA SmartWay GHG emission factors. Includes idling, rerouting, and traction energy impacts.\n    \n\n\n14 FHWA LRFR bridge capacity multiplier (1.0 = 80k lbs standard). Based on NBI Condition Reports.\n    \n\n\n15 IBTTA inclement weather surcharge schedule. Applies to E-ZPass/Presto toll systems.\n    \n\n\n16 CBP Trade Relief Interface Program data: Average commercial lane delays at POE.\n    \n\n\n17 Official API endpoints for real-time routing. Requires agency credentials.\n    \n\n\n\n\n\n\n\n\n\n\n\n\nCode-- Create ENUM for wind direction\nCREATE TYPE cardinal_direction_enum AS ENUM (\n     'N', \n     'NE', \n     'E', \n     'SE', \n     'S', \n     'SW', \n     'W', \n     'NW'\n);\n\nCREATE TYPE month_name_enum AS ENUM (\n     'January', \n     'February', \n     'March', \n     'April', \n     'May',\n     'June', \n     'July', \n     'August', \n     'September', \n     'October', \n     'November', \n     'December'\n);\n\nCREATE TYPE month_abb_enum AS ENUM (\n     'Jan', \n     'Feb', \n     'Mar', \n     'Apr', \n     'May',\n     'Jun', \n     'Jul', \n     'Aug', \n     'Sep', \n     'Oct', \n     'Nov', \n     'Dec'\n);\n\nCREATE TYPE weekday_name_enum AS ENUM (\n     'Sunday', \n     'Monday', \n     'Tuesday', \n     'Wednesday', \n     'Thursday', \n     'Friday', \n     'Saturday'\n);\n\nCREATE TYPE weekday_abb_enum AS ENUM (\n     'Sun', \n     'Mon', \n     'Tue', \n     'Wed', \n     'Thu', \n     'Fri', \n     'Sat'\n);\n\nCREATE TYPE visibility_cat_enum AS ENUM (\n     'Clearest (&gt;30 km)', \n     'Excellent (10-30 km)', \n     'Good (5-10 km)', \n     'Moderate (2-5 km)', \n     'Low (1-2 km)', \n     'Fog/Haze (&lt;1 km)'\n  );\n  \nCREATE TYPE speed_bin_enum AS ENUM (\n     '0-2', \n     '2-4', \n     '4-6', \n     '6-8', \n     '8-10', \n     '10+'\n     );"
  },
  {
    "objectID": "index.html#transformation-with-validation",
    "href": "index.html#transformation-with-validation",
    "title": "Route Assistant",
    "section": "Transformation with Validation",
    "text": "Transformation with Validation\nStages:\n\nCleaning (numeric formatting, type casting)\nFeature engineering (wind bins, direction calculations)\nTemporal decomposition (date/time elements extraction)\nCategorical labeling (visibility categories, enum mapping)\n\n\n\n\n\n\nTransformation\n\nDataset: Forecast, Next Day\n\nViews enhance transformation safety by acting as virtual tables, processing data dynamically without storing intermediates or risking source corruption. They enable iterative logic refinement, avoiding table rewrites. DuckDB optimizes view queries through computation pushdown, boosting efficiency. Self-documenting views clarify transformation logic, fostering collaboration and maintenance\n\n#| label: typeCastWeatherCode\n#| connection: duckdb_con\n\nCREATE OR REPLACE TABLE forecast_data AS\nSELECT \n     *,\n     weather_code::INTEGER::TEXT AS weather_code\nFROM \n     forecast_data;\n\n\nModular SQL, in-database transformation-- Create or replace the view with modular CTE's and explicit column lists\nCREATE OR REPLACE VIEW transformed_forecast AS\nWITH cleaned_data AS (\n  SELECT\n    date,\n    ROUND(temperature_2m::FLOAT, 1) AS temperature_2m,\n    precipitation_probability,\n    ROUND(precipitation::FLOAT, 3) AS precipitation,\n    ROUND(rain::FLOAT, 3) AS rain,\n    ROUND(showers::FLOAT, 3) AS showers,\n    ROUND(snowfall::FLOAT, 3) AS snowfall,\n    ROUND(snow_depth::FLOAT, 3) AS snow_depth,\n    weather_code,\n    ROUND(visibility::FLOAT, 1) AS visibility,\n    ROUND(wind_speed_10m::FLOAT, 2) AS wind_speed_10m,\n    wind_direction_10m,\n    latitude,\n    longitude\n  FROM forecast_data\n),\n\ntransformed_data AS (\n  SELECT\n    *,\n    -- Speed bin\n    CASE \n      WHEN wind_speed_10m &lt;= 2 THEN CAST('0-2' AS speed_bin_enum)\n      WHEN wind_speed_10m &lt;= 4 THEN CAST('2-4' AS speed_bin_enum)\n      WHEN wind_speed_10m &lt;= 6 THEN CAST('4-6' AS speed_bin_enum)\n      WHEN wind_speed_10m &lt;= 8 THEN CAST('6-8' AS speed_bin_enum)\n      WHEN wind_speed_10m &lt;= 10 THEN CAST('8-10' AS speed_bin_enum)\n      ELSE CAST('10+' AS speed_bin_enum)\n    END AS speed_bin,\n    -- Cardinal direction\n    CASE \n      WHEN wind_direction_10m BETWEEN 0 AND 22.5 THEN CAST('N' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 22.5 AND 67.5 THEN CAST('NE' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 67.5 AND 112.5 THEN CAST('E' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 112.5 AND 157.5 THEN CAST('SE' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 157.5 AND 202.5 THEN CAST('S' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 202.5 AND 247.5 THEN CAST('SW' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 247.5 AND 292.5 THEN CAST('W' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 292.5 AND 337.5 THEN CAST('NW' AS cardinal_direction_enum)\n      WHEN wind_direction_10m BETWEEN 337.5 AND 360 THEN CAST('N' AS cardinal_direction_enum)\n      ELSE NULL\n    END AS wind_direction_cardinal,\n    -- 15-degree direction bin (numeric)\n    FLOOR((wind_direction_10m - 1e-9) / 15) * 15 AS direction_bin\n  FROM cleaned_data\n),\n\nfinal_data AS (\n  SELECT\n    *,\n    -- Direction angle\n    CASE\n      WHEN wind_direction_cardinal = 'N' THEN 0\n      WHEN wind_direction_cardinal = 'NE' THEN 45\n      WHEN wind_direction_cardinal = 'E' THEN 90\n      WHEN wind_direction_cardinal = 'SE' THEN 135\n      WHEN wind_direction_cardinal = 'S' THEN 180\n      WHEN wind_direction_cardinal = 'SW' THEN 225\n      WHEN wind_direction_cardinal = 'W' THEN 270\n      WHEN wind_direction_cardinal = 'NW' THEN 315\n      ELSE NULL\n    END AS direction_angle,\n    -- Visibility category\n    CASE\n      WHEN visibility &gt; 30000 THEN CAST('Clearest (&gt;30 km)' AS visibility_cat_enum)\n      WHEN visibility &gt; 10000 THEN CAST('Excellent (10-30 km)' AS visibility_cat_enum)\n      WHEN visibility &gt; 5000 THEN CAST('Good (5-10 km)' AS visibility_cat_enum)\n      WHEN visibility &gt; 2000 THEN CAST('Moderate (2-5 km)' AS visibility_cat_enum)\n      WHEN visibility &gt; 1000 THEN CAST('Low (1-2 km)' AS visibility_cat_enum)\n      WHEN visibility &lt;= 1000 THEN CAST('Fog/Haze (&lt;1 km)' AS visibility_cat_enum)\n      ELSE NULL\n    END AS visibility_category,\n    -- Date parts\n    strftime(date, '%Y-%m-%d') AS date_only,\n    EXTRACT(YEAR FROM date) AS year,\n    EXTRACT(MONTH FROM date) AS month,\n    EXTRACT(hour FROM date) AS hour,\n    monthname(date)::month_name_enum AS month_name,\n    strftime(date, '%b')::month_abb_enum AS month_abb,\n    EXTRACT(DAY FROM date) AS day,\n    dayname(date)::weekday_name_enum AS weekday_name,\n    strftime(date, '%a')::weekday_abb_enum AS weekday_abb,\n    strftime(date, '%b %d') AS month_day,\n    strftime(date, '%H:%M:%S') AS time_only,\n    strptime('1970-01-01 ' || strftime(date, '%H:%M:%S'), '%Y-%m-%d %H:%M:%S') AS common_date\n  FROM transformed_data\n)\n\n-- Final output\nSELECT * FROM final_data;\n\n\n\n\n\nCodeSELECT * FROM transformed_forecast;\n\n\n\n\n\ntable setupr_df &lt;- viewOfForecast |&gt;\ndplyr::mutate(\n     date = as.character(date),\n     common_date = as.character(common_date)\n)\n\nlocations_list = colnames(r_df)\n\nnotes_list &lt;-c(\n  \"Date of the recorded data.\",\n  \"Temperature at 2 meters above ground.\",\n  \"Probability of precipitation.\",\n  \"Amount of precipitation.\",\n  \"Amount of rain.\",\n  \"Amount of showers.\",\n  \"Amount of snowfall.\",\n  \"Depth of snow.\",\n  \"Code representing the weather condition.\",\n  \"Visibility distance.\",\n  \"Wind speed at 10 meters above ground.\",\n  \"Wind direction at 10 meters above ground.\",\n  \"Vertical location coordinate.\", \n  \"Horizontal location coordinate.\",\n  \"Binned categories for wind speed.\",\n  \"Cardinal direction of the wind.\",\n  \"Binned categories for wind direction.\",\n  \"Numeric angle representing wind direction.\",\n  \"Categorized visibility levels.\",\n  \"Date without time\",\n  \"Year extracted from the date.\",\n  \"Month extracted from the date.\",\n  \"Hour extracted from the date.\",\n  \"Name of the month.\",\n  \"Abbreviated name of the month.\",\n  \"Day extracted from the date.\",\n  \"Name of the weekday.\",\n  \"Abbreviated name of the weekday.\",\n  \"Combined month and day.\",\n  \"Time extracted from the date.\",\n  \"Common date format for time-based analysis.\"\n)\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list\n)\n\npal_df &lt;- tibble(\n  cols = locations_list,\n  pals = list(eval_palette(\"grDevices::Rocket\", 10 , 'c', 1))\n)\n\nrTable &lt;- r_table_theming(\nr_df,\ntitle = \"Forecast Data Preview\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: \"),\npal_df,\nfootnotes_multiline = FALSE,\ntable_font_size = pct(70),\n#do_col_labels = TRUE,\n)\n\n\n\n\n\n\n\n\n\nTable¬†4\n\n\n\n\n\n\n\nForecast Data Preview\n    \n\ndate1\n\n      temperature_2m2\n\n      precipitation_probability3\n\n      precipitation4\n\n      rain5\n\n      showers6\n\n      snowfall7\n\n      snow_depth8\n\n      weather_code9\n\n      visibility10\n\n      wind_speed_10m11\n\n      wind_direction_10m12\n\n      latitude13\n\n      longitude14\n\n      speed_bin15\n\n      wind_direction_cardinal16\n\n      direction_bin17\n\n      direction_angle18\n\n      visibility_category19\n\n      date_only20\n\n      year21\n\n      month22\n\n      hour23\n\n      month_name24\n\n      month_abb25\n\n      day26\n\n      weekday_name27\n\n      weekday_abb28\n\n      month_day29\n\n      time_only30\n\n      common_date31\n\n    \n\n\n\n2025-04-05 22:00:00\n44.9\n45\n0.000\n0.000\n0\n0\n0\n3\n46587.9\n9.62\n360.000000\n38.7480\n-90.4390\n8-10\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-05\n2025\n4\n22\nApril\nApr\n5\nSaturday\nSat\nApr 05\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-05 23:00:00\n44.7\n16\n0.012\n0.012\n0\n0\n0\n51\n45275.6\n10.08\n357.455231\n38.7480\n-90.4390\n10+\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-05\n2025\n4\n23\nApril\nApr\n5\nSaturday\nSat\nApr 05\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-06\n44.5\n17\n0.000\n0.000\n0\n0\n0\n3\n47900.3\n11.11\n350.727478\n38.7480\n-90.4390\n10+\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n0\nApril\nApr\n6\nSunday\nSun\nApr 06\n00:00:00\n1970-01-01\n\n\n2025-04-06 01:00:00\n44.7\n4\n0.000\n0.000\n0\n0\n0\n3\n50524.9\n7.55\n348.023895\n38.7480\n-90.4390\n6-8\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n1\nApril\nApr\n6\nSunday\nSun\nApr 06\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-06 02:00:00\n44.7\n3\n0.000\n0.000\n0\n0\n0\n3\n53477.7\n5.88\n351.253906\n38.7480\n-90.4390\n4-6\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n2\nApril\nApr\n6\nSunday\nSun\nApr 06\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-06 03:00:00\n44.7\n3\n0.004\n0.004\n0\n0\n0\n51\n49868.8\n2.47\n354.805664\n38.7480\n-90.4390\n2-4\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n3\nApril\nApr\n6\nSunday\nSun\nApr 06\n03:00:00\n1970-01-01 03:00:00\n\n\n2025-04-06 04:00:00\n43.6\n3\n0.004\n0.004\n0\n0\n0\n51\n58727.0\n11.02\n347.092590\n38.7480\n-90.4390\n10+\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n4\nApril\nApr\n6\nSunday\nSun\nApr 06\n04:00:00\n1970-01-01 04:00:00\n\n\n2025-04-06 05:00:00\n42.2\n5\n0.000\n0.000\n0\n0\n0\n3\n66273.0\n9.63\n357.337067\n38.7480\n-90.4390\n8-10\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n5\nApril\nApr\n6\nSunday\nSun\nApr 06\n05:00:00\n1970-01-01 05:00:00\n\n\n2025-04-06 06:00:00\n42.2\n7\n0.000\n0.000\n0\n0\n0\n3\n61023.6\n6.11\n8.426887\n38.7480\n-90.4390\n6-8\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n6\nApril\nApr\n6\nSunday\nSun\nApr 06\n06:00:00\n1970-01-01 06:00:00\n\n\n2025-04-06 07:00:00\n41.9\n7\n0.000\n0.000\n0\n0\n0\n3\n61351.7\n9.64\n3.990843\n38.7480\n-90.4390\n8-10\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n7\nApril\nApr\n6\nSunday\nSun\nApr 06\n07:00:00\n1970-01-01 07:00:00\n\n\n2025-04-06 08:00:00\n41.4\n7\n0.000\n0.000\n0\n0\n0\n3\n60039.4\n8.72\n360.000000\n38.7480\n-90.4390\n8-10\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n8\nApril\nApr\n6\nSunday\nSun\nApr 06\n08:00:00\n1970-01-01 08:00:00\n\n\n2025-04-06 09:00:00\n40.7\n5\n0.000\n0.000\n0\n0\n0\n3\n61023.6\n8.35\n7.695961\n38.7480\n-90.4390\n8-10\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n9\nApril\nApr\n6\nSunday\nSun\nApr 06\n09:00:00\n1970-01-01 09:00:00\n\n\n2025-04-06 10:00:00\n40.0\n8\n0.000\n0.000\n0\n0\n0\n3\n60039.4\n9.62\n360.000000\n38.7480\n-90.4390\n8-10\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n10\nApril\nApr\n6\nSunday\nSun\nApr 06\n10:00:00\n1970-01-01 10:00:00\n\n\n2025-04-06 11:00:00\n39.4\n7\n0.000\n0.000\n0\n0\n0\n3\n57742.8\n10.41\n351.347534\n38.7480\n-90.4390\n10+\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n11\nApril\nApr\n6\nSunday\nSun\nApr 06\n11:00:00\n1970-01-01 11:00:00\n\n\n2025-04-06 12:00:00\n39.2\n7\n0.000\n0.000\n0\n0\n0\n3\n56102.4\n10.57\n6.072371\n38.7480\n-90.4390\n10+\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n12\nApril\nApr\n6\nSunday\nSun\nApr 06\n12:00:00\n1970-01-01 12:00:00\n\n\n2025-04-06 13:00:00\n39.4\n7\n0.000\n0.000\n0\n0\n0\n3\n54133.9\n8.64\n21.250580\n38.7480\n-90.4390\n8-10\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n13\nApril\nApr\n6\nSunday\nSun\nApr 06\n13:00:00\n1970-01-01 13:00:00\n\n\n2025-04-06 14:00:00\n40.2\n9\n0.000\n0.000\n0\n0\n0\n3\n56102.4\n8.82\n35.706783\n38.7480\n-90.4390\n8-10\nNE\n30\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n14\nApril\nApr\n6\nSunday\nSun\nApr 06\n14:00:00\n1970-01-01 14:00:00\n\n\n2025-04-06 15:00:00\n44.8\n11\n0.000\n0.000\n0\n0\n0\n3\n75787.4\n9.66\n42.184383\n38.7480\n-90.4390\n8-10\nNE\n30\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n15\nApril\nApr\n6\nSunday\nSun\nApr 06\n15:00:00\n1970-01-01 15:00:00\n\n\n2025-04-06 16:00:00\n44.6\n9\n0.000\n0.000\n0\n0\n0\n3\n75131.2\n8.59\n38.659828\n38.7480\n-90.4390\n8-10\nNE\n30\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n16\nApril\nApr\n6\nSunday\nSun\nApr 06\n16:00:00\n1970-01-01 16:00:00\n\n\n2025-04-06 17:00:00\n45.8\n5\n0.000\n0.000\n0\n0\n0\n3\n77755.9\n10.76\n20.695532\n38.7480\n-90.4390\n10+\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n17\nApril\nApr\n6\nSunday\nSun\nApr 06\n17:00:00\n1970-01-01 17:00:00\n\n\n2025-04-06 18:00:00\n45.4\n4\n0.000\n0.000\n0\n0\n0\n3\n82021.0\n8.85\n20.725639\n38.7480\n-90.4390\n8-10\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n18\nApril\nApr\n6\nSunday\nSun\nApr 06\n18:00:00\n1970-01-01 18:00:00\n\n\n2025-04-06 19:00:00\n46.6\n7\n0.000\n0.000\n0\n0\n0\n3\n84317.6\n11.04\n17.700521\n38.7480\n-90.4390\n10+\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n19\nApril\nApr\n6\nSunday\nSun\nApr 06\n19:00:00\n1970-01-01 19:00:00\n\n\n2025-04-06 20:00:00\n45.7\n5\n0.000\n0.000\n0\n0\n0\n3\n82021.0\n8.10\n6.340100\n38.7480\n-90.4390\n8-10\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n20\nApril\nApr\n6\nSunday\nSun\nApr 06\n20:00:00\n1970-01-01 20:00:00\n\n\n2025-04-06 21:00:00\n48.4\n6\n0.000\n0.000\n0\n0\n0\n3\n94160.1\n9.00\n26.564985\n38.7480\n-90.4390\n8-10\nNE\n15\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n21\nApril\nApr\n6\nSunday\nSun\nApr 06\n21:00:00\n1970-01-01 21:00:00\n\n\n2025-04-06 22:00:00\n47.9\n7\n0.000\n0.000\n0\n0\n0\n3\n88910.8\n8.03\n12.875007\n38.7480\n-90.4390\n8-10\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n22\nApril\nApr\n6\nSunday\nSun\nApr 06\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-06 23:00:00\n47.5\n7\n0.000\n0.000\n0\n0\n0\n3\n80052.5\n6.30\n16.504446\n38.7480\n-90.4390\n6-8\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n23\nApril\nApr\n6\nSunday\nSun\nApr 06\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-07\n45.9\n5\n0.000\n0.000\n0\n0\n0\n3\n65944.9\n4.03\n360.000000\n38.7480\n-90.4390\n4-6\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n0\nApril\nApr\n7\nMonday\nMon\nApr 07\n00:00:00\n1970-01-01\n\n\n2025-04-07 01:00:00\n45.0\n3\n0.000\n0.000\n0\n0\n0\n3\n58398.9\n2.24\n360.000000\n38.7480\n-90.4390\n2-4\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n1\nApril\nApr\n7\nMonday\nMon\nApr 07\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-07 02:00:00\n44.6\n2\n0.000\n0.000\n0\n0\n0\n3\n55118.1\n2.25\n354.289490\n38.7480\n-90.4390\n2-4\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n2\nApril\nApr\n7\nMonday\nMon\nApr 07\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-07 03:00:00\n44.3\n2\n0.000\n0.000\n0\n0\n0\n3\n56430.4\n1.50\n26.564985\n38.7480\n-90.4390\n0-2\nNE\n15\n45\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n3\nApril\nApr\n7\nMonday\nMon\nApr 07\n03:00:00\n1970-01-01 03:00:00\n\n\n2025-04-05 22:00:00\n45.1\n35\n0.039\n0.039\n0\n0\n0\n55\n5577.4\n8.13\n58.495792\n40.7128\n-74.0060\n8-10\nNE\n45\n45\nGood (5-10 km)\n2025-04-05\n2025\n4\n22\nApril\nApr\n5\nSaturday\nSat\nApr 05\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-05 23:00:00\n44.7\n23\n0.000\n0.000\n0\n0\n0\n3\n9842.5\n8.25\n40.601215\n40.7128\n-74.0060\n8-10\nNE\n30\n45\nGood (5-10 km)\n2025-04-05\n2025\n4\n23\nApril\nApr\n5\nSaturday\nSat\nApr 05\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-06\n44.7\n5\n0.000\n0.000\n0\n0\n0\n3\n42979.0\n10.02\n29.427368\n40.7128\n-74.0060\n10+\nNE\n15\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n0\nApril\nApr\n6\nSunday\nSun\nApr 06\n00:00:00\n1970-01-01\n\n\n2025-04-06 01:00:00\n43.4\n2\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n8.77\n19.359097\n40.7128\n-74.0060\n8-10\nN\n15\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n1\nApril\nApr\n6\nSunday\nSun\nApr 06\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-06 02:00:00\n42.7\n6\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n9.68\n33.690102\n40.7128\n-74.0060\n8-10\nNE\n30\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n2\nApril\nApr\n6\nSunday\nSun\nApr 06\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-06 03:00:00\n42.0\n8\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n9.30\n27.181028\n40.7128\n-74.0060\n8-10\nNE\n15\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n3\nApril\nApr\n6\nSunday\nSun\nApr 06\n03:00:00\n1970-01-01 03:00:00\n\n\n2025-04-06 04:00:00\n42.8\n18\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n6.71\n36.869980\n40.7128\n-74.0060\n6-8\nNE\n30\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n4\nApril\nApr\n6\nSunday\nSun\nApr 06\n04:00:00\n1970-01-01 04:00:00\n\n\n2025-04-06 05:00:00\n43.0\n49\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n6.19\n49.398785\n40.7128\n-74.0060\n6-8\nNE\n45\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n5\nApril\nApr\n6\nSunday\nSun\nApr 06\n05:00:00\n1970-01-01 05:00:00\n\n\n2025-04-06 06:00:00\n43.5\n63\n0.228\n0.228\n0\n0\n0\n63\n4265.1\n1.90\n135.000107\n40.7128\n-74.0060\n0-2\nSE\n135\n135\nModerate (2-5 km)\n2025-04-06\n2025\n4\n6\nApril\nApr\n6\nSunday\nSun\nApr 06\n06:00:00\n1970-01-01 06:00:00\n\n\n2025-04-06 07:00:00\n43.8\n42\n0.173\n0.173\n0\n0\n0\n63\n40026.2\n1.75\n309.805511\n40.7128\n-74.0060\n0-2\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n7\nApril\nApr\n6\nSunday\nSun\nApr 06\n07:00:00\n1970-01-01 07:00:00\n\n\n2025-04-06 08:00:00\n44.3\n28\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n2.00\n26.564985\n40.7128\n-74.0060\n0-2\nNE\n15\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n8\nApril\nApr\n6\nSunday\nSun\nApr 06\n08:00:00\n1970-01-01 08:00:00\n\n\n2025-04-06 09:00:00\n44.6\n15\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n2.20\n66.037506\n40.7128\n-74.0060\n2-4\nNE\n60\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n9\nApril\nApr\n6\nSunday\nSun\nApr 06\n09:00:00\n1970-01-01 09:00:00\n\n\n2025-04-06 10:00:00\n44.8\n13\n0.004\n0.004\n0\n0\n0\n51\n40026.2\n0.81\n146.309906\n40.7128\n-74.0060\n0-2\nSE\n135\n135\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n10\nApril\nApr\n6\nSunday\nSun\nApr 06\n10:00:00\n1970-01-01 10:00:00\n\n\n2025-04-06 11:00:00\n45.0\n19\n0.004\n0.004\n0\n0\n0\n51\n40026.2\n3.14\n4.085537\n40.7128\n-74.0060\n2-4\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n11\nApril\nApr\n6\nSunday\nSun\nApr 06\n11:00:00\n1970-01-01 11:00:00\n\n\n2025-04-06 12:00:00\n45.4\n16\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n6.00\n333.435028\n40.7128\n-74.0060\n4-6\nNW\n330\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n12\nApril\nApr\n6\nSunday\nSun\nApr 06\n12:00:00\n1970-01-01 12:00:00\n\n\n2025-04-06 13:00:00\n45.6\n25\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n5.52\n338.629303\n40.7128\n-74.0060\n4-6\nN\n330\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n13\nApril\nApr\n6\nSunday\nSun\nApr 06\n13:00:00\n1970-01-01 13:00:00\n\n\n2025-04-06 14:00:00\n46.5\n31\n0.000\n0.000\n0\n0\n0\n3\n40026.2\n4.43\n315.000092\n40.7128\n-74.0060\n4-6\nNW\n315\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n14\nApril\nApr\n6\nSunday\nSun\nApr 06\n14:00:00\n1970-01-01 14:00:00\n\n\n2025-04-06 15:00:00\n48.5\n41\n0.000\n0.000\n0\n0\n0\n3\n41010.5\n8.36\n344.475830\n40.7128\n-74.0060\n8-10\nN\n330\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n15\nApril\nApr\n6\nSunday\nSun\nApr 06\n15:00:00\n1970-01-01 15:00:00\n\n\n2025-04-06 16:00:00\n49.2\n28\n0.000\n0.000\n0\n0\n0\n3\n48556.4\n8.95\n360.000000\n40.7128\n-74.0060\n8-10\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n16\nApril\nApr\n6\nSunday\nSun\nApr 06\n16:00:00\n1970-01-01 16:00:00\n\n\n2025-04-06 17:00:00\n49.6\n14\n0.024\n0.024\n0\n0\n0\n53\n44291.3\n7.38\n345.963715\n40.7128\n-74.0060\n6-8\nN\n345\n0\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n17\nApril\nApr\n6\nSunday\nSun\nApr 06\n17:00:00\n1970-01-01 17:00:00\n\n\n2025-04-06 18:00:00\n49.1\n14\n0.047\n0.047\n0\n0\n0\n55\n42650.9\n7.02\n300.650574\n40.7128\n-74.0060\n6-8\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n18\nApril\nApr\n6\nSunday\nSun\nApr 06\n18:00:00\n1970-01-01 18:00:00\n\n\n2025-04-06 19:00:00\n50.4\n8\n0.008\n0.008\n0\n0\n0\n51\n53477.7\n8.82\n305.706787\n40.7128\n-74.0060\n8-10\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n19\nApril\nApr\n6\nSunday\nSun\nApr 06\n19:00:00\n1970-01-01 19:00:00\n\n\n2025-04-06 20:00:00\n49.2\n11\n0.008\n0.008\n0\n0\n0\n51\n56102.4\n7.33\n301.263672\n40.7128\n-74.0060\n6-8\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n20\nApril\nApr\n6\nSunday\nSun\nApr 06\n20:00:00\n1970-01-01 20:00:00\n\n\n2025-04-06 21:00:00\n48.2\n6\n0.000\n0.000\n0\n0\n0\n3\n67913.4\n7.33\n301.263672\n40.7128\n-74.0060\n6-8\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n21\nApril\nApr\n6\nSunday\nSun\nApr 06\n21:00:00\n1970-01-01 21:00:00\n\n\n2025-04-06 22:00:00\n47.3\n5\n0.000\n0.000\n0\n0\n0\n3\n71522.3\n6.53\n308.047089\n40.7128\n-74.0060\n6-8\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n22\nApril\nApr\n6\nSunday\nSun\nApr 06\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-06 23:00:00\n45.5\n9\n0.000\n0.000\n0\n0\n0\n3\n66929.1\n8.95\n323.130005\n40.7128\n-74.0060\n8-10\nNW\n315\n315\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n23\nApril\nApr\n6\nSunday\nSun\nApr 06\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-07\n45.1\n15\n0.000\n0.000\n0\n0\n0\n3\n58070.9\n3.33\n289.653900\n40.7128\n-74.0060\n2-4\nW\n285\n270\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n0\nApril\nApr\n7\nMonday\nMon\nApr 07\n00:00:00\n1970-01-01\n\n\n2025-04-07 01:00:00\n45.2\n16\n0.016\n0.016\n0\n0\n0\n51\n56758.5\n3.41\n293.198608\n40.7128\n-74.0060\n2-4\nNW\n285\n315\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n1\nApril\nApr\n7\nMonday\nMon\nApr 07\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-07 02:00:00\n44.8\n20\n0.016\n0.016\n0\n0\n0\n51\n55118.1\n4.27\n312.878906\n40.7128\n-74.0060\n4-6\nNW\n300\n315\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n2\nApril\nApr\n7\nMonday\nMon\nApr 07\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-07 03:00:00\n44.5\n31\n0.000\n0.000\n0\n0\n0\n3\n54133.9\n5.45\n340.820892\n40.7128\n-74.0060\n4-6\nN\n330\n0\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n3\nApril\nApr\n7\nMonday\nMon\nApr 07\n03:00:00\n1970-01-01 03:00:00\n\n\n2025-04-05 22:00:00\n82.0\n0\n0.000\n0.000\n0\n0\n0\n0\n295275.6\n6.99\n7.352293\n34.0522\n-118.2437\n6-8\nN\n0\n0\nClearest (&gt;30 km)\n2025-04-05\n2025\n4\n22\nApril\nApr\n5\nSaturday\nSat\nApr 05\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-05 23:00:00\n81.4\n0\n0.000\n0.000\n0\n0\n0\n0\n295275.6\n7.73\n247.890503\n34.0522\n-118.2437\n6-8\nW\n240\n270\nClearest (&gt;30 km)\n2025-04-05\n2025\n4\n23\nApril\nApr\n5\nSaturday\nSat\nApr 05\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-06\n74.5\n0\n0.000\n0.000\n0\n0\n0\n0\n218175.9\n15.62\n240.865799\n34.0522\n-118.2437\n10+\nSW\n240\n225\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n0\nApril\nApr\n6\nSunday\nSun\nApr 06\n00:00:00\n1970-01-01\n\n\n2025-04-06 01:00:00\n71.8\n0\n0.000\n0.000\n0\n0\n0\n0\n191929.1\n11.18\n253.739716\n34.0522\n-118.2437\n10+\nW\n240\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n1\nApril\nApr\n6\nSunday\nSun\nApr 06\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-06 02:00:00\n70.1\n0\n0.000\n0.000\n0\n0\n0\n0\n194225.7\n8.07\n250.559875\n34.0522\n-118.2437\n8-10\nW\n240\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n2\nApril\nApr\n6\nSunday\nSun\nApr 06\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-06 03:00:00\n65.2\n0\n0.000\n0.000\n0\n0\n0\n0\n202427.8\n5.48\n281.768250\n34.0522\n-118.2437\n4-6\nW\n270\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n3\nApril\nApr\n6\nSunday\nSun\nApr 06\n03:00:00\n1970-01-01 03:00:00\n\n\n2025-04-06 04:00:00\n62.4\n0\n0.000\n0.000\n0\n0\n0\n0\n191929.1\n5.19\n277.431305\n34.0522\n-118.2437\n4-6\nW\n270\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n4\nApril\nApr\n6\nSunday\nSun\nApr 06\n04:00:00\n1970-01-01 04:00:00\n\n\n2025-04-06 05:00:00\n60.5\n0\n0.000\n0.000\n0\n0\n0\n0\n187992.1\n3.82\n290.556122\n34.0522\n-118.2437\n2-4\nW\n285\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n5\nApril\nApr\n6\nSunday\nSun\nApr 06\n05:00:00\n1970-01-01 05:00:00\n\n\n2025-04-06 06:00:00\n58.7\n0\n0.000\n0.000\n0\n0\n0\n0\n174868.8\n3.26\n105.945465\n34.0522\n-118.2437\n2-4\nE\n105\n90\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n6\nApril\nApr\n6\nSunday\nSun\nApr 06\n06:00:00\n1970-01-01 06:00:00\n\n\n2025-04-06 07:00:00\n56.9\n0\n0.000\n0.000\n0\n0\n0\n0\n160433.1\n2.47\n84.805664\n34.0522\n-118.2437\n2-4\nE\n75\n90\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n7\nApril\nApr\n6\nSunday\nSun\nApr 06\n07:00:00\n1970-01-01 07:00:00\n\n\n2025-04-06 08:00:00\n54.9\n0\n0.000\n0.000\n0\n0\n0\n0\n137139.1\n4.70\n90.000000\n34.0522\n-118.2437\n4-6\nE\n75\n90\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n8\nApril\nApr\n6\nSunday\nSun\nApr 06\n08:00:00\n1970-01-01 08:00:00\n\n\n2025-04-06 09:00:00\n54.8\n0\n0.000\n0.000\n0\n0\n0\n0\n156168.0\n4.79\n52.594578\n34.0522\n-118.2437\n4-6\nNE\n45\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n9\nApril\nApr\n6\nSunday\nSun\nApr 06\n09:00:00\n1970-01-01 09:00:00\n\n\n2025-04-06 10:00:00\n54.8\n0\n0.000\n0.000\n0\n0\n0\n0\n168963.3\n5.52\n68.629311\n34.0522\n-118.2437\n4-6\nE\n60\n90\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n10\nApril\nApr\n6\nSunday\nSun\nApr 06\n10:00:00\n1970-01-01 10:00:00\n\n\n2025-04-06 11:00:00\n52.5\n0\n0.000\n0.000\n0\n0\n0\n0\n137467.2\n6.20\n64.359047\n34.0522\n-118.2437\n6-8\nNE\n60\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n11\nApril\nApr\n6\nSunday\nSun\nApr 06\n11:00:00\n1970-01-01 11:00:00\n\n\n2025-04-06 12:00:00\n52.4\n0\n0.000\n0.000\n0\n0\n0\n0\n146325.5\n6.30\n62.525658\n34.0522\n-118.2437\n6-8\nNE\n60\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n12\nApril\nApr\n6\nSunday\nSun\nApr 06\n12:00:00\n1970-01-01 12:00:00\n\n\n2025-04-06 13:00:00\n52.4\n0\n0.000\n0.000\n0\n0\n0\n0\n159448.8\n6.41\n60.751270\n34.0522\n-118.2437\n6-8\nNE\n60\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n13\nApril\nApr\n6\nSunday\nSun\nApr 06\n13:00:00\n1970-01-01 13:00:00\n\n\n2025-04-06 14:00:00\n53.3\n0\n0.000\n0.000\n0\n0\n0\n0\n178149.6\n6.76\n55.784248\n34.0522\n-118.2437\n6-8\nNE\n45\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n14\nApril\nApr\n6\nSunday\nSun\nApr 06\n14:00:00\n1970-01-01 14:00:00\n\n\n2025-04-06 15:00:00\n58.6\n0\n0.000\n0.000\n0\n0\n0\n0\n176509.2\n4.53\n57.094753\n34.0522\n-118.2437\n4-6\nNE\n45\n45\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n15\nApril\nApr\n6\nSunday\nSun\nApr 06\n15:00:00\n1970-01-01 15:00:00\n\n\n2025-04-06 16:00:00\n66.4\n0\n0.000\n0.000\n0\n0\n0\n0\n208989.5\n4.08\n99.462250\n34.0522\n-118.2437\n4-6\nE\n90\n90\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n16\nApril\nApr\n6\nSunday\nSun\nApr 06\n16:00:00\n1970-01-01 16:00:00\n\n\n2025-04-06 17:00:00\n71.4\n0\n0.000\n0.000\n0\n0\n0\n0\n227362.2\n3.33\n132.273621\n34.0522\n-118.2437\n2-4\nSE\n120\n135\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n17\nApril\nApr\n6\nSunday\nSun\nApr 06\n17:00:00\n1970-01-01 17:00:00\n\n\n2025-04-06 18:00:00\n76.7\n0\n0.000\n0.000\n0\n0\n0\n0\n268372.7\n2.69\n175.236450\n34.0522\n-118.2437\n2-4\nS\n165\n180\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n18\nApril\nApr\n6\nSunday\nSun\nApr 06\n18:00:00\n1970-01-01 18:00:00\n\n\n2025-04-06 19:00:00\n80.4\n0\n0.000\n0.000\n0\n0\n0\n0\n295275.6\n2.86\n218.659836\n34.0522\n-118.2437\n2-4\nSW\n210\n225\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n19\nApril\nApr\n6\nSunday\nSun\nApr 06\n19:00:00\n1970-01-01 19:00:00\n\n\n2025-04-06 20:00:00\n83.4\n0\n0.000\n0.000\n0\n0\n0\n0\n295275.6\n5.52\n248.629303\n34.0522\n-118.2437\n4-6\nW\n240\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n20\nApril\nApr\n6\nSunday\nSun\nApr 06\n20:00:00\n1970-01-01 20:00:00\n\n\n2025-04-06 21:00:00\n81.7\n0\n0.000\n0.000\n0\n0\n0\n0\n284120.8\n11.11\n260.727478\n34.0522\n-118.2437\n10+\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n21\nApril\nApr\n6\nSunday\nSun\nApr 06\n21:00:00\n1970-01-01 21:00:00\n\n\n2025-04-06 22:00:00\n79.1\n0\n0.000\n0.000\n0\n0\n0\n0\n272309.7\n11.81\n260.180756\n34.0522\n-118.2437\n10+\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n22\nApril\nApr\n6\nSunday\nSun\nApr 06\n22:00:00\n1970-01-01 22:00:00\n\n\n2025-04-06 23:00:00\n77.6\n0\n0.000\n0.000\n0\n0\n0\n0\n270669.3\n12.29\n259.508575\n34.0522\n-118.2437\n10+\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-06\n2025\n4\n23\nApril\nApr\n6\nSunday\nSun\nApr 06\n23:00:00\n1970-01-01 23:00:00\n\n\n2025-04-07\n75.0\n0\n0.000\n0.000\n0\n0\n0\n0\n248031.5\n11.81\n260.180756\n34.0522\n-118.2437\n10+\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n0\nApril\nApr\n7\nMonday\nMon\nApr 07\n00:00:00\n1970-01-01\n\n\n2025-04-07 01:00:00\n70.3\n0\n0.000\n0.000\n0\n0\n0\n0\n193569.6\n11.07\n261.869995\n34.0522\n-118.2437\n10+\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n1\nApril\nApr\n7\nMonday\nMon\nApr 07\n01:00:00\n1970-01-01 01:00:00\n\n\n2025-04-07 02:00:00\n65.5\n0\n0.000\n0.000\n0\n0\n0\n0\n147309.7\n7.84\n266.729584\n34.0522\n-118.2437\n6-8\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n2\nApril\nApr\n7\nMonday\nMon\nApr 07\n02:00:00\n1970-01-01 02:00:00\n\n\n2025-04-07 03:00:00\n61.3\n0\n0.000\n0.000\n0\n0\n0\n0\n110892.4\n3.91\n256.759460\n34.0522\n-118.2437\n2-4\nW\n255\n270\nClearest (&gt;30 km)\n2025-04-07\n2025\n4\n3\nApril\nApr\n7\nMonday\nMon\nApr 07\n03:00:00\n1970-01-01 03:00:00\n\n\n\nsource:\n    \n\n\n        \n1 Date of the recorded data., 2 Temperature at 2 meters above ground., 3 Probability of precipitation., 4 Amount of precipitation., 5 Amount of rain., 6 Amount of showers., 7 Amount of snowfall., 8 Depth of snow., 9 Code representing the weather condition., 10 Visibility distance., 11 Wind speed at 10 meters above ground., 12 Wind direction at 10 meters above ground., 13 Vertical location coordinate., 14 Horizontal location coordinate., 15 Binned categories for wind speed., 16 Cardinal direction of the wind., 17 Binned categories for wind direction., 18 Numeric angle representing wind direction., 19 Categorized visibility levels., 20 Date without time, 21 Year extracted from the date., 22 Month extracted from the date., 23 Hour extracted from the date., 24 Name of the month., 25 Abbreviated name of the month., 26 Day extracted from the date., 27 Name of the weekday., 28 Abbreviated name of the weekday., 29 Combined month and day., 30 Time extracted from the date., 31 Common date format for time-based analysis.\n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nReplace the forecast_data table; optionally, create an output preview object.-- Replace the historical weather table\nCREATE OR REPLACE TABLE forecast_data AS\nSELECT * FROM transformed_forecast;\n\n-- Preview results \nSELECT * FROM forecast_data LIMIT 10;\n\n\n\n\n\nCodeDROP VIEW transformed_forecast;\n\n\n\n\n\nCodeVACUUM forecast_data;\n\n\n\nDataset: Historical, 1974-2024\n#| label: \"preValidationHistorical\"\n#| code-summary: \"Pre-Transformation Validation (Raw Data)\"\n#| code-fold: true\n\n# Using existing DuckDB connection\nraw_data &lt;- tbl(duckdb_con, \"historical_data\")\n\n# Create validation agent for raw data\nraw_agent &lt;- create_agent(tbl = raw_data,\n                          actions = action_levels(warn_at = 0.01, stop_at = 0.05)) |&gt;\n     # Core structure validation\n     col_exists(\n          vars(\n               date,\n               temperature_2m,\n               precipitation,\n               rain,\n               snowfall,\n               snow_depth,\n               weather_code,\n               wind_speed,\n               wind_direction\n          )\n     ) |&gt;\n     col_is_date(vars(date)) |&gt;\n     # Value range checks\n     col_vals_between(vars(temperature_2m), -50, 130, na_pass = TRUE) |&gt;\n     col_vals_gte(vars(precipitation), 0, na_pass = TRUE) |&gt;\n     \n     # Add valid codes\n    # col_vals_in_set(vars(weather_code), set = codes) |&gt; \n     \n     col_vals_between(vars(wind_direction_10m), 0, 360, na_pass = TRUE) |&gt;\n     \n     interrogate()\n\n#| label: \"outputRawAgent\"\n#| echo: false\nraw_agent \n\n\n\nModular SQL, in-database transformation-- Create or replace the view with modular CTEs and explicit column lists\nCREATE OR REPLACE VIEW transformed_historical AS\nWITH cleaned_data AS (\nSELECT\n     date::TIMESTAMP AS date,\n     ROUND(temperature_2m::FLOAT, 1) AS temperature_2m,\n     ROUND(precipitation::FLOAT, 3) AS precipitation,\n     ROUND(rain::FLOAT, 3) AS rain,\n     ROUND(snowfall::FLOAT, 3) AS snowfall,\n     ROUND(snow_depth::FLOAT, 3) AS snow_depth,\n     weather_code AS weather_code,\n     ROUND(wind_speed_10m::FLOAT, 2) AS wind_speed_10m,\n     wind_direction_10m AS wind_direction_10m,\n     latitude AS latitude,\n     longitude AS longitude\nFROM historical_data\n),\n\ntransformed_data AS (\nSELECT\n     *,\n-- Speed bin\nCASE \nWHEN wind_speed_10m &lt;= 2 THEN CAST('0-2' AS speed_bin_enum)\nWHEN wind_speed_10m &lt;= 4 THEN CAST('2-4' AS speed_bin_enum)\nWHEN wind_speed_10m &lt;= 6 THEN CAST('4-6' AS speed_bin_enum)\nWHEN wind_speed_10m &lt;= 8 THEN CAST('6-8' AS speed_bin_enum)\nWHEN wind_speed_10m &lt;= 10 THEN CAST('8-10' AS speed_bin_enum)\nELSE CAST('10+' AS speed_bin_enum)\nEND AS speed_bin,\n-- Cardinal direction\nCASE \nWHEN wind_direction_10m BETWEEN 0 AND 22.5 THEN CAST('N' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 22.5 AND 67.5 THEN CAST('NE' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 67.5 AND 112.5 THEN CAST('E' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 112.5 AND 157.5 THEN CAST('SE' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 157.5 AND 202.5 THEN CAST('S' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 202.5 AND 247.5 THEN CAST('SW' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 247.5 AND 292.5 THEN CAST('W' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 292.5 AND 337.5 THEN CAST('NW' AS cardinal_direction_enum)\nWHEN wind_direction_10m BETWEEN 337.5 AND 360 THEN CAST('N' AS cardinal_direction_enum)\nELSE NULL\nEND AS wind_direction_cardinal,\n-- 15-degree direction bin (numeric)\nFLOOR((wind_direction_10m - 1e-9) / 15) * 15 AS direction_bin\nFROM cleaned_data\n),\n\nfinal_data AS (\nSELECT\n     *,\n     -- Direction angle\n     CASE\n          WHEN wind_direction_cardinal = 'N' THEN 0\n          WHEN wind_direction_cardinal = 'NE' THEN 45\n          WHEN wind_direction_cardinal = 'E' THEN 90\n          WHEN wind_direction_cardinal = 'SE' THEN 135\n          WHEN wind_direction_cardinal = 'S' THEN 180\n          WHEN wind_direction_cardinal = 'SW' THEN 225\n          WHEN wind_direction_cardinal = 'W' THEN 270\n          WHEN wind_direction_cardinal = 'NW' THEN 315\n     ELSE NULL\n     END AS direction_angle,\n-- Date parts\nstrftime(date, '%m-%d-%Y') AS date_only,\nEXTRACT(YEAR FROM date) AS year,\nEXTRACT(MONTH FROM date) AS month,\nEXTRACT(hour FROM date) AS hour,\nmonthname(date)::month_name_enum AS month_name,\nstrftime(date, '%b')::month_abb_enum AS month_abb,\nEXTRACT(DAY FROM date) AS day,\ndayname(date)::weekday_name_enum AS weekday_name,\nstrftime(date, '%a')::weekday_abb_enum AS weekday_abb,\nstrftime(date, '%b %d') AS month_day,\nstrftime(date, '%H:%M:%S') AS time_only,\nstrptime('1970-01-01 ' || strftime(date, '%H:%M:%S'), '%Y-%m-%d %H:%M:%S') AS common_date\nFROM transformed_data\n)\n\n-- Final output\nSELECT * FROM final_data;\n\n\n\n#| label: \"postTransformHistorical\"\n#| code-summary: \"Post-Transformation Validation\"\n#| code-fold: true\n\ntransformed_data &lt;- tbl(duckdb_con, \"transformed_historical\")\n\ntrans_agent &lt;- create_agent(\n     tbl = transformed_data, label = \"Post-Transformed Validation\", actions = action_levels(warn_at = 0.01, stop_at = 0.05)\n) |&gt;\n     # Validate enum mappings\n     col_is_factor(vars(weather_code, speed_bin, wind_direction_cardinal)) |&gt;\n     \n     # Validate temperature decimal places (simpler arithmetic check)\n     col_vals_expr(\n          expr = ~ MOD(temperature_2m * 10, 1) == 0,\n          label = \"Temperature has 1 decimal place\",\n          #na_pass = TRUE  # Skip NA values automatically\n     ) |&gt;\n\n     # Validate speed bin logic\n     col_vals_in_set(vars(speed_bin), set = c(\"0-2\", \"2-4\", \"4-6\", \"6-8\", \"8-10\", \"10+\")) |&gt;\n     \n     # Date validations\n     col_vals_between(vars(year), 1974, 2024) |&gt;\n     col_vals_between(vars(month), 1, 12) |&gt;\n     col_vals_between(vars(day), 1, 31) |&gt;\n     \n     # Month/weekday validations\n     col_vals_in_set(vars(month_name), set = month.name) |&gt;\n     col_vals_in_set(vars(month_abb), set = month.abb) |&gt;\n     col_vals_in_set(\n          vars(weekday_name),\n          set = c(\n               \"Sunday\",\n               \"Monday\",\n               \"Tuesday\",\n               \"Wednesday\",\n               \"Thursday\",\n               \"Friday\",\n               \"Saturday\"\n          )\n     ) |&gt;\n     col_vals_in_set(vars(weekday_abb),\n                     set = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")) |&gt;\n     \n     # Alternative month_day validation\n     col_vals_expr(\n          expr = ~ month_day == sql(\"STRFTIME(date, '%b %d')\"),\n          label = \"Month/day format matches date\"\n     ) |&gt;\n     \n     # Alternative time_only validation\n     col_vals_expr(\n          expr = ~ time_only == sql(\"STRFTIME(date, '%H:%M:%S')\"),\n          label = \"Time format matches date\"\n     ) |&gt;\n\n     # Common date validation\n     col_is_date(vars(common_date)) |&gt;\n     col_vals_between(\n          vars(common_date),\n          left = as.POSIXct(\"1970-01-01 00:00:00\"),\n          right = as.POSIXct(\"1970-01-01 23:59:59\")\n     ) |&gt;\n     \n     # Wind direction validations\n     col_vals_between(vars(direction_angle), 0, 315, na_pass = TRUE) |&gt;\n     col_vals_in_set(vars(wind_direction_cardinal),\n                     set = c(\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\")) |&gt;\n     \n     # Cross-validations using SQL expressions\n     col_vals_expr(\n          expr = ~ time_only == sql(\"STRFTIME(common_date, '%H:%M:%S')\"),\n          label = \"Time matches common_date\"\n     ) |&gt;\n     \n     col_vals_expr(\n          expr = ~ month_name == sql(\n               \"CASE month\n                WHEN 1 THEN 'January' WHEN 2 THEN 'February'\n                WHEN 3 THEN 'March' WHEN 4 THEN 'April'\n                WHEN 5 THEN 'May' WHEN 6 THEN 'June'\n                WHEN 7 THEN 'July' WHEN 8 THEN 'August'\n                WHEN 9 THEN 'September' WHEN 10 THEN 'October'\n                WHEN 11 THEN 'November' WHEN 12 THEN 'December' END\"\n          ),\n          label = \"Month name matches month number\"\n     ) |&gt;\n     \n     col_vals_expr(expr = ~ weekday_abb == sql(\"SUBSTR(weekday_name, 1, 3)\"),\n                   label = \"Weekday abbreviation matches name\") |&gt;\n     \n     interrogate()\n\n#| label: \"transAgent\"\n#| echo: false\ntrans_agent\n\n\n\nCode-- Final output\nSELECT * FROM transformed_historical LIMIT 20;\n\n\n\n\n\ntable setupr_df &lt;- viewOfHistorical |&gt;\ndplyr::mutate(\n     date = as.character(date),\n     common_date = as.character(common_date)\n)\n\nlocations_list = colnames(r_df)\n\nnotes_list &lt;- c(\n     \"Date of the recorded data.\",\n     \"Temperature at 2 meters above ground.\",\n     \"Amount of precipitation.\",\n     \"Amount of rain.\",\n     \"Amount of snowfall.\",\n     \"Depth of snow.\",\n     \"Code representing the weather condition.\",\n     \"Wind speed at 10 meters above ground.\",\n     \"Wind direction at 10 meters above ground.\",\n     \"Vertical location coordinate.\",\n     \"Horizontal location coordinate.\",\n     \"Cardinal direction of the wind.\",\n     \"Binned categories for wind speed.\",\n     \"Binned categories for direction angle.\",\n     \"Numeric angle representing wind direction.\",\n     \"Date without time\",\n     \"Year extracted from the date.\",\n     \"Month extracted from the date.\",\n     \"Hour extracted from the date.\",\n     \"Name of the month.\",\n     \"Abbreviated name of the month.\",\n     \"Day extracted from the date.\",\n     \"Name of the weekday.\",\n     \"Abbreviated name of the weekday.\",\n     \"Combined month and day.\",\n     \"Time extracted from the date.\",\n     \"Common date format for time-based analysis.\"\n)\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list\n)\n\npal_df &lt;- tibble(\n  cols = locations_list,\n  pals = list(eval_palette(\"grDevices::Rocket\", 10 , 'c', 1))\n)\n\nrTable &lt;- r_table_theming(\nr_df,\ntitle = \"Historical Data Preview\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: \"),\npal_df,\nfootnotes_multiline = FALSE,\ntable_font_size = pct(70),\n#do_col_labels = TRUE,\n)\n\n\n\n\n\n\n\n\n\nTable¬†5\n\n\n\n\n\n\n\nHistorical Data Preview\n    \n\ndate1\n\n      temperature_2m2\n\n      precipitation3\n\n      rain4\n\n      snowfall5\n\n      snow_depth6\n\n      weather_code7\n\n      wind_speed_10m8\n\n      wind_direction_10m9\n\n      latitude10\n\n      longitude11\n\n      speed_bin12\n\n      wind_direction_cardinal13\n\n      direction_bin14\n\n      direction_angle15\n\n      date_only16\n\n      year17\n\n      month18\n\n      hour19\n\n      month_name20\n\n      month_abb21\n\n      day22\n\n      weekday_name23\n\n      weekday_abb24\n\n      month_day25\n\n      time_only26\n\n      common_date27\n\n    \n\n\n\n1974-01-01 05:00:00\n50.2\n0\n0\n0\n0\n3\n3.39\n97.59455\n33.4484\n-112.074\n2-4\nE\n90\n90\n01-01-1974\n1974\n1\n5\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n05:00:00\n1970-01-01 05:00:00\n\n\n1974-01-01 06:00:00\n48.1\n0\n0\n0\n0\n2\n4.03\n93.17977\n33.4484\n-112.074\n4-6\nE\n90\n90\n01-01-1974\n1974\n1\n6\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n06:00:00\n1970-01-01 06:00:00\n\n\n1974-01-01 07:00:00\n45.5\n0\n0\n0\n0\n1\n4.92\n90.00000\n33.4484\n-112.074\n4-6\nE\n75\n90\n01-01-1974\n1974\n1\n7\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n07:00:00\n1970-01-01 07:00:00\n\n\n1974-01-01 08:00:00\n44.2\n0\n0\n0\n0\n2\n4.72\n84.55976\n33.4484\n-112.074\n4-6\nE\n75\n90\n01-01-1974\n1974\n1\n8\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n08:00:00\n1970-01-01 08:00:00\n\n\n1974-01-01 09:00:00\n43.2\n0\n0\n0\n0\n3\n4.56\n78.69010\n33.4484\n-112.074\n4-6\nE\n75\n90\n01-01-1974\n1974\n1\n9\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n09:00:00\n1970-01-01 09:00:00\n\n\n1974-01-01 10:00:00\n42.5\n0\n0\n0\n0\n2\n4.72\n84.55976\n33.4484\n-112.074\n4-6\nE\n75\n90\n01-01-1974\n1974\n1\n10\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n10:00:00\n1970-01-01 10:00:00\n\n\n1974-01-01 11:00:00\n41.9\n0\n0\n0\n0\n1\n4.97\n82.23492\n33.4484\n-112.074\n4-6\nE\n75\n90\n01-01-1974\n1974\n1\n11\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n11:00:00\n1970-01-01 11:00:00\n\n\n1974-01-01 12:00:00\n41.6\n0\n0\n0\n0\n0\n5.05\n102.80426\n33.4484\n-112.074\n4-6\nE\n90\n90\n01-01-1974\n1974\n1\n12\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n12:00:00\n1970-01-01 12:00:00\n\n\n1974-01-01 13:00:00\n41.1\n0\n0\n0\n0\n0\n5.00\n116.56499\n33.4484\n-112.074\n4-6\nSE\n105\n135\n01-01-1974\n1974\n1\n13\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n13:00:00\n1970-01-01 13:00:00\n\n\n1974-01-01 14:00:00\n41.0\n0\n0\n0\n0\n0\n6.36\n129.28938\n33.4484\n-112.074\n6-8\nSE\n120\n135\n01-01-1974\n1974\n1\n14\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n14:00:00\n1970-01-01 14:00:00\n\n\n1974-01-01 15:00:00\n41.3\n0\n0\n0\n0\n1\n6.67\n129.55963\n33.4484\n-112.074\n6-8\nSE\n120\n135\n01-01-1974\n1974\n1\n15\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n15:00:00\n1970-01-01 15:00:00\n\n\n1974-01-01 16:00:00\n45.0\n0\n0\n0\n0\n1\n9.03\n131.98714\n33.4484\n-112.074\n8-10\nSE\n120\n135\n01-01-1974\n1974\n1\n16\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n16:00:00\n1970-01-01 16:00:00\n\n\n1974-01-01 17:00:00\n53.6\n0\n0\n0\n0\n1\n8.63\n148.78166\n33.4484\n-112.074\n8-10\nSE\n135\n135\n01-01-1974\n1974\n1\n17\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n17:00:00\n1970-01-01 17:00:00\n\n\n1974-01-01 18:00:00\n59.6\n0\n0\n0\n0\n1\n8.75\n175.60138\n33.4484\n-112.074\n8-10\nS\n165\n180\n01-01-1974\n1974\n1\n18\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n18:00:00\n1970-01-01 18:00:00\n\n\n1974-01-01 19:00:00\n64.2\n0\n0\n0\n0\n3\n12.85\n211.47679\n33.4484\n-112.074\n10+\nSW\n210\n225\n01-01-1974\n1974\n1\n19\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n19:00:00\n1970-01-01 19:00:00\n\n\n1974-01-01 20:00:00\n65.7\n0\n0\n0\n0\n3\n22.42\n233.93050\n33.4484\n-112.074\n10+\nSW\n225\n225\n01-01-1974\n1974\n1\n20\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n20:00:00\n1970-01-01 20:00:00\n\n\n1974-01-01 21:00:00\n65.9\n0\n0\n0\n0\n3\n25.00\n236.30991\n33.4484\n-112.074\n10+\nSW\n225\n225\n01-01-1974\n1974\n1\n21\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n21:00:00\n1970-01-01 21:00:00\n\n\n1974-01-01 22:00:00\n64.9\n0\n0\n0\n0\n3\n21.06\n247.52052\n33.4484\n-112.074\n10+\nW\n240\n270\n01-01-1974\n1974\n1\n22\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n22:00:00\n1970-01-01 22:00:00\n\n\n1974-01-01 23:00:00\n63.3\n0\n0\n0\n0\n3\n19.52\n265.39999\n33.4484\n-112.074\n10+\nW\n255\n270\n01-01-1974\n1974\n1\n23\nJanuary\nJan\n1\nTuesday\nTue\nJan 01\n23:00:00\n1970-01-01 23:00:00\n\n\n1974-01-02\n60.1\n0\n0\n0\n0\n3\n16.48\n277.80008\n33.4484\n-112.074\n10+\nW\n270\n270\n01-02-1974\n1974\n1\n0\nJanuary\nJan\n2\nWednesday\nWed\nJan 02\n00:00:00\n1970-01-01\n\n\n\nsource:\n    \n\n\n        \n1 Date of the recorded data., 2 Temperature at 2 meters above ground., 3 Amount of precipitation., 4 Amount of rain., 5 Amount of snowfall., 6 Depth of snow., 7 Code representing the weather condition., 8 Wind speed at 10 meters above ground., 9 Wind direction at 10 meters above ground., 10 Vertical location coordinate., 11 Horizontal location coordinate., 12 Cardinal direction of the wind., 13 Binned categories for wind speed., 14 Binned categories for direction angle., 15 Numeric angle representing wind direction., 16 Date without time, 17 Year extracted from the date., 18 Month extracted from the date., 19 Hour extracted from the date., 20 Name of the month., 21 Abbreviated name of the month., 22 Day extracted from the date., 23 Name of the weekday., 24 Abbreviated name of the weekday., 25 Combined month and day., 26 Time extracted from the date., 27 Common date format for time-based analysis.\n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nReplace the historical weather tableCREATE OR REPLACE TABLE historical_data AS\nSELECT * FROM transformed_historical;\n\n\n\n\n\nDrop the viewDROP VIEW transformed_historical;\n\n\n\n\n\nRefresh database statistics for the query plannerVACUUM historical_data;"
  },
  {
    "objectID": "index.html#weather-code-stats",
    "href": "index.html#weather-code-stats",
    "title": "Route Assistant",
    "section": "Weather Code Stats",
    "text": "Weather Code Stats\nForecast\n\nInstall and load DuckDB‚Äôs spatial library.INSTALL spatial; LOAD spatial;\n\n\n\nContextualize weather data by linking codes to actionable insights using in-database processing.WITH routes AS (\n  SELECT * FROM (\n    VALUES\n    (101, 38.748, -90.439, 40.7128, -74.0060, 280),\n    (102, 40.7128, -74.0060, 34.0522, -118.2437, 220)\n  ) AS t(route_id, start_lat, start_lon, end_lat, end_lon, distance_miles)\n),\n\nroute_geometries AS (\n  SELECT\n    route_id,\n    distance_miles,\n    ST_MakeLine(\n      ST_Point(start_lon, start_lat),\n      ST_Point(end_lon, end_lat)\n    ) AS route_line\n  FROM routes\n),\n\nenhanced_forecast AS (\n  SELECT\n    *,\n    ST_Point(longitude, latitude) AS forecast_point\n  FROM forecast_data\n),\n\nroute_weather_join AS (\n  SELECT\n    rg.route_id,\n    rg.distance_miles,\n    wc.*,\n    ST_Distance(rg.route_line, ef.forecast_point) AS distance_from_route\n  FROM route_geometries rg\n  JOIN enhanced_forecast ef\n    ON ST_Intersects(ST_Buffer(rg.route_line, 0.1), ef.forecast_point)\n  JOIN weather_codes wc USING (weather_code)\n)\n\nSELECT\n  route_id,\n  MAX(severity) AS max_severity,\n  SUM(risk_score) AS total_risk,\n  AVG(fuel_multiplier) * distance_miles AS projected_fuel,\n  SUM(risk_score * distance_miles / (60 * 10)) AS total_delay,\n  COUNT(*) AS weather_points_impacted\nFROM route_weather_join\nGROUP BY route_id, distance_miles\nORDER BY route_id ASC;\n\n\nSUM(route_delay_factor * distance_miles / 60) + SUM(border_delay_hours) AS total_delay,\n\ntable setuplocations_list = colnames(exampleOutput)\n\nnotes_list &lt;- c(\n  \"Unique identifier for the transportation route\",\n  \"Highest severity level of weather impacts along the route (Low/Moderate/High/Critical)\",\n  \"Sum of all risk scores from weather events affecting the route\",\n  \"Estimated total fuel consumption adjusted for weather multipliers\",\n  \"Cumulative delay time (hours) due to weather-related speed reductions\",\n  \"Number of geographic points along the route affected by adverse weather\"\n)\n\nfootnotes_df &lt;- tibble(\n  notes = notes_list, \n  locations = locations_list)\n\npal_df &lt;- tibble(\n  cols = locations_list\n#  pals = list(eval_palette(\"viridis::viridis\", 2, 'c', 1))\n)\n\nrTable &lt;- r_table_theming(\nexampleOutput,\ntitle = \"Experimental Route Attributes\",\nsubtitle = NULL,\nfootnotes_df,\nsource_note = md(\"**source**: \"),\npal_df,\nmultiline_feet = TRUE,\ntable_font_size = pct(95),\ntarget_everything = TRUE,\n#row_name_col = \"route_id\",\n)\n\n\n\n\n\n\n\n\nTable¬†6\n\n\n\n\n\n\n\nExperimental Route Attributes\n    \n\nroute_id1\n\n      max_severity2\n\n      total_risk3\n\n      projected_fuel4\n\n      total_delay5\n\n      weather_points_impacted6\n\n    \n\n\n\n101\nModerate\n16.25\n296.66\n7.583333\n60\n\n\n102\nModerate\n11.60\n227.37\n4.253333\n60\n\n\n\nsource:\n    \n\n\n\n1 Unique identifier for the transportation route\n    \n\n\n2 Highest severity level of weather impacts along the route (Low/Moderate/High/Critical)\n    \n\n\n3 Sum of all risk scores from weather events affecting the route\n    \n\n\n4 Estimated total fuel consumption adjusted for weather multipliers\n    \n\n\n5 Cumulative delay time (hours) due to weather-related speed reductions\n    \n\n\n6 Number of geographic points along the route affected by adverse weather\n    \n\n\n\n\n\n\n\n\n\n\n\nSpatial Representation\nConvert coordinates into geometric objects:\n\n\\(\\color{yellow}{Routes\\to LineStrings}\\)\n\\(\\color{yellow}{Forecast\\ Points\\to Points}\\) \\(\\color{gray}{\\text{where:}}\\) \\(\\color{yellow}{LineString\\small_R\\normalsize=ST\\_MakeLine(ST\\_Point(start),\\ ST\\_Point(end))}\\) \\(\\color{yellow}{Point(F)=ST\\_Point(longitude,\\ latitude)}\\)\n\n\\({\\textbf{R}}\\) - Route definition (tuple of start/end coordinates)\n\\({\\textbf{LineString(R)}}\\) - Linear geometry connecting route endpoints, generated by: \\(\\color{gray}{ST\\_MakeLine(ST\\_Point(start_{Lon},\\ start_{Lat}),\\ ST\\_Point(end_{Lon},\\ end_{Lat}))}\\)\n\\({\\textbf{F}}\\) - Raw forecast data point (from API)\n\\({\\textbf{Point(F)}}\\) - Geometric point representing weather observation, generated by: \\(\\color{gray}{\\ ST\\_Point(longitude,\\ latitude))}\\)\n\\({\\textbf{start, end}}\\) - Route endpoints (latitude/longitude pairs)\n\\({\\textbf{ST\\_Point}}\\) - DuckDB function converting coordinates to points\n\\({\\textbf{ST\\_MakeLine}}\\) - DuckDB function creating route lines\nRisk Aggregation\nSummarize impacts per route:\n\n\\(\\color{yellow}{Total\\ Risk_R=\\sum{risk\\_score}^{}}\\)\n\n\n\\(\\color{yellow}{Max\\ Severity\\small_R\\normalsize=max(severity)}\\)\n\n\n\\(\\color{yellow}{Fuel\\ Impact_R=distance\\ \\times \\ \\overline{fuel\\_multiplier}}\\)\n\n\n\\(\\color{yellow}{Delay\\small_R\\normalsize=\\left(\\frac{distance}{60}\\ \\times\\ route\\_delay\\right)\\ +\\ border\\_delays}\\)\n\n\\({\\textbf{R}}\\) - Route definition (tuple of start/end coordinates)\nSpatial Filtering\nIdentify weather impacts along routes:\n\n\n\\(\\color{yellow}{Impacted\\ Points=\\{F\\ |\\ ST\\_Intersects(ST\\_Buffer(LineString(R),\\ Point(F))\\}}\\)\n\n\n\\({\\textbf{F}}\\) - Weather forecast points\n\\({\\textbf{R}}\\) - Route geometry\n\\({\\textbf{ST\\_Buffer}}\\) - Expands route line by 0.1 degr. (~11 km at equator)\nSimplified Pipeline\n\n\n\\[\n\\color{yellow}{Raw\\ Forecast\\overset{Spatialize}{\\longrightarrow}Points\\overset{Intersect\\ Routes}{\\longrightarrow}Filtered\\ Data\\overset{Aggregate}{\\longrightarrow}Risk\\ Metrics}\n\\]\n\n\nThe workflow transforms raw coordinates into actionable route risk profiles using spatial relationships and weighted averages."
  },
  {
    "objectID": "index.html#historical-eda",
    "href": "index.html#historical-eda",
    "title": "Route Assistant",
    "section": "Historical EDA",
    "text": "Historical EDA\nParameterized SQL Aggregation Function Examples\n\n\nFull parameterization using a glue_sql templateglue_sql_mean &lt;- function(con,\n                     group_cols,\n                     transformation_col,\n                     metric_col,\n                     from_tbl) {\n     # Create parameterized query with glue_sql\n     query &lt;- glue::glue_sql(\"\n     SELECT\n          {`group_cols`*}\n          ,AVG({`transformation_col`}) AS {`metric_col`}\n     FROM {`from_tbl`}\n     GROUP BY {`group_cols`*}\n     ORDER BY {`group_cols`*}\n     \", .con = con)\n     return(dbGetQuery(con, query))\n}\n\nglue_sql_sum &lt;- function(con,\n                     group_cols,\n                     transformation_col,\n                     metric_col,\n                     from_tbl) {\n     # Create parameterized query with glue_sql\n     query &lt;- glue::glue_sql(\"\n     SELECT\n          {`group_cols`*}\n          ,SUM({`transformation_col`}) AS {`metric_col`}\n     FROM {`from_tbl`}\n     GROUP BY {`group_cols`*}\n     ORDER BY {`group_cols`*}\n     \", .con = con)\n     return(dbGetQuery(con, query))\n}\n\nglue_sql_count &lt;- function(con,\n                     group_cols,\n                     transformation_col,\n                     metric_col,\n                     from_tbl) {\n     # Create parameterized query with glue_sql\n     query &lt;- glue::glue_sql(\"\n     SELECT\n          {`group_cols`*}\n          ,COUNT({`transformation_col`}) AS {`metric_col`}\n     FROM {`from_tbl`}\n     GROUP BY {`group_cols`*}\n     ORDER BY {`group_cols`*}\n     \", .con = con)\n     return(dbGetQuery(con, query))\n}\n\n\n\n\n\nCode# Define parameters\ngroup_cols &lt;- c(\"year\", \"month\")\ntransformation_col &lt;- \"temperature_2m\"\nmetric_col &lt;- \"avg_temp\"\nfrom_tbl &lt;- \"historical_data\"\n\nmean_data &lt;- glue_sql_mean(\n     duckdb_con, \n     group_cols, \n     transformation_col, \n     metric_col, \n     from_tbl\n     )\n\n# Define parameters\ntransformation_col &lt;- \"rain\"\nmetric_col &lt;- \"sum_rain\"\n\nsum_data &lt;- glue_sql_sum(\n     duckdb_con, \n     group_cols, \n     transformation_col, \n     metric_col, \n     from_tbl\n     )\n\ntransformation_col &lt;- \"weekday_name\"\nmetric_col &lt;- \"count_weekdays\"\ngroup_cols &lt;- c(\"year\", \"month\", \"weekday_abb\")\n\ncount_data &lt;- glue_sql_count(\n     duckdb_con, \n     group_cols, \n     transformation_col, \n     metric_col, \n     from_tbl\n)\n\n\n\nTest A Correlation Visual\n\n\nCodelibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nCode# Define parameters\ngroup_cols &lt;- c(\"year\", \"month\")\ntransformation_col &lt;- \"temperature_2m\"\nmetric_col &lt;- \"avg_temp\"\nfrom_tbl &lt;- \"historical_data\"\n\nquery_data &lt;- glue_sql_mean(\n     duckdb_con, \n     group_cols, \n     transformation_col, \n     metric_col, \n     from_tbl\n)\n\npm &lt;- ggpairs(\nquery_data, \ncolumns = c(\"year\", \"month\", \"avg_temp\"), \ncolumnLabels = c(\"Year\", \"Month\", \"Mean Temp\"),\nggplot2::aes(color = as.factor(month), alpha = 0.5)\n)\n\n\n\n\n\nCodepm + ggplot_theming()  # Apply custom theme\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\n\n\nCodelibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nCode# Subset temperature-related numerical variables\ntemp_vars &lt;- tbl(duckdb_con, \"historical_data\") |&gt; \n     select(latitude, temperature_2m, year, snowfall, snow_depth) |&gt;\n     collect() # |&gt;\n     #glimpse()\n\n# Calculate correlation matrix (Pearson)\ncor_matrix_temp &lt;- cor(temp_vars, use = \"complete.obs\", method = \"pearson\")\n\n\n\n\nCodecor_matrix_temp\n\n                    latitude temperature_2m          year     snowfall\nlatitude        1.000000e+00    -0.25852680  3.276914e-07  0.041753557\ntemperature_2m -2.585268e-01     1.00000000  3.739077e-02 -0.117114197\nyear            3.276914e-07     0.03739077  1.000000e+00 -0.005086443\nsnowfall        4.175356e-02    -0.11711420 -5.086443e-03  1.000000000\nsnow_depth      1.279244e-01    -0.34738754 -3.659271e-02  0.173762207\n                snow_depth\nlatitude        0.12792438\ntemperature_2m -0.34738754\nyear           -0.03659271\nsnowfall        0.17376221\nsnow_depth      1.00000000\n\n\n\nCode# Visualize with corrplot\ncorrplot(cor_matrix_temp, method = \"number\", type = \"upper\", tl.cex = 0.7)\n\n\n\n\n\n\n\nANOVA for cateogorical (e.g., weather_code) to continuous data (e.g., temperature, precipitation)\n\n\nCode# Example: Weather code vs temperature\ntemp_weather_code &lt;- tbl(duckdb_con, \"historical_data\") |&gt; \n     select(temperature_2m, weather_code) |&gt;\n     dplyr::collect() \n\nanova_temp &lt;-aov(temperature_2m ~ weather_code, data = temp_weather_code)\n\nsummary(anova_temp)\n\n                  Df    Sum Sq  Mean Sq F value Pr(&gt;F)    \nweather_code       1 3.378e+07 33783893   90217 &lt;2e-16 ***\nResiduals    8941438 3.348e+09      374                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nCode# Boxplot visualization\nggplot(temp_weather_code, aes(x = as.factor(weather_code), y = temperature_2m)) +\n     geom_boxplot() +\n     labs(title = \"Temperature by Weather Code\")\n\n\n\n\n\n\n\n\n\n\nfigure setup# Subset precipitation variables\nprecip_vars &lt;- tbl(duckdb_con, \"historical_data\") |&gt; \n     select(precipitation, rain, snowfall, snow_depth, weather_code) |&gt;\n     dplyr::collect()\n\n# Use Spearman for non-normal distributions\ncor_matrix_precip &lt;- cor(precip_vars, use = \"complete.obs\", method = \"spearman\")\n\n\n\n\nCodecorrplot(cor_matrix_precip, method = \"color\", type = \"upper\")\n\n\n\n\n\n\nFigure¬†2"
  },
  {
    "objectID": "index.html#forecast-plot-testing",
    "href": "index.html#forecast-plot-testing",
    "title": "Route Assistant",
    "section": "Forecast Plot Testing",
    "text": "Forecast Plot Testing\n\n\nCreate a plot list for wind rosesbase_path = \"data/plots/\"\n\nplot_wind_rose_ggplot(duckdb_con)\n\nfileList &lt;-list.files(base_path, pattern = \"^wind_rose\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Weather Codes\n\n\n\n\n\n\n\n\n\n\n\n(b) Freezing/Non-Freezing Temperature\n\n\n\n\n\n\n\n\n\n\n\n(c) Visibility (km)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Visibility Categories\n\n\n\n\n\n\n\n\n\n\n\n(e) Precipitation (empty if no precipitation)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(f) Wind Rose1\n\n\n\n\n\n\n\n\n\n\n\n(g) Wind Rose2\n\n\n\n\n\n\n\n\n\n\n\n(h) Wind Rose3\n\n\n\n\n\n\n\nFigure¬†3: These are the grouped figures."
  }
]